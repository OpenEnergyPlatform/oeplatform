{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#developer-documentation-of-the-open-energy-platform-oep","title":"Developer documentation of the Open Energy Platform (OEP)","text":"<p>Welcome to the Open Energy Platform Documentation. This site provides the developer documentation for the Open Energy Platform (OEP).</p> <p>State of the documentation</p> <p>The documentation already provides helpful information but is not yet complete. As only parts of it were maintained during the long-term development, we have to catch up. This is a task that we cannot complete in one go. We have therefore decided to complete it step by step. This means that we will update the documentation of the missing code as soon as we have to work on the corresponding code again. Documentation for the Community area will be added continuously and in a timely manner.</p> <p>Compendium</p> <p>If you want to get an overview about the complete Open Energy Family Framework please have a look at our Compendium.</p>"},{"location":"#structure-of-the-documentation","title":"Structure of the documentation","text":"<p>It consists of two parts:</p> <ul> <li>The \"Development\" pages provide an overview of our methods and procedures used   during development and also provides context about the Open Energy Platform   Software to be able to understand the Use Cases and the general scope better.</li> </ul> <ul> <li>The \"Installation &amp; Code Documentation\" pages will help you to install and set   up the Open Energy Platform software system if you wish to use the software   for your own purposes or contribute to its development. The \"Code   Documentation\" section provides technical information relevant to   understanding the infrastructure elements and architecture of the software.   You will also find information about the structure of the oeplatform code   project on GitHub. Of course, you will also find documentation about the code   itself. This part is divided into two sections describing the web APIs   provided by the platform and the documentation about the implemented   functions. To structure this part, we group the code documentation according   to the features that the code implements and we hope to create an easier   understanding of the codebase with this structured approach.</li> </ul>"},{"location":"#what-do-we-want-to-archive-with-the-oep-website","title":"What do we want to archive with the OEP-Website","text":"<p>The Open Energy Platform is a website that has three main targets:</p> <ol> <li>Provide a language-independent interface that is a thin layer on top of the    Open Energy Database (oedb)</li> <li>Implement an intuitive and easy-to use web interface on top of the database</li> <li>Improve the visibility, communication, and transparency of results from    energy system modeling</li> </ol>"},{"location":"#mission-statement","title":"Mission statement","text":"<p>The transition to renewable energy sources is one of the huge goals of the last few decades. Whilst conventional energy generation provides a constant, generally available source of electricity, heat, and so on, our environment pays a toll. Contrary, renewable energy generation is less environmentally demanding but more financially expensive or just locally or inconsistently available. Guaranteeing a steady and reliable, yet sustainable supply of energy requires still a lot of thorough research.</p> <p>Expansion of the energy grid might imply measures that must be communicable in a transparent way. Hence, results from research of energy system studies should be publicly available and reproducible. This raises the need for publicly available data sources.</p>"},{"location":"dev/","title":"Index","text":""},{"location":"dev/#getting-started-with-development","title":"Getting started with development","text":"<p>This section gets you started with contribution to the development of the oeplatform software which is part of the OpenEnergyFamily. The development takes place on GitHub and most communication is handled in GitHub Issues, Pull Requests and discussions. Additionally developer meetings are used to talk about latest developments. E-Mails and Matrix/Element chat can be added to the pool once one commits to regular contributions.</p> <ul> <li>Contact info</li> <li>About the OpenEnergyFamily</li> </ul>"},{"location":"dev/#guidelines-for-contribution","title":"Guidelines for contribution","text":"<p>See our developer guidelines and get in touch with our developer team.</p>"},{"location":"dev/#the-workflow-we-follow","title":"The workflow we follow","text":"<p>We created a rather detailed development process which outlines the general tasks and describes roles and their responsibilities. This rather formal process is not meant to provide strict borders as many contributors are no professional software developers but it can scale once a team wants to commit. The detailed process also outlines tasks which are partly automated by now.</p> <ul> <li>Collaborative software development process</li> </ul>"},{"location":"dev/best-practice/","title":"Best practice","text":""},{"location":"dev/best-practice/#gitworfklow","title":"GitWorfklow","text":""},{"location":"dev/best-practice/#code-formatting","title":"Code Formatting","text":""},{"location":"dev/best-practice/#isort","title":"isort","text":""},{"location":"dev/best-practice/#flake8","title":"flake8","text":""},{"location":"dev/best-practice/#docstrings","title":"Docstrings","text":""},{"location":"dev/best-practice/#_1","title":"Best practice","text":""},{"location":"dev/community/","title":"Community","text":""},{"location":"dev/community/#community","title":"Community","text":""},{"location":"dev/community/#collaboration","title":"Collaboration","text":"<p>Note</p> <p>Further information</p>"},{"location":"dev/context/","title":"Context","text":""},{"location":"dev/context/#project-context","title":"Project context","text":"<p>The OpenEnergyFamily and OpenEnergyPlatform are developed since 2016. We want to outline the context and some constrains in this section to clear some assumptions which have been made frequently by users.</p>"},{"location":"dev/context/#what-is-our-goal","title":"What is our goal","text":"<p>Since the beginning of development many features and software tools have been delivered, still there is many room for improvement. Since we did mostly research work we developed a wide variety of tools which all solve specific research questions. In the process there is mostly not much room for topics like usability, software and infrastructure maintenance, and even documentation. We where focused on writing papers, fixing requirements and getting research project focused work done. The outcome is that we mainly delivered tools for experts and people we can provide hands on demonstrations. By connecting the OpenEnergyFamily with the NFDI4Energy consortium we started to readjust our role more into the direction of a service provider whit more focus on enhancing what we have, reducing complexity and creating good and complete documentation.</p>"},{"location":"dev/context/#personas-use-cases","title":"Personas &amp; Use Cases","text":"<p>To get a better understanding about out user base with the goal of enhancing the adaption rate of our services we created personas and documented use cases. Below you can find the links, keep in mind these are \"living\" documents which will have to be updated from time to time.</p> <ul> <li>Use Cases</li> <li>Personas</li> </ul>"},{"location":"dev/git-github/","title":"Git github","text":""},{"location":"dev/git-github/#git-github","title":"Git &amp; GitHub","text":""},{"location":"dev/git-github/#github","title":"GitHub","text":""},{"location":"dev/git-github/#issues","title":"Issues","text":""},{"location":"dev/git-github/#pull-requests","title":"Pull Requests","text":""},{"location":"dev/collaboration/planning-communication/","title":"Planning communication","text":""},{"location":"dev/collaboration/planning-communication/#planning-communication","title":"Planning &amp; Communication","text":""},{"location":"dev/collaboration/planning-communication/#communitcation","title":"Communitcation","text":""},{"location":"dev/collaboration/planning-communication/#chat","title":"Chat","text":""},{"location":"dev/collaboration/planning-communication/#meetings","title":"Meetings","text":""},{"location":"dev/collaboration/planning-communication/#project-planning-with-github","title":"Project-planning with GitHub","text":""},{"location":"dev/collaboration/planning-communication/#milestones","title":"Milestones","text":""},{"location":"dev/collaboration/planning-communication/#projects","title":"Projects","text":""},{"location":"dev/collaboration/planning-communication/#releases","title":"Releases","text":""},{"location":"dev/frontend/accessibility/","title":"Accessibility","text":""},{"location":"dev/frontend/accessibility/#accessibility","title":"Accessibility","text":""},{"location":"dev/frontend/accessibility/#why-does-it-matter","title":"Why does it matter?","text":"<p>About 16 % of the world population  experience some kind of disability. By making the Open Energy platform more accessible, we want to support open science and open data, ensuring that research and data are available to all, including individuals with disabilities. This will help not only to broaden the reach of our work but also to give the energy system research community a new range of different perspectives.</p> <p>While the primary responsibility for accessibility lies with the design team, it is important that all members try to integrate accessibility into their workflow.</p> <p>This documentation is a work in progress. We are continually striving to improve our accessibility standards and welcome feedback to help us achieve this goal.</p>"},{"location":"dev/frontend/accessibility/#assessment","title":"Assessment","text":"<p>Working on accessibilty often means using automation tools to support manual testing.</p>"},{"location":"dev/frontend/accessibility/#automated-testing","title":"Automated Testing","text":"<ul> <li>Use   WAVE    as the main tool</li> <li>Use Lighthouse in the developer tools as a secondary tool</li> <li>It is of course possible to use other tools:<ul> <li>BrowserStack    (needs paid account)</li> <li>Browser extensions such as   Accessibility Insights </li> </ul> </li> </ul>"},{"location":"dev/frontend/accessibility/#manual-testing","title":"Manual Testing","text":""},{"location":"dev/frontend/accessibility/#general","title":"General","text":"<ul> <li>General tips<ul> <li>For   designers </li> <li>For   developers </li> <li>For   content writers <ul> <li>Includes platform and documentation</li> </ul> </li> </ul> </li> <li>Color:<ul> <li>Verify text color contrast<ul> <li>Contrast Checker </li> </ul> </li> <li>Ensure that color is not the only means of conveying information</li> </ul> </li> <li>Correct HTML and headings structure<ul> <li>Tutorial </li> </ul> </li> <li>Appropriate use of ARIA roles and landmarks<ul> <li>Directives    for different components</li> </ul> </li> <li>Forms and Labels<ul> <li>Tutorial </li> </ul> </li> <li>Images and Media<ul> <li>Tutorial </li> <li>Transcripts or captions for audio and video content</li> </ul> </li> <li>Menus<ul> <li>Tutorial </li> </ul> </li> <li>Tables<ul> <li>Tutorial </li> </ul> </li> <li>Video Media<ul> <li>Resource </li> </ul> </li> </ul>"},{"location":"dev/frontend/accessibility/#keyboard-testing","title":"Keyboard Testing","text":"<p>Techniques </p>"},{"location":"dev/frontend/accessibility/#screen-reader-testing","title":"Screen Reader Testing","text":"<ul> <li>Use screen readers like NVDA (Windows), VoiceOver (Mac/iOS), and TalkBack   (Android) or use a tool such as BrowserStack</li> <li>Familiarize with Shortcuts</li> <li>Check the following (mostly covered in the \"General\" section):<ul> <li>Headings structure</li> <li>ARIA landmarks</li> <li>ARIA live regions for dynamic content updates</li> <li>Alt attributes</li> <li>Descriptive texts for links and buttons</li> <li>Form labels</li> <li>Modal dialogs</li> <li>Menus and dropdowns</li> <li>Tables</li> </ul> </li> </ul>"},{"location":"dev/frontend/accessibility/#user-testing","title":"User Testing","text":"<p>Conduct usability testing sessions with users who have various disabilities (visual, auditory, motor, cognitive)\u201a</p>"},{"location":"dev/frontend/accessibility/#remediation","title":"Remediation","text":"<ul> <li>Implement fixes</li> <li>Continuous monitoring</li> <li>Team training</li> </ul>"},{"location":"dev/frontend/design-system/","title":"Design System","text":""},{"location":"dev/frontend/design-system/#overview-draft","title":"Overview Draft","text":""},{"location":"dev/frontend/design-system/#foundations","title":"Foundations","text":""},{"location":"dev/frontend/design-system/#design-principles","title":"Design Principles","text":"<ul> <li>Quality</li> <li>Transparency</li> <li>Collaborative</li> <li>Open Data</li> </ul>"},{"location":"dev/frontend/design-system/#ui-library","title":"UI Library","text":"<p>This library  contains the main components and icons used in the OEP app.</p> <p>Please contact us if you need access.</p>"},{"location":"dev/frontend/design-system/#patterns","title":"Patterns","text":"<p>(Reusable solutions to common goals or issues.)</p>"},{"location":"dev/frontend/workflow/","title":"Workflow","text":""},{"location":"dev/frontend/workflow/#frontend-workflow-draft","title":"Frontend Workflow Draft","text":"<p>If you need or wish to work on the visual part of the platform, here are some resources to help you started with.</p> <p>Be sure to know the existing OEP styling, in order to keep the visual consistent throughout the platform. You can double-check by reviewing the website or going through the the design system. Try to keep accessibility in mind as well.</p>"},{"location":"dev/frontend/workflow/#main-workflow","title":"Main workflow","text":"<p>This is the workflow used for working on the biggest part of the app. But if you need to work with the factsheets, you can directly check the content below about React and MUI.</p>"},{"location":"dev/frontend/workflow/#theming-module","title":"Theming module","text":"<p>Since we use Bootstrap v5.2.0  as a front-end library, you first need to have it installed in order to be able to use it. See documentation .</p> <p>Once installed, you can view the content of the Bootstrap library's content inside <code>/theming/bootstrap</code>.</p>"},{"location":"dev/frontend/workflow/#bem-approach","title":"BEM approach","text":"<p>We use the BEM (Block-Element-Modifier) methodology to create descriptive and maintainable class names for our styles. It helps us structure our CSS by dividing components into blocks (standalone components), elements (parts of a block), and modifiers (variations or states of a block or element):</p> <p><code>block__element--modifier</code></p> <p>For example, we can create a <code>button</code> element, and create variants, such as <code>button--filled</code> and <code>button--outlined</code>.</p> <p>We can also create a <code>table</code> block, then work on the <code>table__header</code> element and style for <code>table__header--large</code> and <code>table__header--small</code>.</p> <p>This approach is particularly useful working with SCSS instead of CSS.</p>"},{"location":"dev/frontend/workflow/#extend","title":"@extend","text":"<p>On top of BEM, we use Sass\u2019s <code>@extend</code> feature to leverage Bootstrap\u2019s existing styles. This approach ensures we adhere to the design language established by Bootstrap. It helps maintain consistency and reduces the risk of CSS specificity issues. Additionally, using <code>@extend</code> makes our style sheets smaller by reusing rulesets from Bootstrap, improving the overall performance of our application. Example:</p> <pre><code>.button--filled {\n  @extend .btn;\n  @extend .btn-primary;\n}\n</code></pre> <p>If you user modifiers, remember to use the two classes:</p> <pre><code>&lt;thead class=\"table__header table__header--large\"&gt;\n    ...\n&lt;/thead&gt;\n</code></pre> <p>This hybrid approach of BEM + @extend means you can safely remove the Bootstrap classes from the HTML elements and only keep the BEM classes. But in some cases it is not possible to remove an original Bootstrap class, as a class can be used to dynamically change the styling through JavaScript. It is the case for some components such as nav or tabs.</p>"},{"location":"dev/frontend/workflow/#add-new-component-or-layout","title":"Add new component or layout","text":"<p>If a component or layout doesn't exist yet inside the <code>/theming</code> directory, you can create a file inside the components or layouts folder:</p> <pre><code>/theming/scss/components/_&lt;new-component-name&gt;.scss\n</code></pre> <p>Then add it to the path inside <code>/theming/oepstrap.scss</code>, before working on the styling.</p> <pre><code>@use 'scss/components/&lt;new-component-name&gt;';\n</code></pre>"},{"location":"dev/frontend/workflow/#overwrite-a-bootstrap-variable","title":"Overwrite a Bootstrap variable","text":"<p>Try as much as possible to use the existing Bootstrap variables (<code>/theming/bootstrap/scss/_variables.scss</code>) or the ones that are already overwritten (<code>/theming/_variables.scss</code>), but if you still need to change/overwrite a variable, you need to do it in 2 places:</p> <ul> <li><code>/theming/_variables.scss</code>: update the variable with a new value</li> </ul> <pre><code>$blue-500: #2972A6;\n</code></pre> <ul> <li><code>/theming/scss/base/_index.scss</code>: add the variable to <code>@forward</code></li> </ul> <pre><code>$blue-500: $blue-500\n</code></pre>"},{"location":"dev/frontend/workflow/#react-and-mui","title":"React and MUI","text":"<p>If you need to work with React, for example inside the <code>/factsheet</code> directory, the workflow is different, i.e. BEM doesn't apply here, but the goal from a UI perspective remains the same: the whole app should look uniform, even if the libraries used in the background are different.</p>"},{"location":"dev/frontend/workflow/#mui","title":"MUI","text":"<p>MUI  provides a set of pre-built components specifically designed for React. It uses a component-based approach where each UI element is encapsulated within a React component. It handles styling internally using CSS-in-JS, which means styles are defined directly in JS files instead of CSS or SCSS files.</p> <p>There is a basic OEP theme inside <code>/factsheet/frontend/src/styles/oep-theme.js</code> with the main color palettes, typographic rules and styling for some main components such as buttons and tables. The styles are similar to the ones used in the theming module, but they don't cover as many uses cases yet, though. They can then be used inside the components in <code>/factsheet/frontend/src/components</code>. Try to mostly use this theme in a .js format, but if you need to add extra CSS, you can add them to <code>/factsheet/frontend/src/styles/App.css</code>.</p>"},{"location":"installation/","title":"Index","text":""},{"location":"installation/#installation","title":"Installation","text":"<p>This section provides detailed information on how to install for development purposes. We will also provide a more detailed guide on how to operate the oeplatform for production use cases in the future. The guide covers the full oeplatform software and its infrastructure which is composed of the website, various databases, a lookup service and the ontop-vkg service (see Infrastructure). You will find two main options to install everything:</p> <ol> <li>A docker based deployment setup for local deployment (and soon for production    deployment setups)</li> <li>A \"manual\" step by step installation guide for the oeplatform-website and its    main features. The guide is mainly for development and documents the details    of the installation.</li> </ol> <p>Production deployments without containerization solutions like docker tend to be very specific and depend on your infrastructure.</p> <p>You will also find information on which further setup steps which should which either help with some common issues and help with writing well formatted and quality checked code to get started with contributing to developments on the oeplatform.</p>"},{"location":"installation/#guides","title":"Guides","text":""},{"location":"installation/#installation-for-development-purposes","title":"Installation for development purposes","text":"<p>Automated Docker based installation guide for development</p> <p>Manual installation guide</p> <p>Details on the database infrastructure setup</p>"},{"location":"installation/#next-steps-to-get-started-with-development","title":"Next steps to get started with development","text":"<p>Good practice and guidelines to participate in the development of the oeplatform</p> <p>Understand the nodejs integration and asset bundler for optimized javascript app deployments</p>"},{"location":"installation/context/docker/","title":"Relevant docker components","text":"<p>Depending on if a docker setup is intended for a production or a development context the included files / services might differ. Sometimes a service is only relevant for development purposes e.g. if we want to have automated reload of assets when developing a frontend to see changes quickly. In production we dont need this module. The following is a general overview of the 3 files most likely be used and especially used in our current setup.</p>"},{"location":"installation/context/docker/#dockerfile","title":"Dockerfile","text":"<p>Docker files are setup per service and keep all commands for configuration, installation and execution of the service in one place. They are e.g. used to copy directories, install python dependencies which includes creating directories, exposing ports and running commands to execute the software like starting a development server. They also link to the entrypoint script which is described in the next section.</p>"},{"location":"installation/context/docker/#docker-entrypoints","title":"Docker entrypoints","text":"<p>The entrypoint is a shell script which included all post installation steps of a software. This might include adding specific settings, migrations or setting up test user and data or collecting static files and more. These scripts also also available per service. In some cases a service might not require one of these files.</p>"},{"location":"installation/context/docker/#docker-compose","title":"Docker compose","text":"<p>Compose is a specific tool provided by docker itself. It can be used in case you want to start more then one software service at a time. This is especially useful if you develop a infrastructure and not only a single software which does not need to communicate with other software services. Composes also created a network so all services can \"talk\" to each other. The docker compose file list all services whit specific configuration options for each service. This includes info on where the files are copied from which will make up the software, what images are used for other services like databases which are used but not developed as part of the oepaltform project and more. For development this also offers great tooling as you want to be able to use the container and still edit its contents like source code files and more. Compose offers a bind mount option which will mount you current directory into the container and watch for any file changes. To gether with devcontainer its also possible to use your IDE\u00b4s debugger tool and more. To sum this up compose enables us</p>"},{"location":"installation/guides/development-setup/","title":"Development setup","text":"<p>Recent updates</p> <p>As we shift the development support towards a docker based setup which sets up the oeplatform infrastructure and deploys it locally most of the commands below are are already included in the automated docker compose setup. For example there is dummy data and a test user pre \"installed\" and ready to use. Also note that if you use the docker based setup you must run the commands below inside the oeplatform web container to gain any effect.</p> <p>Available information which effect your host environment like your IDE and your operating system stay the same.</p> <p>See our developer guidelines and get in touch with our developer team. Have a look at the official git-Book instructions on how to setup your git on a new system to be able to contribute to our GitHub repository.</p>"},{"location":"installation/guides/development-setup/#choose-your-development-environment-and-tools","title":"Choose your development environment and tools","text":"<p>As a software developer, you learn your own way of working and refine it as your experience grows. The choice of developer environment &amp; tools is therefore largely a personal preference. Here we want to suggest how new developers can get started and how we can implement successful, efficient development.</p> <p>In addition, there are some tools that are absolutely necessary to ensure the quality of the software while new code from various sources is collaboratively fed into a code repository on github.</p>"},{"location":"installation/guides/development-setup/#the-operating-system","title":"The operating system","text":"<p>In our installation guide we offer the installation for all common OS (Linux/Apple, Windows). Since the server on which the developed software (especially web applications) is operated is usually a Linux-based system, it is also highly advisable to design the local development environment as similarly as possible.</p> <p>Especially for developers using a Windows computer, there are relevant considerations here to avoid constant additional work that is necessary to install certain packages in order to remain compatible with the latest developments.</p> <p>Those who want to participate in software development in the long term should therefore consider whether it is worth using either a container solution such as Docker in which the software and databases are installed. New code can then be written or tested directly in the container via an IDE. On the other hand, WSL has also been available for some time, which can be used to run a Linux system on a Windows computer. As Microsoft itself developed the solution, it is particularly well integrated.</p>"},{"location":"installation/guides/development-setup/#development-tools","title":"Development tools","text":"<p>We mainly use VSCode or PyCharm as an integrated development environment (IDE). These IDEs are particularly easy to install, can be flexibly extended with plugins and enable all relevant tools for development to be operated in one window, which in our view increases productivity.</p>"},{"location":"installation/guides/development-setup/#pre-commit-hooks","title":"pre-commit-hooks","text":"<p>We encourage you to install our pre-commit hooks. They will probably get in the way sometimes when you try to \"just commit\" your code, but they help us to ensure the quality of the code, especially the formatting of the code.</p> <pre><code>pip install pre-commit\n</code></pre> <p>And install our hooks as defined in the '.pre-commit-config.yaml' file</p> <pre><code>pre-commit install\n</code></pre> <p>From now on, you can only transfer if the hooks are successful.</p>"},{"location":"installation/guides/development-setup/#useful-vscode-plugins","title":"Useful VSCode plugins","text":"<p>You can search the name in the VSCode Extensions tab:</p> <ul> <li>Black Formatter</li> <li>isort</li> <li>Flake8</li> <li>Pylance</li> <li>Python</li> <li>Python Debugger</li> <li>Code Spell Checker</li> <li>Database Client</li> <li>ESLint</li> <li>markdownlint</li> <li>GitLens</li> </ul>"},{"location":"installation/guides/development-setup/#run-all-tests","title":"Run all tests","text":"<p>We aim to develop the oeplatform by using the test driven development approach. Fundamentally this requires a testing framework that is provided by django. If you want to check if your changes to the codebase affect the existing functionality run all available tests:</p> <pre><code>python manage.py test\n</code></pre> <p>Most of our current tests are available in the <code>api</code> app of the django project. Look for the <code>tests</code> directory in any of our apps.</p>"},{"location":"installation/guides/development-setup/#deploy-locally","title":"Deploy locally","text":"<p>You can run your own local copy of the OEP website server with</p> <pre><code>python manage.py runserver\n</code></pre> <p>By default, you should be able to connect to this copy by visiting 127.0.0.1:8000 in your web browser. This way you can insert your changes without worrying about breaking anything in the production system.</p>"},{"location":"installation/guides/development-setup/#deploy-react-app-s-locally","title":"Deploy react app\u00b4s locally","text":"<p>Note</p> <p>This solution is not the best developer experience and needs optimization</p> <p>As some Apps of the Oeplatform integrate React apps they need to be build using npm locally. We offer build scripts that can be triggered using django management commands. For example to build the scenario bundles react app and deploy it in the django app factsheet you can run the command <code>python manage.py build_factsheet_app</code>. Once done you can access the scenario bundles app via your locally deployed django instance (see above).</p> <p>Keep in mind that you now use a bundled version of the react app and all changes you might want to add to the React jsx components will only show up once you build the app again. For development this might be a bit clunky but since the app is deployed inside the django app this enables the React app to use the django authentication. An alternative that will not be able to use the django user authentication currently is to deploy the React app alongside the locally deployed django instance. You can use npm start while being inside the <code>factsheet/frontend/</code> directory in the terminal. To make this work you will have to change the config.json inside the same directory. In this file you find the key <code>\"toep\": \"/\"</code> you'll have to change this <code>/</code> value to <code>http://127.0.0.1:8000</code> to point to the django instance currently deployed locally. If your react test server is still running (<code>npm start</code>) you can now access it at <code>http://127.0.0.1:3000/scenario-bundles/main</code>. All changes made to the React jsx components will now be reflected instantly using live reloading.</p>"},{"location":"installation/guides/development-setup/#user-management-setup-a-test-user","title":"User Management - Setup a test user","text":"<p>To create a dummy user for functionality testing purposes</p> <p>Run the django management command with arguments. Below you see an example:</p> <pre><code>python manage.py create_dev_user \"$DEV_USER\" \"$DEV_USER@mail.com\" --password \"$DEV_PW\" || true\n</code></pre> <p>You can also use this script to create a new user. Execute this python code (either directly in a terminal or from a file)</p> <pre><code>import os\nimport django\n\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"oeplatform.settings\")\ndjango.setup()\nfrom login.models import myuser\nu = myuser.objects.create_devuser('test','test@mail.com')\nu.set_password('pass')\nu.save()\n</code></pre>"},{"location":"installation/guides/development-setup/#create-test-tables","title":"Create test tables","text":"<p>You have multiple options to create tables and upload data. We will not explain the approach using a SQL dump that is imported into the postgresql database. The easiest approach that will get you started quickly is based on the OEP-Website UI. The related functionality is part of the <code>dataedit</code> app in the django project.</p> <p>Before we can get started we have to register the topics where data can be grouped to. Initially all data is uploaded as draft. Once it is published it is moved to another topic e.g. <code>demand</code> or <code>scenario</code>. You can use the management command to register our predefined topics:</p> <pre><code>python manage.py create_topics\n</code></pre> <p>To create and seed the test table using our test dataset you can use the following command:</p> <pre><code>python manage.py create_example_tables\n</code></pre> <p>The command will read the example dataset form our representative, minimal example. Once successfully seeded the database contains the dataset 'example_wind_farm_capacity', including 4 rows of data and metadata.</p>"},{"location":"installation/guides/development-setup/#using-the-http-api","title":"Using the HTTP-API","text":"<p>You can use the http api that is available once you started your local development server using the <code>runserver</code> command. To understand how to use the api you can have a look at our academy courses but keep in mind that you have to modify the URL of the api endpoints to you locally running oep instance. You can to this by changing the beginning of the url from something like <code>https://www.oeplatform.org/</code> to <code>http://127.0.0.1/</code>. Have a look at this course to get started with the http api.</p> <p>Note</p> <p>There are several capabilities which are offered by the API some are aimed on client integration and some are implemented as traditional REST API endpoints. You can find a openAPI schema here, we are currently working on providing the full list of attributes supported by each endpoint. Until this is done we rely on the academy to provide the key information on how to use the REST-API.</p>"},{"location":"installation/guides/development-setup/#using-the-oep-website-ui","title":"Using the OEP-Website UI","text":"<p>The OEP-Website includes a features that is called upload wizard internally. This features usually is used by the user to add datasets and can be accessed via the database page. Initially the database is empty and the topic cards are not visible. You have to navigate to the page manually. Once you have started your local instance of the OEP you can navigate to this URL:</p> <pre><code>http://127.0.0.1/dataedit/wizard/\n</code></pre> <p>There you can create a table, upload data from CSV file, create metadata and then navigate to the table page. To get started it is okay to just create a table with minimal requirements by just adding a table name that is all lowercase and does not include whitespaces, - or any special characters.</p>"},{"location":"installation/guides/development-setup/#publish-aka-move-datasets","title":"Publish aka move datasets","text":"<p>Once you created your test data you probably want to move your data to any of the other topics. This functionality is also available via the Website UI and by using another endpoint of the HTTP-API.</p>"},{"location":"installation/guides/development-setup/#via-the-http-api","title":"Via the HTTP-API","text":"<p>There is no tutorial available for this feature. You can send a post request to the following URL. You need to add your api token to the post request header. You can have a look on the table create tutorial linked above to understand how you can do that. In python you can use the package <code>requests</code> to perform http requests.</p> <pre><code>http://127.0.0.1/v0/schema/&lt;str:schema&gt;/tables/&lt;str:table&gt;/move/&lt;str:to_schema&gt;/\n</code></pre> <p>The URL must include the name of the topic and table you want to move and the name of the topic you want to move table to. In the future this endpoint will change because it is part of the publishing process. Moving a table will then only be possible once the metadata for that table includes an open data license.</p>"},{"location":"installation/guides/development-setup/#via-the-oep-website-ui","title":"Via the OEP-Website UI","text":"<p>You can navigate to the profile page using your local instance of the OEP website.</p> <pre><code>http://127.0.0.1/user/profile/\n</code></pre> <p>There you find a tab called tables. If you include an open data license in the metadata of your test table you previously created, a publish button becomes visible. Once you click it you can select a topic to move the table to.</p> <p>You can edit the metadata for a table by visiting the detail page of a table then click the tab meta information and click the button edit. The license information should be added to the licenses field of the metadata.</p>"},{"location":"installation/guides/development-setup/#import-datasets-from-openenergyplatformorg","title":"Import datasets from openenergyplatform.org","text":"<p>Sometimes it is very useful to have actual datasets which are available on the OEP in your local instance to be able fully reproduce use cases or reproduce errors.</p> <p>We offer a script in the 'script' directory of the oeplatform code project. It is currently a prototype for doing what is described above. It is not fully tested against all data types so far so might be error prone.</p> <p>To use it you must adapt the code and add the information on what datasets you want to import. Datasets are referenced by schema and table name. It is possible to import multiple once in one run and you can limit the amount of rows each dataset should included as some datasets are very large and it is not important to have the full data for testing use cases.</p>"},{"location":"installation/guides/docker/","title":"Docker","text":""},{"location":"installation/guides/docker/#docker-usage","title":"Docker Usage","text":"<p>Works for Linux &amp; MacOS (probably). It is tested with Linux. You also need a working Docker and Docker Compose installation and some basic knowledge about command lines.</p> <p>This is a short introduction into the usage of Docker with Open Energy Platform (OEP). We provide two seperate images for the OEP, a database image and a application image. The database image prepares a ready-to-use database for the OEP and is an extension to a common PostgreSQL docker image. The application image contains the OEP and connects to a container running the database image. There are some additional resources at Further Information for an more in-depth understanding.</p>"},{"location":"installation/guides/docker/#usages","title":"Usages","text":""},{"location":"installation/guides/docker/#full-docker-installation","title":"Full Docker Installation","text":"<p>Use this, if you want to use Open Energy Platform.</p> <p>This can be used, if you just want to host your own OEP installation or test API scripts or something similar, that should not be done with the public instance. We use <code>docker compose</code> to deploy more than one container.</p> <p>Docker Compose is a tool for defining and running multi-container Docker applications. Our application consists of two different containers, a database container and an application container. We need both containers to get a fully working oeplatform deployment. <code>docker-compose.yaml</code> contains a definition for an isolated environment to run both containers.</p> <p>Starting a oeplatform installation with Docker is easy, since it is zero configuration and zero dependencies. Our deployment will create persistent files in your current work directory which needs to be reused across restart. Make sure, you use the same working directory each time, e.g. repository root.</p> <p><code>docker compose up</code> will start the deployment, and you should be able to access a fresh installation via <code>http://localhost:8000</code>. Ctrl + C will stop the entire deployment. If it is restarted in the same working directory, it will keep state.</p>"},{"location":"installation/guides/docker/#tasks","title":"Tasks","text":"<p>We assume, that you choose the repository root as your working directory. If you did choose another working directory, make sure to change the path to the <code>docker-compose.yaml</code> file accordingly.</p>"},{"location":"installation/guides/docker/#start-deployment","title":"Start Deployment","text":"<ul> <li><code>docker compose -f ./docker/docker-compose.yaml up</code></li> </ul>"},{"location":"installation/guides/docker/#start-deployment-in-background","title":"Start Deployment In Background","text":"<ul> <li><code>docker compose -f ./docker/docker-compose.yaml up -d</code></li> </ul>"},{"location":"installation/guides/docker/#stop-deployment-in-background","title":"Stop Deployment In Background","text":"<ul> <li><code>docker compose -f ./docker/docker-compose.yaml down</code></li> </ul>"},{"location":"installation/guides/docker/#reset-database","title":"Reset Database","text":"<ul> <li>Stop Deployment</li> <li>Remove <code>oeplatform_data</code> folder from our working directory</li> <li>Start Deployment</li> </ul>"},{"location":"installation/guides/docker/#database-container-with-local-installation","title":"Database Container with local installation","text":"<p>Use this, if you want to contribute to Open Energy Platform.</p> <p>This can be used, if you want to use a local installation for development and don't want to mess with the database setup (which should be the normal case).</p> <p>First step is to include the OpenEnergyOntology, as described in installation docs, step 3.1.</p> <p>We start the database container and expose the database to our host. Afterwards, we prepare the <code>securitysettings.py</code> with the correct credentials and migrate the database to our current branch.</p> <pre><code>docker run -p \"5432:5432\" -v \"$(pwd)/oeplatform_data:/var/lib/postgresql/data\" ghcr.io/openenergyplatform/oeplatform-postgres:latest\n</code></pre> <p>This command starts a container with the <code>oeplatform-postgres</code> docker image. It automagically creates the needed tables. The database saves its information at your current working directory within the <code>oeplatform_data</code> folder. It also tunnels the PostgreSQL port to your local machine to make it accessible from your host. This enables you to connect your OEP instance to your machine.</p> <p>Connecting the OEP to the database container is similar to any other PostgreSQL instance. You need to adapt the <code>oeplatform/securitysettings.py</code> to the correct values OR set the correct environment, if you use the default values.</p> Description Value Environment Value Django Database Name oep_django <code>OEP_DJANGO_NAME</code> Local Database Name oedb <code>LOCAL_DB_NAME</code> Database User postgres <code>OEP_DJANGO_USER</code>,<code>LOCAL_DB_USER</code> Database Password postgres <code>OEP_DB_PW</code>,<code>LOCAL_DB_PASSWORD</code> Database Host localhost <code>OEP_DJANGO_HOST</code>,<code>LOCAL_DB_HOST</code> Database Port 5432 <code>LOCAL_DB_PORT</code> <p>Afterwards, the application should be able to connect to the empty databases. You need to run the Django preparations and migrations as usual. The following commands are a short summary from the installation instructions.</p> <pre><code># Make sure, you expose the environment correctly to run migrations.\n\nexport OEP_DJANGO_USER=postgres\nexport OEP_DB_PW=postgres\nexport OEP_DJANGO_HOST=localhost\nexport OEP_DJANGO_NAME=oep_django\nexport LOCAL_DB_USER=postgres\nexport LOCAL_DB_PASSWORD=postgres\nexport LOCAL_DB_NAME=oedb\nexport LOCAL_DB_HOST=localhost\n\n# Preparation\npython manage.py collectstatic\npython manage.py compress\n\n# Running Migrations\npython manage.py migrate\npython manage.py alembic upgrade head\n</code></pre> <p>If the PostgreSQL container gets stopped, it can be recreated with the existing <code>oeplatform_data</code> folder. You do NOT need to run migrations on an existing folder except a changed application version.</p> <p>If you followed this documentation, you can skip the entire <code>Setup Your Database</code> chapter. You already did this and your application is ready to be started.</p>"},{"location":"installation/guides/docker/#tasks_1","title":"Tasks","text":""},{"location":"installation/guides/docker/#start-database-on-existing-data","title":"Start Database On Existing Data","text":"<ul> <li>Make sure, <code>oeplatform_data</code> exists in your working directory.</li> <li>Start Database</li> </ul>"},{"location":"installation/guides/docker/#reset-database_1","title":"Reset Database","text":"<ul> <li>Stop Database</li> <li>Remove <code>oeplatform_data</code> folder from our working directory</li> <li>Start Database<ul> <li>Database will recreate all needed tables</li> <li>You need to reapply the migrations</li> </ul> </li> </ul>"},{"location":"installation/guides/docker/#restart-oeplatform","title":"Restart oeplatform","text":"<ul> <li>Open a bash in the oeplatform container and run <code>apache2ctl restart</code>.</li> </ul> <pre><code># Find name of oeplatform container\n$ me@local:~$ sudo docker ps --format '{{.Names}}'\ndocker-oeplatform-1\nf7ed30b9c934_docker-postgres-1\n# open bash in that container\nme@local:~$ docker exec -ti docker-oeplatform-1 bash\nroot@27...7:/app#  apache2ctl restart\nroot@27...7:/app#\n</code></pre>"},{"location":"installation/guides/docker/#build-the-oeplatform-image","title":"Build the oeplatform image","text":"<p>If you want to build the oeplatform docker image yourself, e.g. after you've changed the code, you can do this by running the following command in the main directory of this repository.</p> <pre><code>docker build -t ghcr.io/openenergyplatform/oeplatform -f docker/Dockerfile .\n</code></pre>"},{"location":"installation/guides/docker/#further-information","title":"Further Information","text":"<ul> <li>Image vs Container</li> </ul>"},{"location":"installation/guides/installation-docker-dev/","title":"Docker based installation","text":"<p>\ud83d\udea7</p> <p>This section is still new and might change. The information presented here is tested by the developer and is currently rolled out within our team and close collaborators. Any suggestions are welcome and can be added in this GitHub discussion.</p> <p>Manual installation</p> <p>If you prefer not to use docker or want to get insights into each step of the installation and setup process for the oeplatform please have a look at the manual installation guide which also links the detailed database setup.</p>"},{"location":"installation/guides/installation-docker-dev/#introduction","title":"Introduction","text":"<p>Installing the oeplatform and its infrastructure is a tedious when one wants to setup all the involved components and use them either for development or to deploy them with the goal of operating a dedicated instance for organizations internally or open to the internet. The concept of containerized software helps a lot when developing and also deploying software or even whole infrastructures which may contain several software containers. THe essence of the benefit this brings is the reproducibility due to the container concept. All dependencies which have been installed once successfully can be installed again and any system that supports the container concept which was used will be able to reproduce the build process.</p> <p>This concept is not exclusive to docker as many parties offer specific container solutions. As docker is rather disseminated and adapted we want to start our route to containerization by providing a docker compose development setup which will enable developers even with low technical literacy to install the oeplatform and apply changes to this local instance of the software infrastructure. We hope that this will enable more contributors to get started with development quickly and learn the details along side the development road.</p> <p>Note</p> <p>We already maintain an docker image of the oeplatform and the OEDB (postgresql database) which is mainly used for CI especially unit and integration testing. These images stays valid for now. The new setup aims for developers and is a more complete version as it introduces services to our docker compose setup which have been missing in the previous version.</p>"},{"location":"installation/guides/installation-docker-dev/#relevant-docker-components","title":"Relevant docker components","text":"<p>If you want to understand the docker based setup better and read up on what docker components / modules we used to build the development setup you can read up on the docker compose, docker and docker entrypoint files.</p>"},{"location":"installation/guides/installation-docker-dev/#installation","title":"Installation","text":""},{"location":"installation/guides/installation-docker-dev/#docker-compose-based-installation-for-development-purpose","title":"Docker compose based installation for development purpose","text":"<p>The docker setup is created based on several configuration files and scripts. Together they enable us to install every module of the infrastructure with one single command. This section will give an overview of the setup and also provide commands and any pre-installation steps which will lead to a successful installation of the oeplatform especially and only for development purposes.</p>"},{"location":"installation/guides/installation-docker-dev/#docker-compose-optional-environment-variables","title":"Docker compose (optional) environment variables","text":"<p>You can set these environment variablesto override defaults:</p> <ul> <li><code>OEP_DEV_PORT_POSTGRES</code>: public port to postgres database, defaults to 5432</li> <li><code>OEP_DEV_PORT_WEB</code>: public port to web interface, defaults to 8000</li> <li><code>OEP_DEV_PORT_DEBUGPY</code>: public port to python debugger, defaults to 5678</li> <li><code>OEP_DEV_PORT_FUSEKI</code>: public port to fuseki server, defaults to 3030</li> <li><code>OEP_DEV_PORT_VITE</code>: public vite JavaScript server port, defaults to 5173</li> </ul>"},{"location":"installation/guides/installation-docker-dev/#setup-ontop-service","title":"Setup ontop service","text":"<p>The ontop service requires a special database driver which must be downloaded manually first.</p>"},{"location":"installation/guides/installation-docker-dev/#docker-compose-command","title":"Docker compose command","text":"<p>Info</p> <p>We assume that you already installed these software pieces.</p> <ul> <li>Git</li> <li>Docker</li> </ul> <p>On windows we recommend using WSL2 or a Linux VM as the windows based installation is not tested regularly and often requires additional steps.</p> <p>Add the following commands into your terminal which supports git and docker compose commands.</p> <pre><code># first close the oeplatform repository\n&gt; git clone https://github.com/OpenEnergyPlatform/oeplatform.git\n\n# navigate into the cloned directory, on build runs you need to provide you hosts user and group id\u00b4s\n&gt; USER_ID=$(id -u) GROUP_ID=$(id -g) docker compose -f docker/docker-compose.dev.yaml up --build\n\n# From now on you use the command below to startup the setup, but you will have to rebuild\n# the container regularly to pick up latest changes e.g. if a new npm oder pip package was installed.\n&gt; docker compose -f docker/docker-compose.dev.yaml up\n</code></pre>"},{"location":"installation/guides/installation-docker-dev/#using-a-existing-repository","title":"Using a existing repository","text":"<p>This should print the build process and result in successfully build infrastructure with several containers running. On first start up of the oeplatform container it is likely that you will have to adapt some django settings and or remove some directories in case you have used an existing distribution of the oeplatform code together with previous installations.</p> <p>Checklist:</p> <ul> <li>Remove the <code>oeplatform_data</code> directory from the docker folder</li> <li>Remove any older images and volumes</li> <li>Make sure you have a internet connection for the initial setup</li> <li>In your oeplatform/securitysettings.py make sure you have the variables from   the securitysettings.default.py file available especially the DJANGO_VITE,   VITE_DEV_SERVER_URL and the Updated RDF_DATABASES connection credentials are   new and you might have to add them.</li> </ul>"},{"location":"installation/guides/installation-docker-dev/#remove-installations","title":"Remove installations","text":"<p>Using the command below will stop and all containers. Keep in mind that you will detach from the volume which contains all data from you current database, factsheet and scenario bundles as well as all user.</p> <pre><code>docker compose -f docker/docker-compose.dev.yaml down -v\n</code></pre> <p>This will only remove the containers not the images or the volumes. If you want to install everything make sure to prune all images and if you also want to remove the data you must also remove the images. You can also do this using docker desktop.</p> <p>If you want to create them again you can run the first command again. In most cases it is useful to add the --build flag to trigger a new build which will include latest changes. You can add the -D flag to detach the terminal form the container once it is started.</p> <pre><code>docker compose -f docker/docker-compose.dev.yaml up --build -d\n</code></pre>"},{"location":"installation/guides/installation-docker-dev/#inspect-docker-containers","title":"Inspect docker containers","text":"<p>To monitor your deployment a very simple way is to use docker desktop or output the container in your terminal by not using the -d flag when spinning up containers. You will find all installed containers and find easy to use options to read the logs or even execute commands. This gives you full insights and control in case some errors and you need to inspect the development server output.</p>"},{"location":"installation/guides/installation-docker-dev/#usage","title":"Usage","text":"<p>Once everything is up and running you are good to start development. You should now have the following containers running:</p> <ul> <li>vite (javascript dev server)</li> <li>oeplatform-web-dev (OEP)</li> <li>postgres-1 (OEDB, Django DB)</li> <li>fuseki (OEKG)</li> <li>SOON: LOEP (oeo term lookup tool used for ontological annotation)</li> <li>SOON: ontop (quantitative data comparison)</li> <li>SOON: Docs (mkdocs based documentation website)</li> </ul>"},{"location":"installation/guides/installation-docker-dev/#restart-rebuild-and-cleanup-containers-to-apply-changes","title":"Restart, rebuild and cleanup containers to apply changes","text":"<p>While developing and adding changes you might want to rebuild your docker containers. There are several ways to do this, one is already documented above in the remove installation section. A typical sequence when updating the composed containers:</p> <pre><code># Remove everything, assuming you have a terminal which is at the oeplatform root directory\ndocker compose -f docker/docker-compose.dev.yaml down -v\n\n# Install everything again, don't forget the user id args\nUSER_ID=$(id -u) GROUP_ID=$(id -g) docker compose -f docker/docker-compose.dev.yaml up --build\n\n# Just apply changes to a specific container (see vite as ref to the container name)\ndocker compose -f docker/docker-compose.dev.yaml vite down -v\ndocker compose -f docker/docker-compose.dev.yaml vite up\n</code></pre>"},{"location":"installation/guides/installation-docker-dev/#dummy-user-and-data","title":"Dummy user and data","text":"<p>This setup also gets you started with some of the main features of the oeplatform as it creates a test user and dummy datasets in the database as well as dummy model and framework factsheets and a example scenario bundle.</p> <ul> <li>Login with user \"test\" and password \"pass\"</li> </ul>"},{"location":"installation/guides/installation-docker-dev/#docker-reload-on-files-changes","title":"Docker reload on files changes","text":"<p>The docker setups bind mounts your current workspace which is the directory you cloned the oeplatform to. The bind mount enables you to do edits to any code files which will then be picked up by the docker container which is restarting and you will find your edits in the development deployment which you can access in your browser at http://127.0.0.1:8000.</p> <p>This includes python and javascript sourcecode files.</p>"},{"location":"installation/guides/installation-docker-dev/#working-with-nodenpm-javascript","title":"Working with node/npm (javaScript)","text":"<p>You might want to use node and its package manager npm to install or update package in the package.json file. To do so you should have node installed locally (using node-version-manager \"nvm\") and install new packages using the npm cli. You can also install them directly in the docker container using the \"excec\" option.</p> <pre><code>npm install \"package-name\" --save\n</code></pre> <p>Then you build the vite container, it will pickup the changes in the package.json / package-lock.json and update the container node_modules. See also more info on the node.js aka JavaScript setup.</p> <pre><code>docker compose -f docker/docker-compose.dev.yaml vite up --build\n</code></pre>"},{"location":"installation/guides/installation/","title":"Install and setup the OpenEnergyPlatform Application","text":"<p>Below we describe the manual installation of the oeplatform code and infrastructure.</p> <p>Tip</p> <p>We also support docker users by providing basic oeplatform-webapp and database images . This brings an easy setup which provides an installed and ready to use locally oeplatform and additional databases. To support developers with getting started with the initial setup which provides a pre configured complete oeplatform software infrastructure with a docker compose setup that installs all components of the infrastructure using containers run locally in a shared virtual network. By adding convince functionality to the setup we enhance the developer experience to support the development.</p> <p>Find the installation instructions that get you started with development here</p> <p>Find the (old) instructions related to our docker image mainly used for testing as part of the CI</p> <p>Danger</p> <p>Currently the docker based installation does not cover the installation of the additional database <code>jenna-fuseki</code> a triple store that stores graph data used in some of our features. It is not mandatory to run the core functionality of the oeplatform. You need to install it manually as described in the installation guide.</p> All steps &amp; commands in one list <p>This list of commands will only work on systems where the core system dependencies already exists. Please use the full installation guide in case you encounter errors.</p> <ol> <li> <p>Get code &amp; install dependencies.     - <code>git clone https://github.com/OpenEnergyPlatform/oeplatform.git</code>     - <code>cd oeplatform</code>     - Install python 3.10.     - <code>python -m venv env</code>     - <code>source env/bin/activate</code>     - <code>pip install -r requirements.txt</code></p> </li> <li> <p>Setup the OEO integration     - Instructions on Section 4     - Automatically added in docker container</p> </li> <li> <p>Loading and compressing static assets     - Create your <code>securitysettings.py</code> config file from our default settings: Copy &amp; rename <code>oeplatform/securitysettings.py.default</code> &gt;  <code>securitysettings.py</code>     - <code>python manage.py collectstatic</code>     - <code>python manage.py compress</code>     - These steps are automatically added in the docker container</p> </li> <li> <p>Install databases &amp; setup connection     - Chose option 1 to use docker to install PostgreSQL and most of the setup automatically. You need to install jenna-fuseki additionally as it is not part of the docker container.     - Chose 2 to install everything on your directly on your system.</p> Option 1: Use docker <ul> <li>Install docker</li> <li>while in oeplatform directory <code>cd docker</code></li> <li><code>docker compose -f docker-compose.yaml</code></li> <li>start docker container</li> <li>Additionally install and start jenna-fuseki db as docker or install it locally.</li> </ul> Option 2: Manual database setup <ul> <li>install manually</li> </ul> <p>Summary:</p> <ul> <li>Setup databases PostgreSQL, Jenna-Fuseki</li> <li>Install &amp; start Jenna-Fuseki and create datastore <code>OEKG_DS</code> via the web interface: http://127.0.0.1:3030/</li> <li>Install PostgreSQL</li> <li>Use db user <code>postgres</code> with password <code>postgres</code>:</li> <li>Create databases: <code>oep_django</code>, <code>oedb</code>: <code>sudo -u postgres psql</code></li> <li>Install postgresql extensions <code>hstore</code>, <code>postgis</code>, <code>postgis_topology</code>, <code>pg_trgm</code></li> <li>Setup the connection to the database server to the Django project by adding the credentials in the <code>oeplatoform/securitysettings.py</code></li> </ul> </li> <li> <p>Run management commands to complete the database setup     - <code>python manage.py migrate</code>     - <code>python manage.py alembic upgrade head</code></p> Sept 3.1: Management commands: <p>These commands are most likely not relevant if you are setting up oeplatform for the first time. Use the following command to show a list of all available management commands.</p> <ul> <li><code>python manage.py -h</code></li> </ul> </li> <li> <p>Install react app</p> <ul> <li>Install node oder nvm on your system</li> <li>navigate into <code>factsheet/frontend</code> to install the scenario bundles</li> <li>navigate into the <code>oeo_viewer/client</code> to install the oeo viewer</li> <li>Run <code>npm install</code></li> <li>Navigate back <code>cd ../..</code> to oeplatform root</li> <li>Make sure the jenna-fuseki database is up and running locally</li> <li>Run management commands to install bot react apps     - <code>python manage.py build_factsheet_app</code>     - <code>python manage.py build_oeo_viewer</code></li> <li>Update the served javaScript bundle files in templates:     - <code>factsheet/static/js/main###.js</code> -&gt; <code>factsheet/template/index.html</code>     - <code>oeo_viewer/static/js/main###.js</code> -&gt; <code>oeo_viewer/template/index.html</code></li> </ul> </li> <li> <p>Deploy locally     - Check if the all connected database servers are running.         - sudo service postgresql start         - in the directory where you installed</p> <ul> <li><code>python manage.py runserver</code></li> <li>Open Browser URL: 127.0.0.1:8000</li> </ul> <ul> <li>create a test user.</li> </ul> </li> </ol>"},{"location":"installation/guides/installation/#0-prequisit","title":"0 Prequisit","text":"<p>The installation instructions mainly refer to the creation of a local instance of the oeplatform with a focus on the development or contribution to the software development on github. We use mainly linux and sometimes windows for development with python 3.10 currently (Python 3.12 is also tested with some tweaks in the requirements.txt). Before you start the installation look at this section and think about which operating system you want to use.</p> <p>Deploying the software on a server to make it publicly accessible via the Internet is a further step. Please get in touch as the deployment depends heavily on your server setup.</p>"},{"location":"installation/guides/installation/#notes-for-deployment","title":"Notes for deployment","text":"<p>We do not currently provide instructions for deployment. It also depends heavily on the server environment. In general, a web server (e.g. Apache) and a web server gateway for Python (e.g. mod_wsgi) are required to make the software available on the internet.</p>"},{"location":"installation/guides/installation/#1-setup-the-repository","title":"1 Setup the repository","text":"<p>Recommended: Create a directory to store the oeplatform code and additional resources.</p> <pre><code>mkdir oep-website\ncd oep-website\n</code></pre> <p>Clone the repository locally</p> <pre><code>git clone https://github.com/OpenEnergyPlatform/oeplatform.git\n</code></pre>"},{"location":"installation/guides/installation/#2-setup-virtual-environment","title":"2 Setup virtual environment","text":"<p>Navigate to the oeplatform directory you just cloned</p> <pre><code>cd oeplatform\n</code></pre> <p>Below we explain two methods to install the virtual environment for python.</p>"},{"location":"installation/guides/installation/#conda-on-windows","title":"Conda (on Windows)","text":"<p>If you are a Windows user, we recommend you use conda because of the dependency on the <code>shapely</code> package. It was causing installation issues that potentially have resolved. Don't forget to activate the environment after the setup is done.</p> <pre><code>conda env create -f environment.yml\nconda activate env\n</code></pre>"},{"location":"installation/guides/installation/#venv-on-linux-mac","title":"venv (on Linux / Mac)","text":"<p>If you are not using windows or don't want to use conda, here you can find instructions for setting up virtual environment. In short: You can also use Python to create the environment. Make sure you install the venv package for your python version. Don't forget to activate the environment.</p> <p>On linux you can use:</p> <pre><code>sudo apt install python3.xx-venv # change xx to your exact version\npython3 -m venv env\nsource env/bin/activate\n</code></pre>"},{"location":"installation/guides/installation/#install-requirements","title":"Install requirements","text":"<p>After you have activated your virtual environment, install the required python libraries</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"installation/guides/installation/#3-setup-the-openenergyontology-integration","title":"3 Setup the OpenEnergyOntology integration","text":""},{"location":"installation/guides/installation/#31-include-the-full-oeo","title":"3.1 Include the full oeo","text":"<p>It is necessary to include the source files of the OpenEnergyOntology (OEO) in this project. The goal is to have a new directory like you see below inside the oeplatform directory. The new folder should be stored alongside the django apps and other code related files.</p> <pre><code>```bash\nontologies/\n\u2514\u2500\u2500 oeo\n    \u2514\u2500\u2500 1.0.0 # in production this will be the version of a specific OEO release\n        \u251c\u2500\u2500 imports\n        \u251c\u2500\u2500 modules\n        \u2514\u2500\u2500 oeo-full.owl\n```\n</code></pre> <p>The directory where all ontologies are stored is called \"ontologies\". If you want to change the name of the directory you have to update the settings.py file for the oeplatform also. The following variables are relevant for the configuration of the ontology integration. In most cases, you can use the default settings.</p> <pre><code>ONTOLOGY_FOLDER # Name of the folder for all ontologies\nONTOLOGY_ROOT   # constructed Path for all ontologies\nOPEN_ENERGY_ONTOLOGY_NAME   # Name of the oeo\nOPEN_ENERGY_ONTOLOGY_FOLDER # constructed Path for the oeo directory\n</code></pre> <p>If you use the default naming \"ontologies\" you should create this directory. Then you can download the full oeo release from GitHub and unzip them into the new directory. To validate you can check whether you can find the file \"oeo-full.owl\". Please ensure, that you get the structure shown above.</p>"},{"location":"installation/guides/installation/#4-loading-and-compressing-static-assets-from-the-oeplattform-applications","title":"4 Loading and compressing static assets from the Oeplattform applications","text":"<p>Static data is often stored in the django apps and various additional scripts are loaded, e.g. in HTML files. To enable django to access these resources more efficiently, various management commands are used to collect and partially compress the relevant files.</p> <p>To be able to run the commands below we first need to Setup the security settings file for local development. This file is specific to your local settings. In production environment it is used to store / retrieve critical information that must not be pushed to any publicly available source control system like GitHub.</p> <ul> <li>Navigate to <code>oeplatform/oeplatform</code></li> <li>copy the file <code>securitysettings.py.default</code> and rename it to   <code>securitysettings.py</code></li> </ul> How to configure securitysettings.py <p>The security settings provide information to django to connect to your databases, relevant for step 5, below. You can provide the access credentials directly in the script or import them using environment variables. For detailed instructions see section 3. of the manual database setup guide.</p> <p>After the above setup is done make sure the python environment is activated and then run:</p> <pre><code>python manage.py collectstatic\npython manage.py compress\n</code></pre>"},{"location":"installation/guides/installation/#5-databases-setup","title":"5 Databases setup","text":"<p>We use two relational databases to store the oeplatform data:</p> <ul> <li>The oep-django database is our internal database. It is used to store the   django application related data. This includes things like user information,   reviews, table names, ...</li> <li>Our primary database is the OEDB (Open Energy Database). It is used to store   all data the user uploaded. In production it stores multiple terabyte of data.</li> </ul> <p>Additional we use a triple store database:</p> <ul> <li>Store the open energy ontologies and open energy knowledge graph</li> <li>For now this is not part of the installation guide as it is not mandatory to   run the oeplatform and can be added later.</li> </ul>"},{"location":"installation/guides/installation/#51-how-to-install-the-databases","title":"5.1 How to install the databases","text":"<p>You can install the database and connect it to django as you like. Note that we currently use PostgreSQL version 14.</p> <p>Below we offer our best practice to setup the databases. You have two options to install the databases:</p>"},{"location":"installation/guides/installation/#a-install-the-database-manually","title":"a) Install the database manually","text":"<ul> <li>You chose to install the databases manually by installing PostgreSQL &amp;   jenna-fuseki and complete the setup. In this case you can follow our   manual database setup guide.</li> <li>Using this option you will install the jenna-fuseki &amp; postgresql databases on   your local system. You need to start both databases manually before you can   start using them for development.</li> </ul>"},{"location":"installation/guides/installation/#b-use-our-docker-image","title":"b) Use our docker image","text":"<ul> <li>You can also use our docker based installation to install a container which   will automatically setup the two databases. You still have to install docker   on your system.   Here you can find instructions on how to install the docker images.</li> <li>The jenna-fuseki triple store is not part of the docker image so far. You   would either have to setup the public docker image here and adjust the   credentials in the <code>securitysettings.py</code> or you can perform the steps   explained in   Section 1.2 of the manual database setup   to install the jenna-fuseki database on your system. You will have to start   the service manually afterwards.</li> </ul>"},{"location":"installation/guides/installation/#52-create-the-database-table-structures","title":"5.2 Create the database table structures","text":"<p>Before you can start development, you need to setup tables in the two PostgreSQL databases. To do this, you can run two management commands. The django command will set up all structures required by the oep system in the oep_django database and the alembic command will create all the structures in the OEDB. These structures define how large amounts of uploaded user data is stored in the database. On a high level this is similar to partitions on you personal computer. This structure help's the developers and the system to find the data and group data together.</p> <p>First verify that your database service is running. In case you are using docker start the container. If you installed postgresql locally start the service. On Linux you can use the following command in the terminal:</p> <pre><code>sudo service postgresql start\n</code></pre>"},{"location":"installation/guides/installation/#521-django-setup-oep_django","title":"5.2.1 Django setup - oep_django","text":"<p>In order to run the OEP website, the django database needs some extra management tables. We use the django specific migrations. Each django app defines it own migrations that keep track of all changes made to any app related tabes. The table structure itself is defined as an abstraction in the models.py for each django app.</p> <pre><code>python manage.py migrate\n</code></pre>"},{"location":"installation/guides/installation/#522-alembic-setup-oedb","title":"5.2.2 Alembic setup - oedb","text":"<p>In order to run the OEP website, the primary database needs some extra management tables. We use <code>alembic</code> to keep track of changes to the general structure of the primary database and its initial state e.g. what tables should be there and more. To create all tables that are needed, simply type:</p> <pre><code>python manage.py alembic upgrade head\n</code></pre> <p>Note</p> <p>If you encounter errors in this step verify that your database service is available, the databases <code>oep_django</code> and <code>oedb</code> exist and your <code>securitysettings.py</code> provide the correct access credentials.</p>"},{"location":"installation/guides/installation/#6-install-the-openenergyontology-tools","title":"6 Install the OpenEnergyOntology tools","text":"<p>Only start the following steps if you have completed step 3 above.</p>"},{"location":"installation/guides/installation/#61-setup-the-oeo-viewer-app","title":"6.1 Setup the OEO-viewer app","text":"<p>Optional Step</p> <p>This step is not mandatory to run the oeplatform-core as it is a plug able React-App. If you don't include this step you can access the oeplatform website including most ontology pages except for the oeo-viewer.</p> <p>The oeo-viewer is a visualization tool for our OEO ontology and it is under development. To be able to see and use the oeo-viewer as part of the oep-website, follow the steps below:</p> <ol> <li>Install npm: To install npm it is suggested to use the node version manager.<ul> <li>On Linux &amp; Mac: Node Version Manager (nvm)</li> <li>On Windows: NVM for Windows.</li> <li>Install node version 18</li> </ul> </li> <li> <p>Get the ontology files (see    Section 3)</p> </li> <li> <p>Build the oeo-viewer:    <pre><code>cd oep-website/oeplatform/oeo_viewer/client\nnpm install\nnpm run build\n</code></pre></p> </li> </ol> <p>After these steps, a <code>static</code> folder inside <code>oep-website/oeplatform/oeo_viewer/</code> will be created which includes the results of the <code>npm run build</code> command. These files are necessary for the oeo-viewer.</p>"},{"location":"installation/guides/installation/#62-setup-the-oeo-extended-app","title":"6.2 Setup the oeo extended app","text":"<p>The oeo extended is used to create new ontology classes on the fly while annotating a oemetadata document. Especially if one wants to annotate composed units which are more complex than a simple meter or square meter unit. These composed units are stored separate from the OEO ontology in the OEOX which is located in its own owl file.</p> <p>The use case described above requires to setup the oeo extended template file in the <code>media/</code> directory. We offer a template file to simplify this task.</p> <pre><code>cp oeo_ext/oeo_extended_store/oeox_template/oeo_ext_template_empty.owl  media/oeo_ext/oeo_ext.owl\n</code></pre>"},{"location":"installation/guides/installation/#7-setup-the-scenario-bundles-app","title":"7 Setup the Scenario-Bundles app","text":"<p>Optional Step</p> <p>This step is not mandatory to run the oeplatform-core as it is a plug able React-App. If you don't include this step you can access the oeplatform website except scenario-bundle pages including the scenario-comparison React modules.</p> <p>In the django app directory <code>oeplatform/factsheet</code> we provide a Web-API to access the OEKG and the Scenario-Bundle feature. Similar to the oeo-viewer we need to use npm to install &amp; build the Scenario-Bundle app and integrate the build in the django app.</p> <ol> <li>Make sure npm is installed.</li> <li> <p>Start the jenna-fuseki database (see    instructions from the    installation). The connection to the database API is setup in the    factsheet/views.py you have to make sure that you provide the correct URL to    you database instance. In development mode it should be something like:</p> <pre><code>query_endpoint = 'http://localhost:3030/ds/query'\nupdate_endpoint = 'http://localhost:3030/ds/update'\n</code></pre> </li> <li> <p>Configure the React app</p> <p>To be able to construct the API URLS that are necessary for communication  between the react frontend and the django backend in the react code we have  to configure the URL where our django application is available. In  development mode this should be http://127.0.0.1:8000/, so add the line  <code>\"toep\": \"http://127.0.0.1:8000/\"</code> to <code>factsheet/frontend/src/conf.json</code>.</p> </li> <li> <p>Build the scenario bundle app:</p> <pre><code>cd factsheet/frontend\nnpm install\ncd ../..\n# Use the django management command\npython manage.py build_factsheet_app\n</code></pre> </li> <li> <p>Serve the React build on a django website</p> <p>To serve the React build on a website that is provided by django you have to  include the build files from the <code>factsheet/static</code> directory in the django  template in <code>factsheet/templates/index.html</code>. In the HTML-template you must  make sure that the JavaScript bundle file is imported. The name of the file  changes after each new build and it should read like <code>main.5654a0e0.js</code>.</p> <p>The template should then include this line:</p> <pre><code>&lt;script src=\"{% static 'factsheet/js/main.55586e26.js' %}\"&gt;&lt;/script&gt;\n</code></pre> </li> </ol>"},{"location":"installation/guides/installation/#next-steps","title":"Next steps","text":"<p>Have a look at the steps described in the Development &amp; Collaboration section.</p>"},{"location":"installation/guides/manual-db-setup/","title":"Complete manual database setup","text":"<p>Below we describe the complete manual installation of the OpenEnergyPlatform database infrastructure, which is currently composed by multiple databases:</p> <ol> <li> <p>PostgreSQL</p> <ul> <li>Internal django database (oep_django)</li> <li>as well as the primay database OpenEnergyDatabase (oedb)</li> </ul> </li> <li> <p>Apache Jena Fuseki</p> <ul> <li>and a SPARQL server for the OEKG</li> <li>requires java</li> </ul> </li> </ol>"},{"location":"installation/guides/manual-db-setup/#1-install-the-database-infrastructure","title":"1 Install the database infrastructure","text":"<p>To setup the PostgreSQL database on your own machine you have to install the database software and setup additional packages. After the databases are installed you have to create the database tables that are already available as data model in the oeplatform code project. There we maintain the tables as python classes called models. You will use django and alembic to create these table automatically.</p>"},{"location":"installation/guides/manual-db-setup/#11-install-postgresql","title":"1.1 Install postgresql","text":"<p>If postgresql is not installed yet on your computer, you can follow this guide.</p> <p>Using linux it is most likely already installed. But you can use the following command to install it.</p> <pre><code>sudo apt-get update\nsudo apt-get upgrade\nsudo apt-get install postgresql\n</code></pre> <p>During the installation, make sure that you note the superuser and password. Other relevant details are the host and the port, these will most likely be set to the default value. In the oeplatoform default configuration the values are:</p> <ul> <li>Host <code>127.0.0.1</code> or <code>localhost</code>.</li> <li>Port <code>5432</code></li> </ul> <p>For the creation of spatial objects we use the PostGIS plugin for PostgreSQL. On linux you can use:</p> <pre><code>sudo apt update\nsudo apt upgrade\nsudo apt install postgresql-14-postgis-3\n\n# might be relevant in some cases:\n# sudo apt-get install bin utils libproj-dev gdal-bin\n</code></pre> How to get PostGIS <p>PostGIS is a plugin for PostgreSQL and must be installed additionally. If you use an installation wizard, this step is probably included in the general PostgreSQL installation.</p> <ul> <li>On Windows, We recommend installing the postgis for your local PostgreSQL installation from Application Stack Builder under <code>Spatial Extensions</code>. There should automatically be an entry for <code>PostGIS bundle ...</code> based on the installed version of PostgreSQL, please make sure it is checked and click next. The stack builder will then continue to download and install PostGIS. Alternately PostGIS can also be downloaded from this official ftp server by PostgreSQL. Proceed to install the package. (Flag it as safe in the downloads if prompted, and select Run anyway from the Windows SmartScreen Application Blocked Window)</li> </ul> <ul> <li>On Linux/Unix based systems the installation could be specific to the package manager being employed and the operating system, so please refer to the official installation instructions here. The section <code>Binary Installers</code> covers the installation instructions for various operating systems.</li> </ul> <p>After the installation completed you can start the service. On linux you can simply run:</p> <pre><code>sudo service postgresql start\n</code></pre>"},{"location":"installation/guides/manual-db-setup/#12-install-apache-jena-fuseki","title":"1.2 Install Apache Jena Fuseki","text":"<p>Note</p> <ul> <li>Skip the installation if your development task is not aimed at the OEKG.</li> <li>For more information about Apache Jena Fuseki please visit this page.</li> <li>Note that java is required to run the software</li> </ul> <ol> <li>Download     apache-jena-fuseki-4.2.0.tar.gz     (for other versions please check here)</li> <li>Create a new directory on your system where you install oeplatform     infrastructure components e.g. <code>~/oep-infra/</code> as alternative you can use the     jenna-fuseki db via docker container. In this case you need to specify the     correct credentails for that container in the <code>securitysettings.py</code> (See     Step 3.)</li> <li> <p>Extract the downloaded file to the new directory e.g.:</p> <pre><code>  tar -zxvf apache-jena-fuseki-4.2.0.tar.gz -C ~/oep-infra/\n</code></pre> </li> <li> <p>Navigate to the directory where the files are extracted and execute the     following command to start the server:</p> <pre><code>  ./fuseki-server\n</code></pre> </li> <li> <p>To access the server UI, enter <code>http://localhost:3030/</code> in your web browser.</p> </li> <li>First click the manage datasets tab and then choose the add new     dataset.</li> <li>Enter <code>OEKG_DS</code> for the dataset name and choose the type of dataset     (in-memory datasets do not persist if the server stops) and click create     dataset.</li> </ol>"},{"location":"installation/guides/manual-db-setup/#2-create-the-postgresql-databases","title":"2 Create the PostgreSQL databases","text":"<p>As you dont have to setup the graph databse to run most parts of the oeplatform application and the PostgreSQL databases are mandatory for the core functionality of the oeplatform we start to setup the oep_django and oedb databases on our local PostgreSQL server.</p>"},{"location":"installation/guides/manual-db-setup/#21-django-internal-database","title":"2.1 Django internal database","text":""},{"location":"installation/guides/manual-db-setup/#211-posgresql-command-line-setup","title":"2.1.1 Posgresql command line setup","text":"<p>Once logged into your psql session from your terminal</p> <ul> <li>for linux: <code>sudo -u postgres psql</code></li> <li>for windows: <code>psql</code></li> </ul> <p>then run the following lines to first set the database password as it will ease the further steps:</p> <pre><code>ALTER USER postgres WITH PASSWORD 'postgres';\n</code></pre> <p>and then create the database:</p> <pre><code># optional: .. with owner = postgres;\ncreate database oep_django;\n</code></pre>"},{"location":"installation/guides/manual-db-setup/#22-primary-database","title":"2.2 Primary Database","text":"<p>This database is used for the data input functionality implemented in <code>database/</code>.</p> <p>If this is your first local setup of the OEP website, this database should be an empty database as it will be instantiated by automated scripts later on.</p>"},{"location":"installation/guides/manual-db-setup/#221-posgresql-command-line-setup","title":"2.2.1 Posgresql command line setup","text":"<p>Once logged into your psql session from your terminal</p> <ul> <li>for linux: <code>sudo -u postgres psql</code></li> <li>for windows: <code>psql</code></li> </ul> <p>Then you run the following lines to create the primary database:</p> <pre><code># optional: .. with owner = postgres;\ncreate database oedb;\n</code></pre>"},{"location":"installation/guides/manual-db-setup/#23-install-database-extensions-on-both-databases","title":"2.3 Install database extensions on both databases","text":"<p>After successfully installing PostGIS (see step 1.1), add the database extensions. We keep both database setups equal please enter the commands to both databases.</p> <p>Make sure you connect to psql</p> <pre><code>for linux: `sudo -u postgres psql`\nfor windows: `psql`\n</code></pre> <p><code>oedb</code> (<code>\\c oedb;</code>) then create extensions.</p> <p><code>oep_django</code> (<code>\\c oep_django;</code>) then create extensions also here.</p> <p>After you connected type the commands below and repeat for both of the databases:</p> <pre><code>CREATE EXTENSION IF NOT EXISTS postgis;\nCREATE EXTENSION IF NOT EXISTS postgis_topology;\nCREATE EXTENSION IF NOT EXISTS hstore;\n# This extension enable search for similar objects (e.g. by name)\nCREATE EXTENSION IF NOT EXISTS pg_trgm;\n</code></pre> <p>The database installation is now complete and you can exit the psql command line by typing:</p> <pre><code>\\q\n</code></pre>"},{"location":"installation/guides/manual-db-setup/#3-connect-database-to-the-django-project","title":"3 Connect database to the Django project","text":"<p>In the oeplatform repository, copy the file <code>oeplatform/securitysettings.py.default</code> and rename it <code>oeplatform/securitysettings.py</code>. Then, enter the connection to your above mentioned postgresql database.</p>"},{"location":"installation/guides/manual-db-setup/#31-store-and-access-database-credentials","title":"3.1 Store and access database credentials","text":"<p>To setup the connection in the oeplatform project you can either setup environment variables that store the database connection credentials locally on your system or you can change the default value in the securitysetting. For production systems it is recommended to use the concept of environment variables.</p> <p>Note</p> <p>You have to provide the user name and password (with access to the oep_django and oedb database). Additionally you can configure the database name and the host and port variables if you don't run the database server using the default values.</p>"},{"location":"installation/guides/manual-db-setup/#311-oep_django-internal-database","title":"3.1.1 oep_django internal database","text":"<p>In the oeplatform/securitysettings.py file enter the database connection details in this section:</p> <p>Info</p> <p>This code will attempt to collect the value from a environment variable in case it is not available the fallback value is used.</p> <p><code>'NAME': os.environ.get(\"OEP_DJANGO_NAME\", \"oep_django\")</code></p> <pre><code># oeplatform/securitysettings.py\n\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql_psycopg2',\n        'NAME': os.environ.get(\"OEP_DJANGO_NAME\", \"oep_django\"),\n     'USER': os.environ.get(\"OEP_DJANGO_USER\", \"postgres\"),\n     'PASSWORD': os.environ.get(\"OEP_DJANGO_PW\", \"postgres\"),\n     'HOST': os.environ.get(\"OEP_DJANGO_HOST\", \"localhost\")\n }\n}\n</code></pre> Setup environment variables <p>Create environment variables <code>OEP_DJANGO_USER</code> and <code>OEP_DJANGO_PW</code> with values <code>oep_django_user</code> and <code>&lt;oep_django_password&gt;</code>, respectively.</p> environment variable required OEP_DJANGO_USER yes OEP_DJANGO_PW yes OEP_DJANGO_HOST no OEP_DJANGO_NAME no <p>For default settings, you can type the following commands</p> <ul> <li> <p>On windows We recommend you set the environment variables via menus. However, we still provide you with the terminal commands (before you can set environment variables in your terminal you should first type <code>cmd/v</code>).</p> <pre><code>set OEP_DJANGO_USER=oep_django_user\nset OEP_DJANGO_PW=&lt;oep_django_password&gt;\n</code></pre> </li> </ul> <p>In the following steps we'll provide the terminal commands but you always can set the environment variables via menus instead.</p> <ul> <li> <p>On linux</p> <pre><code>export OEP_DJANGO_USER=oep_django_user\nexport OEP_DJANGO_PW=&lt;oep_django_password&gt;\n</code></pre> </li> </ul>"},{"location":"installation/guides/manual-db-setup/#312-oedb-primary-database","title":"3.1.2 oedb primary database","text":"<p>In the oeplatform/securitysettings.py file enter the database connection details in this section:</p> <pre><code># oeplatform/securitysettings.py\n\ndbuser = os.environ.get(\"LOCAL_DB_USER\", \"postgres\")\ndbpasswd = os.environ.get(\"LOCAL_DB_PASSWORD\", \"postgres\")\ndbport = os.environ.get(\"LOCAL_DB_PORT\", 5432)\ndbhost = os.environ.get(\"LOCAL_DB_HOST\", \"localhost\")\ndbname = os.environ.get(\"LOCAL_DB_NAME\", \"oedb\")\n</code></pre> Setup environment variables environment variable required LOCAL_DB_USER yes LOCAL_DB_PASSWORD yes LOCAL_DB_PORT no LOCAL_DB_HOST no LOCAL_DB_NAME no <p>Make sure to set the required environment variables before going to the next section!</p> <p>For default settings, you can type the following commands</p> <ul> <li> <p>On windows</p> <pre><code>set LOCAL_DB_USER=oedb_user\nset LOCAL_DB_PASSWORD=&lt;oedb_password&gt;\nset LOCAL_DB_NAME=oedb\n</code></pre> </li> </ul> <ul> <li> <p>On linux</p> <pre><code>export LOCAL_DB_USER=oedb_user\nexport LOCAL_DB_PASSWORD=&lt;oedb_password&gt;\nexport LOCAL_DB_NAME=oedb\n</code></pre> </li> </ul> <p>Tip</p> <p>If you kept the default name from the above example in 2.1, then the environment variables <code>LOCAL_DB_USER</code> and <code>LOCAL_DB_NAME</code> should have the values <code>oedb_user</code> and <code>oedb</code>, respectively.</p>"},{"location":"installation/guides/manual-db-setup/#4-create-the-database-tables","title":"4 Create the database tables","text":"<p>To complete the database installation, the table structures must then be installed. Step 3 &amp; Step 4 must be completed first so that the necessary commands can be executed after.</p> <p>After that Proceed with the next steps in section 4.2 Create the database table structures of the oeplatform installation guide.</p>"},{"location":"installation/guides/nodejs/","title":"JavaScript integration","text":"<p>Note</p> <p>The information provided here is only relevant if you encounter issues in the vite (nodejs) setup. During development the javascript server is running automatically and in production only a bundled version of the code is shipped which keeps the production environment clean.</p> <p>We integrate nodejs into the django project to support JavaScript and enhance developer experience, enhance consistency for JavaScript modules and more.</p>"},{"location":"installation/guides/nodejs/#benefits","title":"Benefits","text":"<ul> <li>HotModuleReplacing (HMR)   which is one of the main benefits for development as devs can write and see   the results of code changes in JavaScript code much faster.</li> </ul> <ul> <li>Dependency resolving &amp; Pre-Bundling</li> </ul> <ul> <li>Option to go for type script</li> </ul> <ul> <li>Enables us to get npm packages</li> </ul>"},{"location":"installation/guides/nodejs/#build-tool","title":"Build tool","text":"<p>Currently we not 100% set on what build tool we will role out for all parts of the oeplatform apps. Webpack is a proven and more complicated to setup tool while vite seems to be less overhead and supports all our needs also. That is why we opt for vite for now and test it for current development tasks.</p>"},{"location":"installation/guides/nodejs/#setup-integration","title":"Setup Integration","text":"<p>To setup vite we follow https://github.com/MrBin99/django-vite.</p> <p>We will have to install the pypi package, update requirements.txt, modify django settings and add django-vite to base templates and specific tags to react templates.</p> <p>To setup the javascript server we have to create and configure <code>vite.config.mjs</code> config file for the vite server and initiate a npm project creating and maintaining a <code>package.json</code>. This sets up java script for the whole django project, but also requires devs to set this up until we offer a docker image which will automate this process. Once the npm environment is setup we must run <code>npm install</code> and make sure vite is installed as well as the vite-react plugin is added (see the vite getting started guide).</p>"},{"location":"installation/guides/nodejs/#integration-status","title":"Integration status","text":"<p>The following apps integrate:</p> <ul> <li>Webpack<ul> <li>oeo-viewer</li> <li>factsheet (also supported by vite integration)</li> </ul> </li> </ul> <ul> <li>Vite<ul> <li>Open peer review (dataedit js client)</li> <li>factsheet (scenario bundles react client)</li> </ul> </li> </ul> <ul> <li>None so far<ul> <li>MetaBuilder (dataedit js client)</li> </ul> </li> </ul>"},{"location":"installation/guides/setuo-ontop/","title":"Setup ontop service","text":"<p>The ontop service is mainly use as enabling technology for the quantitative scenario comparison as it enables SPARQL queries on SQL databases using semantic mappings ontop on the \"normal\" sql like table definition.</p>"},{"location":"installation/guides/setuo-ontop/#installation","title":"Installation","text":"<p>We offer the pre-configured ontop service as part of the OEP-docker setup for development. It comes with a empty semantic mapping template which can be extended based on the user needs. You still need to download the JDBC database driver to enable connection to the postgresql database OEDB.</p> <p>Once you downloaded the driver make sure it is available in the ontop config directory and only then build the ontop service using docker.</p> <p>Download the database JDBC driver for ontop:</p> <ul> <li>https://jdbc.postgresql.org/</li> </ul> <p>Add the file postgresql.jar to this directory.</p>"},{"location":"oeplatform-code/","title":"Index","text":""},{"location":"oeplatform-code/#code-documentation","title":"Code Documentation","text":"<p>Welcome to the software documentation of the oeplatform project. Here you can find specific information about the software architecture, its user features &amp; the WEB-APIs for programmatic access to the features.</p>"},{"location":"oeplatform-code/apps/","title":"oeplatform django apps","text":"<p>In this section we document the oeplatform applications. As we not yet migrated the architecture to a more commonly used one we maintain all apps in the root django project directory. This impacts how we apply settings as configuration to the whole system. Each App implements a specific group of features to provide solutions to certain user needs. We implement the apps to provide very specific tool to all users and encourage them to upload and document their data. This approach reflects our vision to continually publish our research work results as publicly usable functionality. This requirement we set ourself often brings a lot of extra effort as usability must also be prioritized. This correctly suggests that each app also maintains a user interface and possibly also some app specific data is stored in the django database.</p>"},{"location":"oeplatform-code/apps/login/","title":"Login","text":"<p>This app handles the user authentication using django allauth and implements a user profile that provide an overview on tables and helps to manage the datasets draft or published state. Additionally the profile pages include the permission groups to manage data table resource access permissions as group with other users. The last feature is the user profile, including a view showing the api token with functionality to reset it as well as a Form to provide additional user data like adding a user image.</p>"},{"location":"oeplatform-code/apps/login/#setup","title":"Setup","text":"<p>First make sure to install django allauth package and install it into the existing project:</p> <ul> <li> <p>install latest requirements.txt in the python environment</p> <p><code>pip install -r requirements.txt</code></p> </li> </ul> <ul> <li> <p>run python migrations to setup the new django allauth models (tables)</p> <p><code>python manage.py migrate</code></p> </li> </ul> <ul> <li>check your iptables setting on the server to enable server to server   connection using the service static ip address. Don`t forget to restart the   iptables service to apply the updates.</li> </ul> <p>Now edit your securitysettings.py and update it with the content form the securitysettings.py.default template file to setup the social provider used for 3rd Party Login flow. We use openIDConnect that is implemented by django allauth:</p> <p>Note</p> <p>Filling out the values in the dictionary depends on your Provider. They should provide documentation or provide you with the relevant credentials. In some cases the provider_id must be in line with the specification of the provider in others you can choose your own name here. The client_id &amp; secret should also be provided as well as the server_url.</p> <pre><code>SOCIALACCOUNT_PROVIDERS = {\n    \"openid_connect\": {\n        # For each OAuth based provider, either add a ``SocialApp``\n        # (``socialaccount`` app) containing the required client\n        # credentials, or list them here:\n        \"APPS\": [{\n            \"provider_id\": \"\",\n            \"name\": \"\",\n            \"client_id\": \"\",\n            \"secret\": \"\",\n            \"VERIFIED_EMAIL\": True,\n            \"EMAIL_AUTHENTICATION\": True,\n            \"settings\": {\"server_url\": \"\"},\n        }]\n    }\n}\n</code></pre>"},{"location":"oeplatform-code/apps/login/#app-components","title":"App Components","text":"<p>The components of each app implement the django app structure and implement a MVVM pattern for web applications. This includes the files model.py, views.py, urls.py, Then there are migrations that specify the django table structure and is also a core django feature. The templates include all HTML page payouts including django template syntax to render pages with dynamic server data and JavaScript. Additionally there might be other folders and python modules available.w</p>"},{"location":"oeplatform-code/apps/login/#views","title":"Views","text":"<p>EditUserView ::: login.views</p>"},{"location":"oeplatform-code/apps/login/#forms","title":"Forms","text":"<p>3rd party Signup ::: login.forms.UserSocialSignupForm</p> <p>Default Signup ::: login.forms.CreateUserForm</p> <p>Edit existing user data ::: login.forms.EditUserForm</p>"},{"location":"oeplatform-code/apps/login/#adapters","title":"Adapters","text":"<p>SPDX-FileCopyrightText: 2024 Jonas Huber https://github.com/jh-RLI \u00a9 Reiner Lemoine Institut SPDX-License-Identifier: AGPL-3.0-or-later</p>"},{"location":"oeplatform-code/apps/login/#login.adapters.AccountAdapter","title":"<code>AccountAdapter</code>","text":"<p>               Bases: <code>DefaultAccountAdapter</code></p> <p>Handles default logins</p> Source code in <code>login/adapters.py</code> <pre><code>class AccountAdapter(DefaultAccountAdapter):\n    \"\"\"\n    Handles default logins\n    \"\"\"\n\n    def is_open_for_signup(self, request: HttpRequest) -&gt; bool:\n        return settings.ACCOUNT_ALLOW_REGISTRATION\n</code></pre>"},{"location":"oeplatform-code/apps/login/#login.adapters.SocialAccountAdapter","title":"<code>SocialAccountAdapter</code>","text":"<p>               Bases: <code>DefaultSocialAccountAdapter</code></p> <p>Handles logins via 3rd party organizations like ORCID.</p> Source code in <code>login/adapters.py</code> <pre><code>class SocialAccountAdapter(DefaultSocialAccountAdapter):\n    \"\"\"\n    Handles logins via 3rd party organizations like ORCID.\n    \"\"\"\n\n    def is_open_for_signup(\n        self, request: HttpRequest, sociallogin: SocialLogin\n    ) -&gt; bool:\n        return settings.ACCOUNT_ALLOW_REGISTRATION\n\n    def populate_user(\n        self,\n        request: HttpRequest,\n        sociallogin: SocialLogin,\n        data: dict[str, typing.Any],\n    ) -&gt; User:\n        \"\"\"\n        Populates user information from social provider info.\n\n        See: https://django-allauth.readthedocs.io/en/latest/advanced.html?#creating-and-populating-user-instances # noqa\n        \"\"\"\n        provider = sociallogin.account.provider\n\n        # Specific modifications for the RegApp context data.\n        # Provider name must be the same as in securitysettings.\n        if provider == \"RegApp\":\n            name = data.get(\n                \"name\"\n            )  # NOTE: Consider to add random user name if not available\n            first_name = data.get(\"given_name\")\n            last_name = data.get(\"given_name\")\n            new_data = data\n            new_data[\"username\"] = name\n            new_data[\"first_name\"] = first_name\n            new_data[\"last_name\"] = last_name\n\n        return super().populate_user(request, sociallogin, data)\n</code></pre>"},{"location":"oeplatform-code/apps/login/#login.adapters.SocialAccountAdapter.populate_user","title":"<code>populate_user(request, sociallogin, data)</code>","text":"<p>Populates user information from social provider info.</p> <p>See: https://django-allauth.readthedocs.io/en/latest/advanced.html?#creating-and-populating-user-instances # noqa</p> Source code in <code>login/adapters.py</code> <pre><code>def populate_user(\n    self,\n    request: HttpRequest,\n    sociallogin: SocialLogin,\n    data: dict[str, typing.Any],\n) -&gt; User:\n    \"\"\"\n    Populates user information from social provider info.\n\n    See: https://django-allauth.readthedocs.io/en/latest/advanced.html?#creating-and-populating-user-instances # noqa\n    \"\"\"\n    provider = sociallogin.account.provider\n\n    # Specific modifications for the RegApp context data.\n    # Provider name must be the same as in securitysettings.\n    if provider == \"RegApp\":\n        name = data.get(\n            \"name\"\n        )  # NOTE: Consider to add random user name if not available\n        first_name = data.get(\"given_name\")\n        last_name = data.get(\"given_name\")\n        new_data = data\n        new_data[\"username\"] = name\n        new_data[\"first_name\"] = first_name\n        new_data[\"last_name\"] = last_name\n\n    return super().populate_user(request, sociallogin, data)\n</code></pre>"},{"location":"oeplatform-code/apps/login/#models","title":"Models","text":"<p>The user manager that handles oeplatform users and their system role ::: login.models.OEPUserManager</p> <p>The user model of a oeplatform user ::: login.models.myuser</p>"},{"location":"oeplatform-code/architecture/","title":"Index","text":""},{"location":"oeplatform-code/architecture/#architecture","title":"Architecture","text":"<p>This section provides the necessary information to gain a basic technical understanding of the oeplatform software system, in particular the physical scheme of the hardware and software distribution, all modules of the software and the code project structure.</p> <p>Visit Infrastructure to lean about how we describe out hardware and software modules, the distribution and general interfaces that are implemented to drive the oeplatform software.</p> <p>Read oeplatform Modules and Software Project to learn about how we organize the code and project tools to enable our software development practice. This overview can be used if you want to start getting involved in the oeplatform development on GitHub.</p>"},{"location":"oeplatform-code/architecture/infrastructure/","title":"Infrastructure","text":""},{"location":"oeplatform-code/architecture/infrastructure/#infrastructure-service-architecture","title":"Infrastructure &amp; Service Architecture","text":"<p>In summary, the architecture is made up of various technologies that are installed on several servers.The individual servers each take on a specific responsibility in order to guarantee the functional scope of the open energy platform. As shown, the individual elements communicate via defined interfaces either via the internet (http) or in the internal network (TCP/IP).</p> <p>Basically, the OpenEnergyPlatform is a monolithic application as the functional core is developed together in a code base for frontend and backend. The application logic, database structure, web APIs and user interface are thus provided in the production system.</p> <p>In the course of development, more modern architectures were introduced, which are shown as services in the illustration. The LOEP service performs a specific task for which a user sends data to the service interface. The service has its own backend that processes the data and returns a suitable response. This architecture makes the system more modular.</p> <p>The database layer is always close to the applications and provides fast data access for the application via the internal network. In addition to application data such as user accounts, which are stored in the OEP Django database, there is the OEDB, which manages large amounts of data uploaded by users. The OEKB serves as a database for storing complex data. This involves data that has many attributes and relationships and is stored in the form of data triples. This enables high-performance and complex semantic data queries.</p> <p>The entire productive system and the databases are replicated in a test environment. Here, new versions of the software are installed before the official release and can be tested under real conditions.</p> <p>Note</p> <p>The diagram shows the software architecture of openenergyplatform.org.</p> <p></p>"},{"location":"oeplatform-code/architecture/infrastructure/#technologies","title":"Technologies","text":"<p>Out technology stacks describes the inventory of all larger software libraries or frameworks we currently implement in the infrastructure of the OpenEnergyPLatform. The oeplatform website project does not implement all of these technologies directly as some are developed as service meaning that the software runs independently form the oeplatform but these services offer a specific functionality that is required by some of the oeplatforms use cases / features.</p> <p>The \"oeplatform\" project depends on the these technologies:</p> <ul> <li>Python (Version 3.10)</li> <li>Django (version 5.1, Webframework)</li> <li>Django rest framework (WEB-API)</li> <li>django-allauth (login / registration / SSO)</li> <li>SQLAlchemy (Primary-Database access)</li> <li>Postgresql (version 15, database)</li> <li>sparqlWrapper, RDFLib, owlready2 (Ontology &amp; OEKG access)</li> </ul> <p>Below the services of the oeplatform are named and it is shown on which technologies they depend:</p> <p>Lookup-OEP (LOEP) This service implements a semantic search for the contents of the OpenEnergyOntology. It is used to implement the Ontological Annotation and can be used in the GUI for the oeplatforms \"metaBuilder\" feature. It enables a core use-case of the oeplatform website as it implements the first step of the quantitative scenario comparison.</p> <ul> <li>Java</li> <li>Apache Lucence</li> <li>Ontology file</li> </ul> <p>Open Energy Knowledge Graph (OEKG) It is a triple store that is persistent and is extended constantly based on user input. User of the oeplatform add data to the triple store when they create or extend Scenario Bundles via the website. The services itself offer an API to search &amp; update data to its database.</p> <ul> <li>Apache Jenna-Fuseki</li> </ul> <p>OEVKG This service is part of the scenario comparison that is implemented in the scenario bundles feature on the oeplatform. It enables ontology based data access by using a virtual knowledge graph based on a sematic mapping. The base for the semantic mapping is provided by the user when doing the ontological annotation of data resources mentioned in the Lookup-OEP service above.</p> <ul> <li>Java</li> <li>Ontop-VKG</li> </ul> <p>Databus A metadata registry implementing data management functionality needed by the oeplatform. The databus enables a advanced semantic search across all table resources on the OEP-Website and also its metadata. Additionally it enables storing data sources in groups, create version and collections of multiple unrelated data resources and more. It offers API\u00b4s which are used by the oeplatform to interact with the databus.</p> <ul> <li>Java</li> <li>Virtuoso</li> </ul> <p>MOSS .....</p>"},{"location":"oeplatform-code/architecture/modules/","title":"oeplatform Modules","text":""},{"location":"oeplatform-code/architecture/modules/#modules-of-the-oeplatform-software","title":"Modules of the oeplatform software","text":"<p>This section describes the modules of the oeplatoform website software. As we use django modules are also called apps. Each modules describes a django app that provides all the backend functionality as well as the user interface for a specific area of the website.</p>"},{"location":"oeplatform-code/architecture/modules/#overview","title":"Overview","text":"<p>Each module represents a Django App and includes a specific functionality or area of the Open Energy Platform Website.</p> Module Function oeplatform - Configuration of the Django application- Security-critical configuration such as connection data to a database base - Basic structure for homepage and views in other components- Mainly static content for textual description of OEP and research projects- Contact form- Legal information api - Provision of the RESTful API- Data management- Generic and specific data queries using query parameters- User permission querying login - User management- Login system dataedit - Presentation of database contents- Metadata management and annotation of ontology terms- Data management via user interface- Tag system- Data visualization- Data querying via user interface- Open Peer Review for data modelview - Creation and editing of various factsheets using a developed standard format in the form of a form- Factsheet searching- Tag system ontology - Integration of the Open Energy Ontology- Presentation of the contents of OEO- Descriptive contents about OEO and the development process oeo_viewer - Open Energy Ontology visualization- Open Energy Ontology search functionality- Special feature: Integrated React application <p>In addition to Django apps, there are other components that serve specific functionalities within the system:</p> Module Explanation theming Configures the global design using Bootstrap5 and provides design components that are imported into the software components listed above. This is where the user-friendly and aesthetic presentation of the web application is configured. oedb Implements database migration schemas used for migrating changes to the database (OEDB). These schemas are utilized by an imported software tool to manage all changes to the Open Energy Database from within the Django application."},{"location":"oeplatform-code/architecture/project-structure/","title":"Software Project","text":""},{"location":"oeplatform-code/architecture/project-structure/#project-directory","title":"Project directory","text":"<p>The tree structure you see below describes the structure of the oeplatform code project. In general it is a django (using version 3.2) project that maintains multiple django apps that either serve for the frontend UI of the oeplatform website or host our WEB-API\u00b4s like the REST-API or our OEKG-API which provide a interface to specific functionality that accesses the the different databases we maintain.</p> <p>The tree also shows several configurations and text files for the django application itself and also the project tooling and management we use to operate, test, maintain and document the system as well as the software code. Some files are also used to provide specific information about the development and deployment process and some other files are used for the project presentation on GitHub.</p> <p>In the following we will dive a bit deeper into the structure of the project. We aim to provide a general understanding of the different modules so that developers become enabled to get started with the development.</p> <pre><code>.oeplatform\n\u251c\u2500\u2500 .github         # GitHub test automation &amp; repository configuration\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 api             # Django app\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 base            # Django app\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 dataedit        # Django app\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 docker          # Docker &amp; docker-compose setup\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 docs            # mkdocs based project &amp; code documentation\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 factsheet       # Django app with react frontend\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 login           # Django app\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 media           # All kinds of media data from app\u00b4s\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 modelview       # Django app\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 oedb # Alembic migrations to manage the database structure\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 oeo_viewer      # Django app with react frontend\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 oeplatform      # Project configuration\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 ontology        # Django app\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 static          # statics from all apps are collected here\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 CACHE\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 theming         # The general oep design / styling and ui components\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 versions        # Changelogs\n\u2502   \u251c\u2500\u2500 bumpversion.sh\n\u2502   \u2514\u2500\u2500 changelogs\n\u251c\u2500\u2500 CITATION.cff\n\u251c\u2500\u2500 CONTRIBUTING.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 RELEASE_PROCEDURE.md\n\u251c\u2500\u2500 VERSION\n\u251c\u2500\u2500 alembic.ini\n\u251c\u2500\u2500 mkdocs.yml\n\u251c\u2500\u2500 package-lock.json\n\u251c\u2500\u2500 tox.ini\n\u251c\u2500\u2500 manage.py\n\u251c\u2500\u2500 environment.yml\n\u251c\u2500\u2500 requirements-dev.txt\n\u251c\u2500\u2500 requirements-docs.txt\n\u2514\u2500\u2500 requirements.txt\n</code></pre>"},{"location":"oeplatform-code/architecture/project-structure/#oeplatform","title":"oeplatform","text":""},{"location":"oeplatform-code/architecture/project-structure/#django-apps","title":"Django Apps","text":"<p>Casual django app</p> <pre><code>\u251c\u2500\u2500 dataedit\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 admin.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 apps.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 forms.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 helper.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 management\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 metadata\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 migrations\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 models.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 static\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 structures.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 templates\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 templatetags\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tests.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 urls.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 views.py\n</code></pre> <p>Django app that integrates a react frontend</p> <pre><code>\u251c\u2500\u2500 factsheet\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 frontend\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 management\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 migrations\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 models.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 static\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 templates\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 urls.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 views.py\n</code></pre> <p>Basic functionality</p> <ul> <li>base</li> <li>login</li> </ul> <p>REST API and Advanced API</p> <ul> <li>api</li> </ul> <p>Features</p> <p>Data publication(upload tabular data &amp; metadata), view, search, peer-review, download</p> <ul> <li>dataedit</li> </ul> <p>Model and Framework factsheets</p> <ul> <li>modelview</li> </ul> <p>Scenario Bundles &amp; Scenario Comparison</p> <ul> <li>factsheet</li> </ul> <p>Integration of the OpenEnergyOntology (view, search download full .owl file that includes the latest release of the oeo)</p> <ul> <li>ontology</li> </ul>"},{"location":"oeplatform-code/architecture/project-structure/#design","title":"Design","text":"<ul> <li>base</li> <li>theming</li> <li>oep design system and workflow</li> </ul> <pre><code>\u251c\u2500\u2500 theming\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Dockerfile\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 README.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _variables.scss\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 buildTheme.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 oepstrap.scss\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 scss\n</code></pre>"},{"location":"oeplatform-code/architecture/project-structure/#django-project-configuration","title":"Django-Project configuration","text":"<pre><code>\u251c\u2500\u2500 oeplatform\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dumper.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 securitysettings.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 securitysettings.py.default\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 settings.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 urls.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 views.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 wsgi.py\n</code></pre> <ul> <li>django models &amp; migrations</li> <li>sqlalchemy alembic structures</li> </ul>"},{"location":"oeplatform-code/architecture/project-structure/#oedatabase","title":"oedatabase","text":"<pre><code>\u251c\u2500\u2500 oedb\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 README\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 env.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 script.py.mako\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 versions\n</code></pre>"},{"location":"oeplatform-code/architecture/project-structure/#oep-django-db","title":"oep django db","text":""},{"location":"oeplatform-code/architecture/project-structure/#oe-knowledgegraph","title":"oe knowledgegraph","text":""},{"location":"oeplatform-code/architecture/project-structure/#oe-knowledgebase","title":"oe knowledgebase","text":""},{"location":"oeplatform-code/architecture/project-structure/#lookup-oep","title":"lookup oep","text":""},{"location":"oeplatform-code/architecture/project-structure/#test-oeplatform-replication","title":"test oeplatform (replication)","text":""},{"location":"oeplatform-code/architecture/project-structure/#dev-opperations","title":"Dev-opperations","text":"<ul> <li>github actions</li> <li>automated tests</li> <li>workflows and procedure</li> <li>requirement management</li> <li>versions</li> </ul>"},{"location":"oeplatform-code/architecture/project-structure/#collaboration","title":"Collaboration","text":""},{"location":"oeplatform-code/architecture/project-structure/#documentation","title":"Documentation","text":"<pre><code>\u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 css\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 index.md\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 install-and-documentation\n</code></pre> <pre><code>\u251c\u2500\u2500 docker\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Dockerfile\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 USAGE.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 apache2.conf\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 docker-compose.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 docker-entrypoint.sh\n</code></pre>"},{"location":"oeplatform-code/features/","title":"Index","text":""},{"location":"oeplatform-code/features/#openenergyplatform-features","title":"OpenEnergyPlatform features","text":"<p>This section provides detailed code documentation to document the implementation of all features of the oeplatform. In the Architecture/Modules section, we have already provided a brief overview of all the software modules (Django apps) that we maintain in the oeplatform.</p>"},{"location":"oeplatform-code/features/metaBuilder/","title":"Index","text":""},{"location":"oeplatform-code/features/metaBuilder/#metabuilder","title":"metaBuilder","text":"<p>The metaBuilder is a tool to create, edit and download metadata for the oeplatform.</p>"},{"location":"oeplatform-code/features/metaBuilder/#create","title":"Create","text":""},{"location":"oeplatform-code/features/metaBuilder/#download","title":"Download","text":"<p>We currently offer multiple download buttons on the OEP. You can either download the metadata while editing the metadata on a table or when you use the standalone version of the metaBuilder. It is also possible to download the metadata when you view the metadata on a table in the \"meta information\" tab.</p> <p>When you download the metadata json file the empty fields are kept as \"null\" values.</p>"},{"location":"oeplatform-code/features/oep-datasets/datasets/","title":"Datasets","text":""},{"location":"oeplatform-code/features/oep-datasets/datasets/#datasets","title":"Datasets","text":"<p>\ud83d\udea7 Feature not yet available</p> <p>Datasets are still in development and not yet fully implemented as described below. Currently, tabular data resources are handled individually.</p> <p>This section explains how we plan to implement Datasets in the OEP (Open Energy Platform).</p>"},{"location":"oeplatform-code/features/oep-datasets/datasets/#context","title":"Context","text":"<p>The OEP is based on a relational database (PostgreSQL) and provides both a REST API and a user interface (UI) for reading, uploading, editing, and deleting data. This setup supports the implementation phase of research projects by enabling integrated, agile data management.</p> <p>Our goal is to make data reusable and comparable, adding transparency to the complete data lifecycle. Many research projects struggle with data reusability and FAIR principles due to poor or missing data management workflows. We believe that by offering simple, flexible, and powerful tooling, we can change that.</p> <p>The OEP integrates the OpenEnergyDatabus, which assigns persistent identifiers (PIDs) and versions to datasets. The Databus itself does not store data, but references it using semantic web technologies, organizing data in a similar way to linked data graphs.</p>"},{"location":"oeplatform-code/features/oep-datasets/datasets/#about-oep-datasets","title":"About OEP Datasets","text":"\ud83e\udde9 Dataset Specifications We Build On <p>Datasets are a general concept used to group one or more data resources. Each dataset represents a unique set of data resources, meaning resources are not duplicated within a dataset.</p> <p>Rather than being stored as a physical set in a database, datasets are often described using metadata. In most professional and governmental domains, datasets follow the DCAT vocabulary (W3C), particularly the DCAT-AP specification promoted by the EU.</p> <ul> <li>\ud83d\udd17 DCAT Dataset Class Documentation</li> </ul> <p>Another popular framework is Frictionless Data, which offers: - A metadata specification for tabular datasets - A detailed schema for describing files like CSVs - Support for relational models (e.g., SQL tables)</p> <p>On the OEP, datasets are accessible via the UI and programmatically via the REST API using standard HTTP methods.</p>"},{"location":"oeplatform-code/features/oep-datasets/datasets/#use-cases","title":"Use Cases","text":"OEP Datasets serve multiple use cases <p>Draft Data Storage</p> <p>Upload data in any structure, using any PostgreSQL-supported types. No strict schema required during early exploration.</p> <p>Catalog Publishing</p> <p>Move draft datasets to published state within a topic category.</p> <p>Requires:</p> <ul> <li>Open data license for each resource</li> <li>Consistent structure</li> <li>Metadata completeness</li> </ul> <p>Scenario Data</p> <p>Link datasets to Scenario Bundles for model comparison and scenario analysis.</p> <p>This allows:</p> <ul> <li>Qualitative comparisons of scenario descriptions</li> <li>Quantitative comparisons using graphs and metrics across bundles</li> </ul> <p>User Stories overview</p> <ul> <li>User want to create datasets and want to add data, delete data and tables from   the dataset or edit it.</li> <li>User can use the UI of the Website and the Rest-API to do all datasets related   tasks</li> <li>Users want to find data and publish it: Data is grouped in topics and all   datasets are uploaded, later datasets can be published and are considered   complete, multiple versions might follow</li> <li>Users may want to add Datasets to multiple topics</li> <li>Users want to use well known functionality like the Legacy API functionality.   They think that it cannot be changed suddenly. (if we need to add   functionality we want to make it optional. Once it was adopted we can start do   bigger changes.)</li> </ul>"},{"location":"oeplatform-code/features/oep-datasets/datasets/#implementation","title":"Implementation","text":"Changes in OEP <p>First of we have in the OEP:</p> <ul> <li>Two databases 1. Primary DB and 2. Django DB. The Datastore for actual data is the Primary DB and the Django DB is like data registry to manage uploaded datasets and provide additional functionality.</li> </ul> <ul> <li>The django application in which mainly the <code>api</code> &amp; <code>dataedit</code> apps are affected.</li> </ul> What other services are affected <p>Additionally we need to handle:</p> <ul> <li>The Databus is the PID system for the OEP. Once the data is in a specific quality it is either manually or automatically (once published) registered on the Databus. The Databus itself only stores a metadata entry (based on DCAT-AP) in its internal graph store. It offers a rest api. It is hosted outside the OEP network but is connected internally to enable server-to-server communication.</li> <li>The MOSS is another Service we want to use to provide extended semantic search functionality based on the oemetadata entires for each dataset/table. It will also serve as primary metadata store for the OEP. It is also connected to the OEP for server-to-server communication.</li> </ul> OEMetadata &amp; Moss <p>OEP Datasets are described using the OEMetadata specification. The metadata is stored as JSON on both the OEP and MOSS, our RDF-capable metadata store. MOSS handles:</p> <ul> <li>Primary store for metadata documents</li> <li>Generating RDF from JSON-LD</li> <li>Metadata search functionality</li> </ul> <p>Keeping metadata in both systems improves integration but requires sync logic. This is solved by atomic updates on the OEP side when metadata is created or updated both systems are updated or changes are ignored and the user is informed.</p> <p>As described above we define a dataset similar to the DCAT-AP definition and build ontop of the frictionless datapackage standard. A datasets can be either a single table resource or multiple. We organize datasets hierarchically. All Datasets are grouped into Topics which make up the catalog categories. The Topics are not part of the hierarchy as datasets can be in multiple Topics.</p> <p>With this baseline definition we get a desired hierarchy which looks like this:</p> <ol> <li><code>Datasets/</code></li> <li><code>Datasets/&lt;dataset&gt;/</code></li> <li><code>Datasets/&lt;dataset&gt;/Resources/</code></li> <li><code>Datasets/&lt;dataset&gt;/Resources/&lt;resource&gt;/</code></li> </ol> <p>This structure ensures deep linking and intuitive access across the platform.</p> <p>What will change in the current URL/API system? (While keeping functionality available)</p> <p>To keep the current functionality in place the previous per-table approach is maintained and current urls are redirected:</p> <p>Topics will not be part of the dataset url anymore but there will be topic specific list urls like</p> <ol> <li><code>database/topics</code> = list all topics</li> <li><code>database/topics/&lt;topic&gt;</code> = list all datasets/tables per topic</li> </ol> <p>Currently we have something like <code>topics/&lt;topic&gt;/tables/&lt;table&gt;</code> which will become</p> <ol> <li><code>datasets</code> = Not necessarily relevant but for api request this could be an    easy way to get all available datasets</li> <li><code>datasets/&lt;table&gt;/</code> = Tables detail page</li> </ol> <p>How this will affect the REST-API:</p> <p>Since we already have a production implementation up and running since years and users are used to the existing structure as well as all REST-API endpoints using</p>"},{"location":"oeplatform-code/features/oep-datasets/datasets/#ui-preview","title":"UI Preview","text":"<p>The OEP interface will visualize datasets within a navigable catalog structure and provide editing capabilities for metadata and resources.</p> <p>\ud83c\udf31 Coming Soon</p> <p>The dataset interface is currently under active development. Feedback and suggestions are welcome as we evolve the feature!</p>"},{"location":"oeplatform-code/features/oep-datasets/tech-stack/","title":"Tech stack","text":""},{"location":"oeplatform-code/features/oep-datasets/tech-stack/#technology-architecture","title":"Technology &amp; Architecture","text":"<p>\ud83d\udea7 Feature not yet available</p> <p>Datasets are still in development and not yet fully implemented as described below. Currently, tabular data resources are handled individually.</p> <p>This section describes the technologies and architecture used to implement Datasets in the OEP (Open Energy Platform).</p>"},{"location":"oeplatform-code/features/oep-datasets/tech-stack/#technology-stack","title":"Technology Stack","text":"<p>The following software components and specifications form the foundation of the dataset implementation.</p>"},{"location":"oeplatform-code/features/oep-datasets/tech-stack/#software-components","title":"\ud83e\uddf0 Software Components","text":"<ul> <li>MOSS A microservice that stores metadata documents and provides a   high-performance semantic search overlay system.</li> </ul> <ul> <li>PostgreSQL Primary relational database used to store actual data tables.</li> </ul> <ul> <li>Django Python-based web framework responsible for business logic, database   access, and user interfaces.</li> </ul> <ul> <li>JavaScript &amp; CSS Used to create interactive and user-friendly experiences   in the web UI.</li> </ul>"},{"location":"oeplatform-code/features/oep-datasets/tech-stack/#metadata-specifications","title":"\ud83d\udcd0 Metadata Specifications","text":"<ul> <li>OEMetadata Custom metadata specification developed for the OEP to describe   datasets and related resources using a structured JSON (and JSON-LD) format.</li> </ul>"},{"location":"oeplatform-code/features/oep-datasets/tech-stack/#architecture","title":"Architecture","text":"<p>This section provides a conceptual overview of how datasets are integrated into the OEP platform.</p> <p>\ud83d\udccc Goal: Transition from handling resources individually (per-table) to managing grouped datasets containing multiple resources.</p>"},{"location":"oeplatform-code/features/oep-datasets/tech-stack/#system-overview","title":"System Overview","text":"<p>The diagram below illustrates the affected infrastructure components, relevant software modules, and how users will interact with the dataset system:</p> <p></p>"},{"location":"oeplatform-code/features/oep-datasets/tech-stack/#migration-summary","title":"Migration Summary","text":"<p>The transition to a dataset-centric model requires several substantial changes:</p> <p>Database Module (<code>dataedit</code>)</p> <ul> <li>Must support grouping resources into datasets</li> <li>Requires updated internal data models and database migrations</li> </ul> <p>API Module (<code>api</code>)</p> <ul> <li>Needs to allow creating datasets, adding/removing table resources, and   accessing datasets via REST</li> </ul> <p>User Interface</p> <ul> <li>Will be updated to present datasets instead of individual resources</li> <li>Improves clarity and reduces visual clutter by grouping related elements</li> </ul>"},{"location":"oeplatform-code/features/oep-datasets/tech-stack/#benefits-of-the-new-architecture","title":"Benefits of the New Architecture","text":"<ul> <li>\u2705 Supports larger and more complex datasets</li> <li>\u2705 Enhances usability by organizing data meaningfully</li> <li>\u2705 Enables dataset-level search and discoverability through the MOSS   microservice</li> <li>\u2705 Aligns with modern metadata standards and FAIR principles</li> </ul> <p>The MOSS microservice plays a key role in powering metadata search by indexing OEMetadata documents. This greatly improves findability and supports FAIR data practices.</p> <p>\ud83d\udca1 Looking Ahead</p> <p>Once fully implemented, the new architecture will streamline data handling, reduce redundancy, and make working with large datasets on the OEP much more efficient.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/","title":"Index","text":""},{"location":"oeplatform-code/features/open-peer-review-process/#developer-documentation-of-the-open-peer-review-process","title":"Developer documentation of the Open Peer Review Process","text":"<p>\ud83d\udea7 Feature currently deactivated</p> <p>The Open Peer Review on the OEP is currently under development as we migrated all metadata documents to version 2.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/#what-is-this-feature-about","title":"What is this feature about?","text":"<p>The Open Peer Review Process system facilitates collaborative review and validation of metadata through user interaction. It includes functionalities for uploading metadata, suggesting corrections, and reaching consensus on metadata fields. The system also features badge assignment and metadata updating upon agreement.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/#who-will-use-it-what-are-the-use-cases","title":"Who will use it &amp; What are the use cases?","text":"<ol> <li>Metadata Authors: Users who upload metadata for review, interact with     reviewers to address suggestions, and make necessary adjustments.</li> <li>Reviewers: Users who evaluate metadata fields, propose corrections, and     collaborate with authors to reach agreement.</li> <li>Accompanying Persons: Users with extended rights to access and manage     reviews, potentially overseeing the review process.</li> </ol>"},{"location":"oeplatform-code/features/open-peer-review-process/#use-cases-include","title":"Use Cases include","text":"<ol> <li>Collaborative metadata validation and improvement.</li> <li>Badge assignment based on field agreement.</li> <li>Management and oversight of the review process.</li> </ol>"},{"location":"oeplatform-code/features/open-peer-review-process/#what-functionality-is-there-from-a-user-pov-not-technical","title":"What functionality is there (from a user POV, not technical)?","text":"<ol> <li>Metadata Uploading and Reviewing: Users can upload metadata, propose     corrections, and accept or deny fields.</li> <li>Interactive Feedback: Authors and reviewers interact to agree on metadata     fields.</li> <li>Badge Assignment and Metadata Updating: Upon agreement, the appropriate     badge is assigned, and metadata is updated.</li> <li>Review Management: Accompanying persons have special tools for review     oversight.</li> </ol>"},{"location":"oeplatform-code/features/open-peer-review-process/#description-of-the-review-process-for-users","title":"Description of the Review Process for Users","text":"<ol> <li>Uploading Metadata:</li> </ol> <p>Any registered user can upload metadata to the database page</p> <ol> <li>Review Process:</li> </ol> <p>Other users, who are not the authors of the metadata, can review each field of the metadata. The reviewer has three possible actions:</p> <ul> <li>Accept: Agreeing with the   current data of the field</li> <li>Suggest: Proposing   corrections for the field</li> <li>Deny: Rejecting, if the   field does not meet the criteria or is not appropriate in content</li> </ul> <ol> <li>Author\u2019s Feedback:</li> </ol> <p>The author of the metadata can view the reviewers' feedback on their page and respond to it, either agreeing with the suggestions or proposing their own changes.</p> <ol> <li>Interaction and Agreement:</li> </ol> <p>The reviewer and the author continue interacting until an agreement is reached and all fields obtain the accept status. A response can only be sent after evaluating all fields that do not yet have the accept status.</p> <ol> <li>Choosing Badge and Updating Metadata:</li> </ol> <p>After all fields are agreed upon, the reviewer selects the appropriate badge, and the metadata in the JSON file is updated accordingly.</p> <ol> <li>Exclusivity of the Process:</li> </ol> <p>If the review process has already begun, other users cannot join it until it is completed.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/#new-functional-features","title":"New Functional Features","text":"<ol> <li>Badge Calculation and Visualization</li> </ol> <p>Implementation of functionality for calculating the badge by comparing the filled fields with the metadata schema. Users will be provided with a visualization of the percentage of fields that have an \"OK\" status, allowing for easier navigation through the review process.</p> <ol> <li>Review Process Optimization</li> </ol> <p>Introduction of mechanisms for optimizing the review process, including limiting the number of fields requiring human verification. This will allow focusing on the most relevant or error-prone fields, thereby enhancing the user experience and encouraging the completion of the review.</p> <ol> <li>Role of the Accompanying Person</li> </ol> <p>Addition of a new role \"accompanying person,\" endowed with extended rights of access and management of reviews. The accompanying person will have access to all reviews, be able to delete them, and will have special management tools in the user profile. The role of the accompanying person can be assigned based on the is_staff attribute.</p> <ol> <li>Displaying the Percentage</li> </ol> <p>The system will feature functionality to display the percentage of fields that are in an \"OK\" state out of the total number of fields. This feature will provide users with a quick overview of the progress made in the review process, allowing them to easily assess how many fields have been successfully validated.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/#a-meta-description","title":"A Meta Description","text":""},{"location":"oeplatform-code/features/open-peer-review-process/#what-is-the-context-what-other-parts-of-the-oep-are-connected","title":"What is the context (what other parts of the OEP are connected)?","text":"<p>This function is a part of the Open Energy Platform (OEP). It interacts with the database, loading and updating metadata, ensuring data consistency within the OEP. The function utilizes JSON and is developed using the Django framework. It also manages user access and employs specialized libraries, such as OEMETADATA_V160_SCHEMA.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/#software-architecture-implementation-details","title":"Software Architecture &amp; Implementation Details","text":""},{"location":"oeplatform-code/features/open-peer-review-process/#context","title":"Context","text":"<p>The Open Peer Review Process is designed with a modular and scalable architecture, ensuring seamless integration with existing systems and adaptability to evolving technological requirements.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/#technologies","title":"Technologies","text":"<ol> <li>Python:</li> </ol> <p>The backbone of the application, Python is employed for developing core functionalities, defining data structures, and orchestrating interactions between different components.</p> <ol> <li>Django:</li> </ol> <p>This high-level Python web framework is used to encourage rapid development and clean, pragmatic design, facilitating the creation of reusable and maintainable code.</p> <ol> <li>JSON:</li> </ol> <p>JSON plays a pivotal role in structuring and handling metadata, enabling efficient data interchange between the server and client-side components.</p> <ol> <li>Jinja2:</li> </ol> <p>Leveraged for templating, Jinja2 aids in generating dynamic HTML content, thereby enhancing user interface design and user experience.</p> <ol> <li>mkdocstrings:</li> </ol> <p>This library is vital for automatically collecting Python docstrings from the source code and rendering them into the project's documentation.</p> <ol> <li>Special Libraries and Modules:</li> </ol> <p>Libraries such as OEMETADATA_V160_SCHEMA and functions like load_metadata_from_db are integrated for enhanced metadata management and interaction with the database.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/#connection-to-existing-code","title":"Connection to Existing Code","text":"<p>The Open Peer Review Process system is meticulously integrated into the Open Energy Platform (OEP). It interfaces with the OEP's database to load and update metadata, ensuring data consistency across various modules. The implementation leverages Django-specific classes and methods, such as LoginRequiredMixin and View, to enforce user permissions and manage user interactions.</p> <p>Furthermore, the system utilizes existing modules and libraries, ensuring that the metadata adheres to predefined schemas and facilitating interaction with the database. The addition of new functionalities and roles, such as the \"accompanying person,\" is executed in alignment with the established codebase, ensuring that the extended rights and functionalities are seamlessly incorporated.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/#conclusion","title":"Conclusion","text":"<p>By leveraging a diverse technology stack and ensuring meticulous integration with the existing codebase, the Open Peer Review Process exemplifies a robust and scalable architecture. This design philosophy not only facilitates current operations but also lays a solid foundation for future developments and enhancements.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/#changelogs","title":"Changelogs","text":"<p>Description:</p> <p>The CHANGELOG is a document that contains an organized and dated list of changes made in each version of the project. This list includes updates, bug fixes, new features, and other important notifications for users and developers.</p> <p>Purpose:</p> <p>The purpose of the CHANGELOG is to provide a clear and concise list of changes for each release, making it easier to track modifications and understand the current state of the project.</p> <p>To view a detailed list of changes for each version, follow the link to the CHANGELOGS folder.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/","title":"Technical docs","text":""},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#views","title":"Views","text":"<p>Django views.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#peerreviewview","title":"PeerReviewView","text":"<p>View for the reviewer role of the Open Peer Review process.</p> <p>               Bases: <code>LoginRequiredMixin</code>, <code>View</code></p> <p>A view handling the peer review of metadata. This view supports loading, parsing, sorting metadata, and handling GET and POST requests for peer review.</p> Source code in <code>dataedit/views.py</code> <pre><code>class TablePeerReviewView(LoginRequiredMixin, View):\n    \"\"\"\n    A view handling the peer review of metadata. This view supports loading,\n    parsing, sorting metadata, and handling GET and POST requests for peer review.\n    \"\"\"\n\n    def load_json(self, table: str, review_id=None):\n        \"\"\"\n        Load JSON metadata from the database. If the review_id is available\n        then load the metadata form the peer review instance and not from the\n        table. This avoids changes to the metadata that is or was reviewed.\n\n        Args:\n            table (str): The name of the table.\n            review_id (int): Id of a peer review in the django database\n\n        Returns:\n            dict: Loaded oemetadata.\n        \"\"\"\n        metadata = {}\n        if review_id is None:\n            metadata = load_metadata_from_db(table=table)\n        elif review_id:\n            opr = PeerReviewManager.get_opr_by_id(opr_id=review_id)\n            metadata = opr.oemetadata\n\n        return metadata\n\n    def load_json_schema(self):\n        \"\"\"\n        Load the JSON schema used for validating metadata.\n\n        Note:\n            Update this method if a new oemetadata version is released.\n\n        Returns:\n            dict: JSON schema.\n        \"\"\"\n        json_schema = OEMETADATA_V20_SCHEMA\n        return json_schema\n\n    def parse_keys(self, val, old=\"\"):\n        \"\"\"\n        Recursively parse keys from a nested dictionary or list and return them\n        as a list of dictionaries.\n\n        Args:\n            val (dict or list): The input dictionary or list to parse.\n            old (str, optional): The prefix for nested keys. Defaults to an\n                empty string.\n\n        Returns:\n            list: A list of dictionaries, each containing 'field' and 'value'\n                keys.\n        \"\"\"\n        lines = []\n        if isinstance(val, dict):\n            for k in val.keys():\n                lines += self.parse_keys(val[k], old + \".\" + str(k))\n        elif isinstance(val, list):\n            if not val:\n                # handles empty list\n                lines += [{\"field\": old[1:], \"value\": str(val)}]\n            else:\n                for i, k in enumerate(val):\n                    lines += self.parse_keys(\n                        k, old + \".\" + str(i)\n                    )  # handles user value\n        else:\n            lines += [{\"field\": old[1:], \"value\": str(val)}]\n        return lines\n\n    def sort_in_category(self, table: str, oemetadata):\n        \"\"\"\n        Group flattened OEMetadata v2 fields into thematic buckets and attach\n        placeholders required by the review UI.\n\n        Each entry has six keys:\n        {\n          \"field\": \"&lt;dot-path&gt;\",\n          \"label\": \"&lt;display label without 'resources.&lt;idx&gt;.'&gt;\",\n          \"value\": \"&lt;current value&gt;\",\n          \"newValue\": \"\",\n          \"reviewer_suggestion\": \"\",\n          \"suggestion_comment\": \"\"\n        }\n        \"\"\"\n\n        flattened = self.parse_keys(oemetadata)\n        flattened = [\n            item for item in flattened if item[\"field\"].startswith(\"resources.\")\n        ]\n\n        bucket_map = {\n            \"spatial\": \"spatial\",\n            \"temporal\": \"temporal\",\n            \"sources\": \"source\",\n            \"licenses\": \"license\",\n        }\n\n        def make_label(dot_path: str) -&gt; str:\n            # remove leading resources.&lt;idx&gt;.\n            trimmed = re.sub(r\"^resources\\.[0-9]+\\.\", \"\", dot_path)\n            parts = trimmed.split(\".\")\n            out = []\n            for p in parts:\n                if p in {\"@id\", \"@type\"}:\n                    out.append(p)\n                else:\n                    out.append(p.replace(\"_\", \" \"))\n            if out:\n                out[0] = out[0][:1].upper() + out[0][1:]\n            return \" \".join(out)\n\n        tmp = defaultdict(list)\n\n        for item in flattened:\n            raw_key = item[\"field\"]\n            parts = raw_key.split(\".\")\n\n            if parts[0] == \"resources\" and len(parts) &gt;= 3:\n                root = parts[2]\n            else:\n                root = parts[0]\n\n            bucket = bucket_map.get(root, \"general\")\n\n            tmp[bucket].append(\n                {\n                    \"field\": raw_key,\n                    \"label\": make_label(raw_key),\n                    \"value\": item[\"value\"],\n                    \"newValue\": \"\",\n                    \"reviewer_suggestion\": \"\",\n                    \"suggestion_comment\": \"\",\n                }\n            )\n\n        return {\n            \"general\": tmp[\"general\"],\n            \"spatial\": tmp[\"spatial\"],\n            \"temporal\": tmp[\"temporal\"],\n            \"source\": tmp[\"source\"],\n            \"license\": tmp[\"license\"],\n        }\n\n    def get_all_field_descriptions(self, json_schema, prefix=\"\"):\n        \"\"\"\n        Collects the field title, descriptions, examples, and badge information\n        for each field of the oemetadata from the JSON schema and prepares them\n        for further processing.\n\n        Args:\n            json_schema (dict): The JSON schema to extract field descriptions\n                from.\n            prefix (str, optional): The prefix for nested keys. Defaults to an\n                empty string.\n\n        Returns:\n            dict: A dictionary containing field descriptions, examples, and\n                other information.\n        \"\"\"\n\n        field_descriptions = {}\n\n        def extract_descriptions(properties, prefix=\"\"):\n            for field, value in properties.items():\n                key = f\"{prefix}.{field}\" if prefix else field\n\n                if any(\n                    attr in value\n                    for attr in [\"description\", \"examples\", \"example\", \"badge\", \"title\"]\n                ):\n                    field_descriptions[key] = {}\n                    if \"description\" in value:\n                        field_descriptions[key][\"description\"] = value[\"description\"]\n                    # Prefer v2 \"examples\" (array) over v1 \"example\" (single value)\n                    if \"examples\" in value and value[\"examples\"]:\n                        # v2: first item of the examples array\n                        field_descriptions[key][\"example\"] = value[\"examples\"][0]\n                    elif \"example\" in value:\n                        # v1 fallback\n                        field_descriptions[key][\"example\"] = value[\"example\"]\n                    if \"badge\" in value:\n                        field_descriptions[key][\"badge\"] = value[\"badge\"]\n                    if \"title\" in value:\n                        field_descriptions[key][\"title\"] = value[\"title\"]\n                if \"properties\" in value:\n                    new_prefix = f\"{prefix}.{field}\" if prefix else field\n                    extract_descriptions(value[\"properties\"], new_prefix)\n                if \"items\" in value:\n                    new_prefix = f\"{prefix}.{field}\" if prefix else field\n                    if \"properties\" in value[\"items\"]:\n                        extract_descriptions(value[\"items\"][\"properties\"], new_prefix)\n\n        extract_descriptions(json_schema[\"properties\"], prefix)\n        return field_descriptions\n\n    def get(\n        self,\n        request: HttpRequest,\n        table: str,\n        review_id: int | None = None,\n    ) -&gt; HttpResponse:\n        \"\"\"\n        Handle GET requests for peer review.\n        Loads necessary data and renders the review template.\n\n        Args:\n            request (HttpRequest): The incoming HTTP GET request.\n            table (str): The name of the table.\n            review_id (int, optional): The ID of the review. Defaults to None.\n\n        Returns:\n            HttpResponse: Rendered HTML response.\n        \"\"\"\n\n        table_obj = table_or_404(table=table)\n        topic = table_obj.topics\n\n        # review_state = PeerReview.is_finished  # TODO: Use later\n        json_schema = self.load_json_schema()\n        can_add = False\n        field_descriptions = self.get_all_field_descriptions(json_schema)\n\n        # Check user permissions\n        user: login_models.myuser = request.user  # type: ignore\n        if not user.is_anonymous:\n            level = user.get_table_permission_level(table_obj)\n            can_add = level &gt;= login.permissions.WRITE_PERM\n\n        oemetadata = self.load_json(table, review_id)\n        metadata = self.sort_in_category(\n            table, oemetadata=oemetadata\n        )  # Generate URL for peer_review_reviewer\n        if review_id is not None:\n            url_peer_review = reverse(\n                \"dataedit:peer_review_reviewer\",\n                kwargs={\"table\": table, \"review_id\": review_id},\n            )\n            opr_review = PeerReviewManager.get_opr_by_id(opr_id=review_id)\n\n            existing_review = (opr_review.review or {}).get(\"reviews\", [])\n            review_finished = opr_review.is_finished\n            categories = [\n                \"general\",\n                \"spatial\",\n                \"temporal\",\n                \"source\",\n                \"license\",\n            ]\n            state_dict = process_review_data(\n                review_data=existing_review, metadata=metadata, categories=categories\n            )\n        else:\n            url_peer_review = reverse(\n                \"dataedit:peer_review_create\",\n                kwargs={\"table\": table},\n            )\n            # existing_review={}\n            state_dict = None\n            review_finished = None\n\n        config_data = {\n            \"can_add\": can_add,\n            \"url_peer_review\": url_peer_review,\n            \"url_table\": reverse(\"dataedit:view\", kwargs={\"table\": table}),\n            \"topic\": topic,\n            \"table\": table,\n            \"review_finished\": review_finished,\n            \"review_id\": review_id,\n        }\n        context_meta = {\n            # need this here as json.dumps breaks the template syntax access\n            # like {{ config.table }} now you can use {{ table }}\n            \"table\": table,\n            \"topic\": table_obj.topics,\n            \"config\": json.dumps(config_data),\n            \"meta\": metadata,\n            \"json_schema\": json_schema,\n            \"field_descriptions_json\": json.dumps(field_descriptions),\n            \"state_dict\": json.dumps(state_dict),\n            \"review_finished\": review_finished,\n            \"review_id\": review_id,\n        }\n        return render(request, \"dataedit/opr_review.html\", context=context_meta)\n\n    def post(self, request: HttpRequest, table: str, review_id=None) -&gt; HttpResponse:\n        \"\"\"\n        Handle POST requests for submitting reviews by the reviewer.\n\n        This method:\n        - Creates (or saves) reviews in the PeerReview table.\n        - Updates the review finished attribute in the dataedit.Tables table,\n            indicating that the table can be moved from the model draft topic.\n\n        Missing parts:\n        - once the opr is finished (all field reviews agreed on)\n        - merge field review results to metadata on table\n        - awarde a badge\n            - is field filled in?\n            - calculate the badge by comparing filled fields\n              and the badges form metadata schema\n\n        Args:\n            request (HttpRequest): The incoming HTTP POST request.\n            table (str): The name of the table.\n            review_id (int, optional): The ID of the review. Defaults to None.\n\n        Returns:\n            HttpResponse: Rendered HTML response for the review.\n\n        Raises:\n            JsonResponse: If any error occurs, a JsonResponse containing the\n            error message is raised.\n\n        Note:\n            - There are some missing parts in this method. Once the review process\n                is finished (all field reviews agreed on), it should merge field\n                review results to metadata on the table and award a badge based\n                on certain criteria.\n            - A notification should be sent to the user if he/she can't review tables\n            for which he/she is the table holder (TODO).\n            - After a review is finished, the table's metadata is updated, and the table\n            can be moved to a different topic (TODO).\n        \"\"\"\n        table_obj = table_or_404(table=table)\n\n        context = {}\n        user: login_models.myuser = request.user  # type: ignore\n\n        # get the review data and additional application metadata\n        # from user peer review submit/save\n        review_data = json.loads(request.body)\n        if review_id:\n            contributor_review = PeerReview.objects.filter(id=review_id).first()\n            if contributor_review:\n                contributor_review_data = (contributor_review.review or {}).get(\n                    \"reviews\", []\n                )\n                review_data[\"reviewData\"][\"reviews\"].extend(contributor_review_data)\n\n        # The type can be \"save\" or \"submit\" as this triggers different behavior\n        review_post_type = review_data.get(\"reviewType\")\n        # The opr datamodel that includes the field review data and metadata\n        review_datamodel = review_data.get(\"reviewData\")\n        review_finished = review_datamodel.get(\"reviewFinished\")\n        # TODO: Send a notification to the user that he can't review tables\n        # he is the table holder.\n        if review_post_type == \"delete\":\n            return delete_peer_review(review_id)\n\n        contributor = PeerReviewManager.load_contributor(table=table_obj.name)\n\n        if contributor is not None:\n            # \u00dcberpr\u00fcfen, ob ein aktiver PeerReview existiert\n            active_peer_review = PeerReview.load(table=table_obj.name)\n            if active_peer_review is None or active_peer_review.is_finished:\n                # Kein aktiver PeerReview vorhanden\n                # oder der aktive PeerReview ist abgeschlossen\n                table_review = PeerReview(\n                    table=table_obj.name,\n                    is_finished=review_finished,\n                    review=review_datamodel,\n                    reviewer=user,\n                    contributor=contributor,\n                    oemetadata=load_metadata_from_db(table=table_obj.name),\n                )\n                table_review.save(review_type=review_post_type)\n            else:\n                # Aktiver PeerReview ist vorhanden ... aktualisieren\n                current_review_data = active_peer_review.review\n                merged_review_data = merge_field_reviews(\n                    current_json=current_review_data, new_json=review_datamodel\n                )\n\n                # Set new review values and update existing review\n                active_peer_review.review = merged_review_data\n                active_peer_review.reviewer = user  # type:ignore TODO why type warning?\n                active_peer_review.contributor = contributor  # type:ignore TODO\n                active_peer_review.update(review_type=review_post_type)\n        else:\n            error_msg = (\n                \"Failed to retrieve any user that identifies \"\n                f\"as table holder for the current table: {table_obj.name}!\"\n            )\n            return JsonResponse({\"error\": error_msg}, status=400)\n\n        # TODO: Check for topic as reviewed finished also indicates the table\n        # needs to be or has to be moved.\n        if review_finished is True:\n            review_table = Table.load(name=table_obj.name)\n            review_table.set_is_reviewed()\n            metadata = self.load_json(table_obj.name, review_id=review_id)\n            updated_metadata = recursive_update(metadata, review_data)\n            save_metadata_to_db(table_obj.name, updated_metadata)\n            active_peer_review = PeerReview.load(table=table_obj.name)\n\n            if active_peer_review:\n                updated_oemetadata = recursive_update(\n                    active_peer_review.oemetadata, review_data\n                )\n                active_peer_review.oemetadata = updated_oemetadata\n                active_peer_review.save()\n\n            # TODO: also update reviewFinished in review datamodel json\n\n        return render(request, \"dataedit/opr_review.html\", context=context)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.views.TablePeerReviewView.get","title":"<code>get(request, table, review_id=None)</code>","text":"<p>Handle GET requests for peer review. Loads necessary data and renders the review template.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP GET request.</p> required <code>table</code> <code>str</code> <p>The name of the table.</p> required <code>review_id</code> <code>int</code> <p>The ID of the review. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>HttpResponse</code> <code>HttpResponse</code> <p>Rendered HTML response.</p> Source code in <code>dataedit/views.py</code> <pre><code>def get(\n    self,\n    request: HttpRequest,\n    table: str,\n    review_id: int | None = None,\n) -&gt; HttpResponse:\n    \"\"\"\n    Handle GET requests for peer review.\n    Loads necessary data and renders the review template.\n\n    Args:\n        request (HttpRequest): The incoming HTTP GET request.\n        table (str): The name of the table.\n        review_id (int, optional): The ID of the review. Defaults to None.\n\n    Returns:\n        HttpResponse: Rendered HTML response.\n    \"\"\"\n\n    table_obj = table_or_404(table=table)\n    topic = table_obj.topics\n\n    # review_state = PeerReview.is_finished  # TODO: Use later\n    json_schema = self.load_json_schema()\n    can_add = False\n    field_descriptions = self.get_all_field_descriptions(json_schema)\n\n    # Check user permissions\n    user: login_models.myuser = request.user  # type: ignore\n    if not user.is_anonymous:\n        level = user.get_table_permission_level(table_obj)\n        can_add = level &gt;= login.permissions.WRITE_PERM\n\n    oemetadata = self.load_json(table, review_id)\n    metadata = self.sort_in_category(\n        table, oemetadata=oemetadata\n    )  # Generate URL for peer_review_reviewer\n    if review_id is not None:\n        url_peer_review = reverse(\n            \"dataedit:peer_review_reviewer\",\n            kwargs={\"table\": table, \"review_id\": review_id},\n        )\n        opr_review = PeerReviewManager.get_opr_by_id(opr_id=review_id)\n\n        existing_review = (opr_review.review or {}).get(\"reviews\", [])\n        review_finished = opr_review.is_finished\n        categories = [\n            \"general\",\n            \"spatial\",\n            \"temporal\",\n            \"source\",\n            \"license\",\n        ]\n        state_dict = process_review_data(\n            review_data=existing_review, metadata=metadata, categories=categories\n        )\n    else:\n        url_peer_review = reverse(\n            \"dataedit:peer_review_create\",\n            kwargs={\"table\": table},\n        )\n        # existing_review={}\n        state_dict = None\n        review_finished = None\n\n    config_data = {\n        \"can_add\": can_add,\n        \"url_peer_review\": url_peer_review,\n        \"url_table\": reverse(\"dataedit:view\", kwargs={\"table\": table}),\n        \"topic\": topic,\n        \"table\": table,\n        \"review_finished\": review_finished,\n        \"review_id\": review_id,\n    }\n    context_meta = {\n        # need this here as json.dumps breaks the template syntax access\n        # like {{ config.table }} now you can use {{ table }}\n        \"table\": table,\n        \"topic\": table_obj.topics,\n        \"config\": json.dumps(config_data),\n        \"meta\": metadata,\n        \"json_schema\": json_schema,\n        \"field_descriptions_json\": json.dumps(field_descriptions),\n        \"state_dict\": json.dumps(state_dict),\n        \"review_finished\": review_finished,\n        \"review_id\": review_id,\n    }\n    return render(request, \"dataedit/opr_review.html\", context=context_meta)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.views.TablePeerReviewView.get_all_field_descriptions","title":"<code>get_all_field_descriptions(json_schema, prefix='')</code>","text":"<p>Collects the field title, descriptions, examples, and badge information for each field of the oemetadata from the JSON schema and prepares them for further processing.</p> <p>Parameters:</p> Name Type Description Default <code>json_schema</code> <code>dict</code> <p>The JSON schema to extract field descriptions from.</p> required <code>prefix</code> <code>str</code> <p>The prefix for nested keys. Defaults to an empty string.</p> <code>''</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing field descriptions, examples, and other information.</p> Source code in <code>dataedit/views.py</code> <pre><code>def get_all_field_descriptions(self, json_schema, prefix=\"\"):\n    \"\"\"\n    Collects the field title, descriptions, examples, and badge information\n    for each field of the oemetadata from the JSON schema and prepares them\n    for further processing.\n\n    Args:\n        json_schema (dict): The JSON schema to extract field descriptions\n            from.\n        prefix (str, optional): The prefix for nested keys. Defaults to an\n            empty string.\n\n    Returns:\n        dict: A dictionary containing field descriptions, examples, and\n            other information.\n    \"\"\"\n\n    field_descriptions = {}\n\n    def extract_descriptions(properties, prefix=\"\"):\n        for field, value in properties.items():\n            key = f\"{prefix}.{field}\" if prefix else field\n\n            if any(\n                attr in value\n                for attr in [\"description\", \"examples\", \"example\", \"badge\", \"title\"]\n            ):\n                field_descriptions[key] = {}\n                if \"description\" in value:\n                    field_descriptions[key][\"description\"] = value[\"description\"]\n                # Prefer v2 \"examples\" (array) over v1 \"example\" (single value)\n                if \"examples\" in value and value[\"examples\"]:\n                    # v2: first item of the examples array\n                    field_descriptions[key][\"example\"] = value[\"examples\"][0]\n                elif \"example\" in value:\n                    # v1 fallback\n                    field_descriptions[key][\"example\"] = value[\"example\"]\n                if \"badge\" in value:\n                    field_descriptions[key][\"badge\"] = value[\"badge\"]\n                if \"title\" in value:\n                    field_descriptions[key][\"title\"] = value[\"title\"]\n            if \"properties\" in value:\n                new_prefix = f\"{prefix}.{field}\" if prefix else field\n                extract_descriptions(value[\"properties\"], new_prefix)\n            if \"items\" in value:\n                new_prefix = f\"{prefix}.{field}\" if prefix else field\n                if \"properties\" in value[\"items\"]:\n                    extract_descriptions(value[\"items\"][\"properties\"], new_prefix)\n\n    extract_descriptions(json_schema[\"properties\"], prefix)\n    return field_descriptions\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.views.TablePeerReviewView.load_json","title":"<code>load_json(table, review_id=None)</code>","text":"<p>Load JSON metadata from the database. If the review_id is available then load the metadata form the peer review instance and not from the table. This avoids changes to the metadata that is or was reviewed.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table.</p> required <code>review_id</code> <code>int</code> <p>Id of a peer review in the django database</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Loaded oemetadata.</p> Source code in <code>dataedit/views.py</code> <pre><code>def load_json(self, table: str, review_id=None):\n    \"\"\"\n    Load JSON metadata from the database. If the review_id is available\n    then load the metadata form the peer review instance and not from the\n    table. This avoids changes to the metadata that is or was reviewed.\n\n    Args:\n        table (str): The name of the table.\n        review_id (int): Id of a peer review in the django database\n\n    Returns:\n        dict: Loaded oemetadata.\n    \"\"\"\n    metadata = {}\n    if review_id is None:\n        metadata = load_metadata_from_db(table=table)\n    elif review_id:\n        opr = PeerReviewManager.get_opr_by_id(opr_id=review_id)\n        metadata = opr.oemetadata\n\n    return metadata\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.views.TablePeerReviewView.load_json_schema","title":"<code>load_json_schema()</code>","text":"<p>Load the JSON schema used for validating metadata.</p> Note <p>Update this method if a new oemetadata version is released.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>JSON schema.</p> Source code in <code>dataedit/views.py</code> <pre><code>def load_json_schema(self):\n    \"\"\"\n    Load the JSON schema used for validating metadata.\n\n    Note:\n        Update this method if a new oemetadata version is released.\n\n    Returns:\n        dict: JSON schema.\n    \"\"\"\n    json_schema = OEMETADATA_V20_SCHEMA\n    return json_schema\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.views.TablePeerReviewView.parse_keys","title":"<code>parse_keys(val, old='')</code>","text":"<p>Recursively parse keys from a nested dictionary or list and return them as a list of dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>dict or list</code> <p>The input dictionary or list to parse.</p> required <code>old</code> <code>str</code> <p>The prefix for nested keys. Defaults to an empty string.</p> <code>''</code> <p>Returns:</p> Name Type Description <code>list</code> <p>A list of dictionaries, each containing 'field' and 'value' keys.</p> Source code in <code>dataedit/views.py</code> <pre><code>def parse_keys(self, val, old=\"\"):\n    \"\"\"\n    Recursively parse keys from a nested dictionary or list and return them\n    as a list of dictionaries.\n\n    Args:\n        val (dict or list): The input dictionary or list to parse.\n        old (str, optional): The prefix for nested keys. Defaults to an\n            empty string.\n\n    Returns:\n        list: A list of dictionaries, each containing 'field' and 'value'\n            keys.\n    \"\"\"\n    lines = []\n    if isinstance(val, dict):\n        for k in val.keys():\n            lines += self.parse_keys(val[k], old + \".\" + str(k))\n    elif isinstance(val, list):\n        if not val:\n            # handles empty list\n            lines += [{\"field\": old[1:], \"value\": str(val)}]\n        else:\n            for i, k in enumerate(val):\n                lines += self.parse_keys(\n                    k, old + \".\" + str(i)\n                )  # handles user value\n    else:\n        lines += [{\"field\": old[1:], \"value\": str(val)}]\n    return lines\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.views.TablePeerReviewView.post","title":"<code>post(request, table, review_id=None)</code>","text":"<p>Handle POST requests for submitting reviews by the reviewer.</p> <p>This method: - Creates (or saves) reviews in the PeerReview table. - Updates the review finished attribute in the dataedit.Tables table,     indicating that the table can be moved from the model draft topic.</p> <p>Missing parts: - once the opr is finished (all field reviews agreed on) - merge field review results to metadata on table - awarde a badge     - is field filled in?     - calculate the badge by comparing filled fields       and the badges form metadata schema</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP POST request.</p> required <code>table</code> <code>str</code> <p>The name of the table.</p> required <code>review_id</code> <code>int</code> <p>The ID of the review. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>HttpResponse</code> <code>HttpResponse</code> <p>Rendered HTML response for the review.</p> <p>Raises:</p> Type Description <code>JsonResponse</code> <p>If any error occurs, a JsonResponse containing the</p> Note <ul> <li>There are some missing parts in this method. Once the review process     is finished (all field reviews agreed on), it should merge field     review results to metadata on the table and award a badge based     on certain criteria.</li> <li>A notification should be sent to the user if he/she can't review tables for which he/she is the table holder (TODO).</li> <li>After a review is finished, the table's metadata is updated, and the table can be moved to a different topic (TODO).</li> </ul> Source code in <code>dataedit/views.py</code> <pre><code>def post(self, request: HttpRequest, table: str, review_id=None) -&gt; HttpResponse:\n    \"\"\"\n    Handle POST requests for submitting reviews by the reviewer.\n\n    This method:\n    - Creates (or saves) reviews in the PeerReview table.\n    - Updates the review finished attribute in the dataedit.Tables table,\n        indicating that the table can be moved from the model draft topic.\n\n    Missing parts:\n    - once the opr is finished (all field reviews agreed on)\n    - merge field review results to metadata on table\n    - awarde a badge\n        - is field filled in?\n        - calculate the badge by comparing filled fields\n          and the badges form metadata schema\n\n    Args:\n        request (HttpRequest): The incoming HTTP POST request.\n        table (str): The name of the table.\n        review_id (int, optional): The ID of the review. Defaults to None.\n\n    Returns:\n        HttpResponse: Rendered HTML response for the review.\n\n    Raises:\n        JsonResponse: If any error occurs, a JsonResponse containing the\n        error message is raised.\n\n    Note:\n        - There are some missing parts in this method. Once the review process\n            is finished (all field reviews agreed on), it should merge field\n            review results to metadata on the table and award a badge based\n            on certain criteria.\n        - A notification should be sent to the user if he/she can't review tables\n        for which he/she is the table holder (TODO).\n        - After a review is finished, the table's metadata is updated, and the table\n        can be moved to a different topic (TODO).\n    \"\"\"\n    table_obj = table_or_404(table=table)\n\n    context = {}\n    user: login_models.myuser = request.user  # type: ignore\n\n    # get the review data and additional application metadata\n    # from user peer review submit/save\n    review_data = json.loads(request.body)\n    if review_id:\n        contributor_review = PeerReview.objects.filter(id=review_id).first()\n        if contributor_review:\n            contributor_review_data = (contributor_review.review or {}).get(\n                \"reviews\", []\n            )\n            review_data[\"reviewData\"][\"reviews\"].extend(contributor_review_data)\n\n    # The type can be \"save\" or \"submit\" as this triggers different behavior\n    review_post_type = review_data.get(\"reviewType\")\n    # The opr datamodel that includes the field review data and metadata\n    review_datamodel = review_data.get(\"reviewData\")\n    review_finished = review_datamodel.get(\"reviewFinished\")\n    # TODO: Send a notification to the user that he can't review tables\n    # he is the table holder.\n    if review_post_type == \"delete\":\n        return delete_peer_review(review_id)\n\n    contributor = PeerReviewManager.load_contributor(table=table_obj.name)\n\n    if contributor is not None:\n        # \u00dcberpr\u00fcfen, ob ein aktiver PeerReview existiert\n        active_peer_review = PeerReview.load(table=table_obj.name)\n        if active_peer_review is None or active_peer_review.is_finished:\n            # Kein aktiver PeerReview vorhanden\n            # oder der aktive PeerReview ist abgeschlossen\n            table_review = PeerReview(\n                table=table_obj.name,\n                is_finished=review_finished,\n                review=review_datamodel,\n                reviewer=user,\n                contributor=contributor,\n                oemetadata=load_metadata_from_db(table=table_obj.name),\n            )\n            table_review.save(review_type=review_post_type)\n        else:\n            # Aktiver PeerReview ist vorhanden ... aktualisieren\n            current_review_data = active_peer_review.review\n            merged_review_data = merge_field_reviews(\n                current_json=current_review_data, new_json=review_datamodel\n            )\n\n            # Set new review values and update existing review\n            active_peer_review.review = merged_review_data\n            active_peer_review.reviewer = user  # type:ignore TODO why type warning?\n            active_peer_review.contributor = contributor  # type:ignore TODO\n            active_peer_review.update(review_type=review_post_type)\n    else:\n        error_msg = (\n            \"Failed to retrieve any user that identifies \"\n            f\"as table holder for the current table: {table_obj.name}!\"\n        )\n        return JsonResponse({\"error\": error_msg}, status=400)\n\n    # TODO: Check for topic as reviewed finished also indicates the table\n    # needs to be or has to be moved.\n    if review_finished is True:\n        review_table = Table.load(name=table_obj.name)\n        review_table.set_is_reviewed()\n        metadata = self.load_json(table_obj.name, review_id=review_id)\n        updated_metadata = recursive_update(metadata, review_data)\n        save_metadata_to_db(table_obj.name, updated_metadata)\n        active_peer_review = PeerReview.load(table=table_obj.name)\n\n        if active_peer_review:\n            updated_oemetadata = recursive_update(\n                active_peer_review.oemetadata, review_data\n            )\n            active_peer_review.oemetadata = updated_oemetadata\n            active_peer_review.save()\n\n        # TODO: also update reviewFinished in review datamodel json\n\n    return render(request, \"dataedit/opr_review.html\", context=context)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.views.TablePeerReviewView.sort_in_category","title":"<code>sort_in_category(table, oemetadata)</code>","text":"<p>Group flattened OEMetadata v2 fields into thematic buckets and attach placeholders required by the review UI.</p> <p>Each entry has six keys: {   \"field\": \"\",   \"label\": \".'&gt;\",   \"value\": \"\",   \"newValue\": \"\",   \"reviewer_suggestion\": \"\",   \"suggestion_comment\": \"\" } Source code in <code>dataedit/views.py</code> <pre><code>def sort_in_category(self, table: str, oemetadata):\n    \"\"\"\n    Group flattened OEMetadata v2 fields into thematic buckets and attach\n    placeholders required by the review UI.\n\n    Each entry has six keys:\n    {\n      \"field\": \"&lt;dot-path&gt;\",\n      \"label\": \"&lt;display label without 'resources.&lt;idx&gt;.'&gt;\",\n      \"value\": \"&lt;current value&gt;\",\n      \"newValue\": \"\",\n      \"reviewer_suggestion\": \"\",\n      \"suggestion_comment\": \"\"\n    }\n    \"\"\"\n\n    flattened = self.parse_keys(oemetadata)\n    flattened = [\n        item for item in flattened if item[\"field\"].startswith(\"resources.\")\n    ]\n\n    bucket_map = {\n        \"spatial\": \"spatial\",\n        \"temporal\": \"temporal\",\n        \"sources\": \"source\",\n        \"licenses\": \"license\",\n    }\n\n    def make_label(dot_path: str) -&gt; str:\n        # remove leading resources.&lt;idx&gt;.\n        trimmed = re.sub(r\"^resources\\.[0-9]+\\.\", \"\", dot_path)\n        parts = trimmed.split(\".\")\n        out = []\n        for p in parts:\n            if p in {\"@id\", \"@type\"}:\n                out.append(p)\n            else:\n                out.append(p.replace(\"_\", \" \"))\n        if out:\n            out[0] = out[0][:1].upper() + out[0][1:]\n        return \" \".join(out)\n\n    tmp = defaultdict(list)\n\n    for item in flattened:\n        raw_key = item[\"field\"]\n        parts = raw_key.split(\".\")\n\n        if parts[0] == \"resources\" and len(parts) &gt;= 3:\n            root = parts[2]\n        else:\n            root = parts[0]\n\n        bucket = bucket_map.get(root, \"general\")\n\n        tmp[bucket].append(\n            {\n                \"field\": raw_key,\n                \"label\": make_label(raw_key),\n                \"value\": item[\"value\"],\n                \"newValue\": \"\",\n                \"reviewer_suggestion\": \"\",\n                \"suggestion_comment\": \"\",\n            }\n        )\n\n    return {\n        \"general\": tmp[\"general\"],\n        \"spatial\": tmp[\"spatial\"],\n        \"temporal\": tmp[\"temporal\"],\n        \"source\": tmp[\"source\"],\n        \"license\": tmp[\"license\"],\n    }\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#peerrreviewcontributorview","title":"PeerRreviewContributorView","text":"<p>View for the contributor role of the Open Peer Review process.</p> <p>               Bases: <code>TablePeerReviewView</code></p> <p>A view handling the contributor's side of the peer review process. This view supports rendering the review template and handling GET and POST requests for contributor's review.</p> Source code in <code>dataedit/views.py</code> <pre><code>class TablePeerRreviewContributorView(TablePeerReviewView):\n    \"\"\"\n    A view handling the contributor's side of the peer review process.\n    This view supports rendering the review template and handling GET and\n    POST requests for contributor's review.\n    \"\"\"\n\n    def get(self, request: HttpRequest, table: str, review_id: int) -&gt; HttpResponse:\n        \"\"\"\n        Handle GET requests for contributor's review. Loads necessary data and\n        renders the contributor review template.\n\n        Args:\n            request (HttpRequest): The incoming HTTP GET request.\n            table (str): The name of the table.\n            review_id (int): The ID of the review.\n\n        Returns:\n            HttpResponse: Rendered HTML response for contributor review.\n        \"\"\"\n        table_obj = table_or_404(table=table)\n\n        can_add = False\n        peer_review = PeerReview.objects.get(id=review_id)\n\n        user: login_models.myuser = request.user  # type: ignore\n        if not user.is_anonymous:\n            level = user.get_table_permission_level(table_obj)\n            can_add = level &gt;= login.permissions.WRITE_PERM\n        oemetadata = self.load_json(table_obj.name, review_id)\n        metadata = self.sort_in_category(table_obj.name, oemetadata=oemetadata)\n        json_schema = self.load_json_schema()\n        field_descriptions = self.get_all_field_descriptions(json_schema)\n        review_data = (peer_review.review or {}).get(\"reviews\", [])\n\n        categories = [\n            \"general\",\n            \"spatial\",\n            \"temporal\",\n            \"source\",\n            \"license\",\n        ]\n        state_dict = process_review_data(\n            review_data=review_data, metadata=metadata, categories=categories\n        )\n        context_meta = {\n            \"config\": json.dumps(\n                {\n                    \"can_add\": can_add,\n                    \"url_peer_review\": reverse(\n                        \"dataedit:peer_review_contributor\",\n                        kwargs={\n                            \"table\": table_obj.name,\n                            \"review_id\": review_id,\n                        },\n                    ),\n                    \"url_table\": reverse(\n                        \"dataedit:view\", kwargs={\"table\": table_obj.name}\n                    ),\n                    \"topic\": table_obj.topics,\n                    \"table\": table_obj.name,\n                }\n            ),\n            \"table\": table_obj.name,\n            \"topic\": table_obj.topics,\n            \"meta\": metadata,\n            \"json_schema\": json_schema,\n            \"field_descriptions_json\": json.dumps(field_descriptions),\n            \"state_dict\": json.dumps(state_dict),\n        }\n        return render(request, \"dataedit/opr_contributor.html\", context=context_meta)\n\n    def post(self, request: HttpRequest, table: str, review_id: int) -&gt; HttpResponse:\n        \"\"\"\n        Handle POST requests for contributor's review. Merges and updates\n        the review data in the PeerReview table.\n\n        Args:\n            request (HttpRequest): The incoming HTTP POST request.\n            table (str): The name of the table.\n            review_id (int): The ID of the review.\n\n        Returns:\n            HttpResponse: Rendered HTML response for contributor review.\n\n        \"\"\"\n        # table_obj = table_or_404(table=table)\n        # TODO: why unused argument \"table\"?\n\n        context = {}\n        if request.method == \"POST\":\n            review_data = json.loads(request.body)\n            review_post_type = review_data.get(\"reviewType\")\n            review_datamodel = review_data.get(\"reviewData\")\n            current_opr = PeerReviewManager.get_opr_by_id(opr_id=review_id)\n            existing_reviews = current_opr.review\n            merged_review = merge_field_reviews(\n                current_json=existing_reviews, new_json=review_datamodel\n            )\n\n            current_opr.review = merged_review\n            current_opr.update(review_type=review_post_type)\n\n        return render(request, \"dataedit/opr_contributor.html\", context=context)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.views.TablePeerRreviewContributorView.get","title":"<code>get(request, table, review_id)</code>","text":"<p>Handle GET requests for contributor's review. Loads necessary data and renders the contributor review template.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP GET request.</p> required <code>table</code> <code>str</code> <p>The name of the table.</p> required <code>review_id</code> <code>int</code> <p>The ID of the review.</p> required <p>Returns:</p> Name Type Description <code>HttpResponse</code> <code>HttpResponse</code> <p>Rendered HTML response for contributor review.</p> Source code in <code>dataedit/views.py</code> <pre><code>def get(self, request: HttpRequest, table: str, review_id: int) -&gt; HttpResponse:\n    \"\"\"\n    Handle GET requests for contributor's review. Loads necessary data and\n    renders the contributor review template.\n\n    Args:\n        request (HttpRequest): The incoming HTTP GET request.\n        table (str): The name of the table.\n        review_id (int): The ID of the review.\n\n    Returns:\n        HttpResponse: Rendered HTML response for contributor review.\n    \"\"\"\n    table_obj = table_or_404(table=table)\n\n    can_add = False\n    peer_review = PeerReview.objects.get(id=review_id)\n\n    user: login_models.myuser = request.user  # type: ignore\n    if not user.is_anonymous:\n        level = user.get_table_permission_level(table_obj)\n        can_add = level &gt;= login.permissions.WRITE_PERM\n    oemetadata = self.load_json(table_obj.name, review_id)\n    metadata = self.sort_in_category(table_obj.name, oemetadata=oemetadata)\n    json_schema = self.load_json_schema()\n    field_descriptions = self.get_all_field_descriptions(json_schema)\n    review_data = (peer_review.review or {}).get(\"reviews\", [])\n\n    categories = [\n        \"general\",\n        \"spatial\",\n        \"temporal\",\n        \"source\",\n        \"license\",\n    ]\n    state_dict = process_review_data(\n        review_data=review_data, metadata=metadata, categories=categories\n    )\n    context_meta = {\n        \"config\": json.dumps(\n            {\n                \"can_add\": can_add,\n                \"url_peer_review\": reverse(\n                    \"dataedit:peer_review_contributor\",\n                    kwargs={\n                        \"table\": table_obj.name,\n                        \"review_id\": review_id,\n                    },\n                ),\n                \"url_table\": reverse(\n                    \"dataedit:view\", kwargs={\"table\": table_obj.name}\n                ),\n                \"topic\": table_obj.topics,\n                \"table\": table_obj.name,\n            }\n        ),\n        \"table\": table_obj.name,\n        \"topic\": table_obj.topics,\n        \"meta\": metadata,\n        \"json_schema\": json_schema,\n        \"field_descriptions_json\": json.dumps(field_descriptions),\n        \"state_dict\": json.dumps(state_dict),\n    }\n    return render(request, \"dataedit/opr_contributor.html\", context=context_meta)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.views.TablePeerRreviewContributorView.post","title":"<code>post(request, table, review_id)</code>","text":"<p>Handle POST requests for contributor's review. Merges and updates the review data in the PeerReview table.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP POST request.</p> required <code>table</code> <code>str</code> <p>The name of the table.</p> required <code>review_id</code> <code>int</code> <p>The ID of the review.</p> required <p>Returns:</p> Name Type Description <code>HttpResponse</code> <code>HttpResponse</code> <p>Rendered HTML response for contributor review.</p> Source code in <code>dataedit/views.py</code> <pre><code>def post(self, request: HttpRequest, table: str, review_id: int) -&gt; HttpResponse:\n    \"\"\"\n    Handle POST requests for contributor's review. Merges and updates\n    the review data in the PeerReview table.\n\n    Args:\n        request (HttpRequest): The incoming HTTP POST request.\n        table (str): The name of the table.\n        review_id (int): The ID of the review.\n\n    Returns:\n        HttpResponse: Rendered HTML response for contributor review.\n\n    \"\"\"\n    # table_obj = table_or_404(table=table)\n    # TODO: why unused argument \"table\"?\n\n    context = {}\n    if request.method == \"POST\":\n        review_data = json.loads(request.body)\n        review_post_type = review_data.get(\"reviewType\")\n        review_datamodel = review_data.get(\"reviewData\")\n        current_opr = PeerReviewManager.get_opr_by_id(opr_id=review_id)\n        existing_reviews = current_opr.review\n        merged_review = merge_field_reviews(\n            current_json=existing_reviews, new_json=review_datamodel\n        )\n\n        current_opr.review = merged_review\n        current_opr.update(review_type=review_post_type)\n\n    return render(request, \"dataedit/opr_contributor.html\", context=context)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#helper-functions","title":"Helper Functions","text":"<p>Separated functionality that can be imported in other modules. It contains several functions that help with recurring tasks in the peer review system.</p> <p>Provide helper functionality for views to reduce code lines in views.py make the codebase more modular.</p> <p>SPDX-FileCopyrightText: 2025 Christian Winger https://github.com/wingechr \u00a9 \u00d6ko-Institut e.V. SPDX-FileCopyrightText: 2025 Daryna Barabanova https://github.com/Darynarli \u00a9 Reiner Lemoine Institut SPDX-FileCopyrightText: 2025 Jonas Huber https://github.com/jh-RLI \u00a9 Reiner Lemoine Institut SPDX-FileCopyrightText: 2025 Jonas Huber https://github.com/jh-RLI \u00a9 Reiner Lemoine Institut SPDX-FileCopyrightText: 2025 Jonas Huber https://github.com/jh-RLI \u00a9 Reiner Lemoine Institut SPDX-FileCopyrightText: 2025 user https://github.com/Darynarli \u00a9 Reiner Lemoine Institut SPDX-License-Identifier: AGPL-3.0-or-later</p>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.add_tag","title":"<code>add_tag(name, color)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>max 40 character tag text</p> required <code>color</code> <code>str</code> <p>hexadecimal color code, eg #aaf0f0</p> required Source code in <code>dataedit/helper.py</code> <pre><code>def add_tag(name: str, color: str) -&gt; None:\n    \"\"\"\n    Args:\n        name(str): max 40 character tag text\n        color(str): hexadecimal color code, eg #aaf0f0\n    \"\"\"\n    Tag(name=name, color=Tag.color_from_hex(color)).save()\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.change_requests","title":"<code>change_requests(table_obj)</code>","text":"<p>Loads the dataedit admin interface :param request: :return:</p> Source code in <code>dataedit/helper.py</code> <pre><code>def change_requests(table_obj: Table):\n    \"\"\"\n    Loads the dataedit admin interface\n    :param request:\n    :return:\n    \"\"\"\n    # I want to display old and new data, if different.\n\n    display_message = None\n    api_columns = get_column_changes(reviewed=False, table_obj=table_obj)\n    api_constraints = get_constraints_changes(reviewed=False, table_obj=table_obj)\n\n    data = dict()\n\n    data[\"api_columns\"] = {}\n    data[\"api_constraints\"] = {}\n\n    keyword_whitelist = [\n        \"column_name\",\n        \"c_table\",\n        \"c_schema\",\n        \"reviewed\",\n        \"changed\",\n        \"id\",\n    ]\n\n    old_description = describe_columns(table_obj)\n\n    for change in api_columns:\n        name = change[\"column_name\"]\n        id = change[\"id\"]\n\n        # Identifing over 'new'.\n        if change.get(\"new_name\") is not None:\n            change[\"column_name\"] = change[\"new_name\"]\n\n        old_cd = old_description.get(name)\n\n        data[\"api_columns\"][id] = {}\n        data[\"api_columns\"][id][\"old\"] = {}\n\n        if old_cd is not None:\n            old = api.parser.parse_scolumnd_from_columnd(\n                table_obj, name, old_description.get(name)\n            )\n\n            for key in list(change):\n                value = change[key]\n                if key not in keyword_whitelist and (\n                    value is None or value == old[key]\n                ):\n                    old.pop(key)\n                    change.pop(key)\n            data[\"api_columns\"][id][\"old\"] = old\n        else:\n            data[\"api_columns\"][id][\"old\"][\"c_schema\"] = table_obj.oedb_schema\n            data[\"api_columns\"][id][\"old\"][\"c_table\"] = table_obj.name\n            data[\"api_columns\"][id][\"old\"][\"column_name\"] = name\n\n        data[\"api_columns\"][id][\"new\"] = change\n\n    for i in range(len(api_constraints)):\n        value = api_constraints[i]\n        id = value.get(\"id\")\n        if (\n            value.get(\"reference_table\") is None\n            or value.get(\"reference_column\") is None\n        ):\n            value.pop(\"reference_table\")\n            value.pop(\"reference_column\")\n\n        data[\"api_constraints\"][id] = value\n\n    display_style = [\n        \"c_schema\",\n        \"c_table\",\n        \"column_name\",\n        \"not_null\",\n        \"data_type\",\n        \"reference_table\",\n        \"constraint_parameter\",\n        \"reference_column\",\n        \"action\",\n        \"constraint_type\",\n        \"constraint_name\",\n    ]\n\n    return {\n        \"data\": data,\n        \"display_items\": display_style,\n        \"display_message\": display_message,\n    }\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.delete_peer_review","title":"<code>delete_peer_review(review_id)</code>","text":"<p>Remove Peer Review by review_id. Args:     review_id (int): ID review.</p> <p>Returns:</p> Name Type Description <code>JsonResponse</code> <p>JSON response about successful deletion or error.</p> Source code in <code>dataedit/helper.py</code> <pre><code>def delete_peer_review(review_id):\n    \"\"\"\n    Remove Peer Review by review_id.\n    Args:\n        review_id (int): ID review.\n\n    Returns:\n        JsonResponse: JSON response about successful deletion or error.\n    \"\"\"\n    if review_id:\n        peer_review = PeerReview.objects.filter(id=review_id).first()\n        if peer_review:\n            peer_review.delete()\n            return JsonResponse({\"message\": \"PeerReview successfully deleted.\"})\n        else:\n            return JsonResponse({\"error\": \"PeerReview not found.\"}, status=404)\n    else:\n        return JsonResponse({\"error\": \"Review ID is required.\"}, status=400)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.edit_tag","title":"<code>edit_tag(id, name, color)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>id</code> <code>int</code> <p>tag id</p> required <code>name</code> <code>str</code> <p>max 40 character tag text</p> required <code>color</code> <code>str</code> <p>hexadecimal color code, eg #aaf0f0</p> required Source code in <code>dataedit/helper.py</code> <pre><code>def edit_tag(id: str, name: str, color: str) -&gt; None:\n    \"\"\"\n    Args:\n        id(int): tag id\n        name(str): max 40 character tag text\n        color(str): hexadecimal color code, eg #aaf0f0\n\n    \"\"\"\n    tag = Tag.objects.get(pk=id)\n    tag.name = name\n    tag.color = Tag.color_from_hex(color)\n    tag.save()\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.find_tables","title":"<code>find_tables(topic_name=None, query_string=None, tag_ids=None)</code>","text":"<p>find tables given search criteria</p> <p>Parameters:</p> Name Type Description Default <code>topic_name</code> <code>str</code> <p>only tables in this topic</p> <code>None</code> <code>query_string</code> <code>str</code> <p>user search term</p> <code>None</code> <code>tag_ids</code> <code>list</code> <p>list of tag ids</p> <code>None</code> <p>Returns:</p> Type Description <code>QuerySet[Table]</code> <p>QuerySet of Table objetcs</p> Source code in <code>dataedit/helper.py</code> <pre><code>def find_tables(\n    topic_name: str | None = None,\n    query_string: str | None = None,\n    tag_ids: list[str] | None = None,\n) -&gt; QuerySet[Table]:\n    \"\"\"find tables given search criteria\n\n    Args:\n        topic_name (str, optional): only tables in this topic\n        query_string (str, optional): user search term\n        tag_ids (list, optional): list of tag ids\n\n    Returns:\n        QuerySet of Table objetcs\n    \"\"\"\n\n    tables = Table.objects\n\n    tables = tables.filter(is_sandbox=False)\n\n    if topic_name:\n        if topic_name == PSEUDO_TOPIC_DRAFT:\n            tables = tables.filter(is_publish=False)\n        else:\n            tables = tables.filter(topics__pk=topic_name)\n\n    if query_string:  # filter by search terms\n        tables = tables.filter(\n            Q(\n                search=SearchQuery(\n                    \" &amp; \".join(p + \":*\" for p in re.findall(r\"[\\w]+\", query_string)),\n                    search_type=\"raw\",\n                )\n            )\n        )\n\n    if tag_ids:  # filter by tags:\n        # find tables that use all of the tags\n        # by adding a filter for each tag\n        # (instead of all at once, which would be OR)\n        for tag_id in tag_ids:\n            tables = tables.filter(tags__pk=tag_id)\n\n    return tables\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.get_all_tags","title":"<code>get_all_tags(table_name=None)</code>","text":"<p>Load all tags of a specific table :param table: Name of a table :return:</p> Source code in <code>dataedit/helper.py</code> <pre><code>def get_all_tags(table_name: str | None = None) -&gt; QuerySet[Tag]:\n    \"\"\"\n    Load all tags of a specific table\n    :param table: Name of a table\n    :return:\n    \"\"\"\n    if table_name:\n        tags = Table.objects.get(name=table_name).tags.all()\n    else:\n        tags = Tag.objects.all()\n\n    return tags\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.get_column_description","title":"<code>get_column_description(table_obj)</code>","text":"<p>Return list of column descriptions: [{    \"name\": str,    \"data_type\": str,    \"is_nullable': bool,    \"is_pk\": bool }]</p> Source code in <code>dataedit/helper.py</code> <pre><code>def get_column_description(table_obj: Table):\n    \"\"\"Return list of column descriptions:\n    [{\n       \"name\": str,\n       \"data_type\": str,\n       \"is_nullable': bool,\n       \"is_pk\": bool\n    }]\n\n    \"\"\"\n\n    def get_datatype_str(column_def):\n        \"\"\"get single string sql type definition.\n\n        We want the data type definition to be a simple string, e.g. decimal(10, 6)\n        or varchar(128), so we need to combine the various fields\n        (type, numeric_precision, numeric_scale, ...)\n        \"\"\"\n        # for reverse validation, see also api.parser.parse_type(dt_string)\n        dt = column_def[\"data_type\"].lower()\n        precisions = None\n        if dt.startswith(\"character\"):\n            if dt == \"character varying\":\n                dt = \"varchar\"\n            else:\n                dt = \"char\"\n            precisions = [column_def[\"character_maximum_length\"]]\n        elif dt.endswith(\" without time zone\"):  # this is the default\n            dt = dt.replace(\" without time zone\", \"\")\n        elif re.match(\"(numeric|decimal)\", dt):\n            precisions = [column_def[\"numeric_precision\"], column_def[\"numeric_scale\"]]\n        elif dt == \"interval\":\n            precisions = [column_def[\"interval_precision\"]]\n        elif re.match(\".*int\", dt) and re.match(\n            \"nextval\", column_def.get(\"column_default\") or \"\"\n        ):\n            # dt = dt.replace('int', 'serial')\n            pass\n        elif dt.startswith(\"double\"):\n            dt = \"float\"\n        if precisions:  # remove None\n            precisions = [x for x in precisions if x is not None]\n        if precisions:\n            dt += \"(%s)\" % \", \".join(str(x) for x in precisions)\n        return dt\n\n    def get_pk_fields(constraints):\n        \"\"\"Get the column names that make up the primary key\n        from the constraints definitions.\n\n        NOTE: Currently, the wizard to create tables only supports\n            single fields primary keys (which is advisable anyways)\n        \"\"\"\n        pk_fields = []\n        for _name, constraint in constraints.items():\n            if constraint.get(\"constraint_type\") == \"PRIMARY KEY\":\n                m = re.match(\n                    r\"PRIMARY KEY[ ]*\\(([^)]+)\", constraint.get(\"definition\") or \"\"\n                )\n                if m:\n                    # \"f1, f2\" -&gt; [\"f1\", \"f2\"]\n                    pk_fields = [x.strip() for x in m.groups()[0].split(\",\")]\n        return pk_fields\n\n    _columns = describe_columns(table_obj)\n    _constraints = describe_constraints(table_obj)\n    pk_fields = get_pk_fields(_constraints)\n    # order by ordinal_position\n    columns = []\n    for name, col in sorted(\n        _columns.items(), key=lambda kv: int(kv[1][\"ordinal_position\"])\n    ):\n        columns.append(\n            {\n                \"name\": name,\n                \"data_type\": get_datatype_str(col),\n                \"is_nullable\": col[\"is_nullable\"],\n                \"is_pk\": name in pk_fields,\n                \"unit\": None,\n                \"description\": None,\n            }\n        )\n    return columns\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.get_review_for_key","title":"<code>get_review_for_key(key, review_data)</code>","text":"<p>Retrieve the review for a specific key from the review data.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key for which to retrieve the review. review_data (dict): The review data containing reviews for various keys.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>The new value associated with the specified key in the review data, or None if the key is not found.</p> Source code in <code>dataedit/helper.py</code> <pre><code>def get_review_for_key(key, review_data):\n    \"\"\"\n    Retrieve the review for a specific key from the review data.\n\n    Args:\n        key (str): The key for which to retrieve the review.\n            review_data (dict): The review data containing\n            reviews for various keys.\n\n    Returns:\n        Any: The new value associated with the specified key\n            in the review data, or None if the key is not found.\n    \"\"\"\n\n    for review in review_data[\"reviewData\"][\"reviews\"]:\n        if review[\"key\"] == key:\n            return review[\"fieldReview\"].get(\"newValue\", None)\n    return None\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.merge_field_reviews","title":"<code>merge_field_reviews(current_json, new_json)</code>","text":"<p>Merge reviews from contributors and reviewers into a single JSON object.</p> <p>Parameters:</p> Name Type Description Default <code>current_json</code> <code>dict</code> <p>The current JSON object containing reviewer's reviews.</p> required <code>new_json</code> <code>dict</code> <p>The new JSON object containing contributor's reviews.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>The merged JSON object containing both contributor's and reviewer's reviews.</p> Note <p>If the same key is present in both the contributor's and     reviewer's reviews, the function will merge the field     evaluations. Otherwise, it will create a new entry in     the Review-Dict.</p> Source code in <code>dataedit/helper.py</code> <pre><code>def merge_field_reviews(current_json, new_json):\n    \"\"\"\n    Merge reviews from contributors and reviewers into a single JSON object.\n\n    Args:\n        current_json (dict): The current JSON object containing\n            reviewer's reviews.\n        new_json (dict): The new JSON object containing contributor's reviews.\n\n    Returns:\n        dict: The merged JSON object containing both contributor's and\n            reviewer's reviews.\n\n    Note:\n        If the same key is present in both the contributor's and\n            reviewer's reviews, the function will merge the field\n            evaluations. Otherwise, it will create a new entry in\n            the Review-Dict.\n    \"\"\"\n    merged_json = new_json.copy()\n    review_dict = {}\n\n    for contrib_review in merged_json[\"reviews\"]:\n        category = contrib_review[\"category\"]\n        key = contrib_review[\"key\"]\n        review_dict[(category, key)] = contrib_review[\"fieldReview\"]\n\n    for reviewer_review in current_json[\"reviews\"]:\n        category = reviewer_review[\"category\"]\n        key = reviewer_review[\"key\"]\n\n        if (category, key) in review_dict:\n            # Add field evaluations to the existing entry\n            existing_field_review = review_dict[(category, key)]\n            if isinstance(existing_field_review, dict):\n                existing_field_review = [existing_field_review]\n            if isinstance(reviewer_review[\"fieldReview\"], dict):\n                reviewer_review[\"fieldReview\"] = [reviewer_review[\"fieldReview\"]]\n            merged_field_review = existing_field_review + reviewer_review[\"fieldReview\"]\n            review_dict[(category, key)] = merged_field_review\n        else:\n            # Create new entry in Review-Dict\n            review_dict[(category, key)] = reviewer_review[\"fieldReview\"]\n\n    # Insert updated field scores back into the JSON\n    merged_json[\"reviews\"] = [\n        {\"category\": category, \"key\": key, \"fieldReview\": review_dict[(category, key)]}\n        for category, key in review_dict\n    ]\n\n    return merged_json\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.recursive_update","title":"<code>recursive_update(metadata, review_data)</code>","text":"<p>Recursively updates metadata with new values from review_data, skipping or removing fields with status 'rejected'.</p> <p>Args: metadata (dict): The original metadata dictionary to update. review_data (dict): The review data containing the new values for various keys.</p> <p>Note: The function iterates through the review data and for each key updates the corresponding value in metadata if the new value is present and is not an empty string, and if the field status is not 'rejected'.</p> Source code in <code>dataedit/helper.py</code> <pre><code>def recursive_update(metadata, review_data):\n    \"\"\"\n    Recursively updates metadata with new values from review_data,\n    skipping or removing fields with status 'rejected'.\n\n    Args:\n    metadata (dict): The original metadata dictionary to update.\n    review_data (dict): The review data containing the new values\n    for various keys.\n\n    Note:\n    The function iterates through the review data and for each key\n    updates the corresponding value in metadata if the new value is\n    present and is not an empty string, and if the field status is\n    not 'rejected'.\n    \"\"\"\n\n    def delete_nested_field(data: list | dict | None, keys: list[str]):\n        \"\"\"\n        Removes a nested field from a dictionary based on a list of keys.\n\n        Args:\n            data (dict or list): The dictionary or list from which\n            to remove the field.\n            keys (list): A list of keys pointing to the field to remove.\n        \"\"\"\n\n        for key in keys[:-1]:\n            if isinstance(data, list):\n                key = int(key)\n                data = data[key]\n            elif isinstance(data, dict):\n                data = data.get(key)\n            else:\n                raise NotImplementedError()\n\n        last_key = keys[-1]\n        if isinstance(data, list) and last_key.isdigit():\n            index = int(last_key)\n            if 0 &lt;= index &lt; len(data):\n                data.pop(index)\n        elif isinstance(data, dict):\n            data.pop(last_key, None)\n\n    for review_key in review_data[\"reviewData\"][\"reviews\"]:\n        keys = review_key[\"key\"].split(\".\")\n\n        field_review = review_key.get(\"fieldReview\")\n        if isinstance(field_review, list):\n            field_rejected = False\n            for fr in field_review:\n                state = fr.get(\"state\")\n                if state == \"rejected\":\n                    # If a field is rejected, delete it and move on to the next one.\n                    delete_nested_field(metadata, keys)\n                    field_rejected = True\n                    break\n            if field_rejected:\n                continue\n\n            # If the field is not rejected, apply the new value\n            for fr in field_review:\n                new_value = fr.get(\"newValue\", None)\n                if new_value is not None and new_value != \"\":\n                    set_nested_value(metadata, keys, new_value)\n\n        elif isinstance(field_review, dict):\n            state = field_review.get(\"state\")\n            if state == \"rejected\":\n                # If a field is rejected, delete it and move on to the next one.\n                delete_nested_field(metadata, keys)\n                continue\n\n            # If the field is not rejected, apply the new value\n            new_value = field_review.get(\"newValue\", None)\n            if new_value is not None and new_value != \"\":\n                set_nested_value(metadata, keys, new_value)\n\n    return metadata\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.set_nested_value","title":"<code>set_nested_value(metadata, keys, value)</code>","text":"<p>Set a nested value in a dictionary given a sequence of keys.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>dict</code> <p>The dictionary in which to set the value.</p> required <code>keys</code> <code>list</code> <p>A list of keys representing the path to the nested value.</p> required <code>value</code> <code>Any</code> <p>The value to set.</p> required Note <p>The function navigates through the dictionary using the keys and sets the value at the position indicated by the last key in the list.</p> Source code in <code>dataedit/helper.py</code> <pre><code>def set_nested_value(metadata, keys, value):\n    \"\"\"\n    Set a nested value in a dictionary given a sequence of keys.\n\n    Args:\n        metadata (dict): The dictionary in which to set the value.\n        keys (list): A list of keys representing the path to the nested value.\n        value (Any): The value to set.\n\n    Note:\n        The function navigates through the dictionary using the keys\n        and sets the value at the position indicated by the last key in the list.\n    \"\"\"\n\n    for key in keys[:-1]:\n        if key.isdigit():\n            key = int(key)\n        metadata = metadata[key]\n    last_key = keys[-1]\n    if last_key.isdigit():\n        last_key = int(last_key)\n    metadata[last_key] = value\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.helper.update_keywords_from_tags","title":"<code>update_keywords_from_tags(table)</code>","text":"<p>synchronize keywords in metadata with tags</p> Source code in <code>dataedit/helper.py</code> <pre><code>def update_keywords_from_tags(table: Table) -&gt; None:\n    \"\"\"synchronize keywords in metadata with tags\"\"\"\n\n    metadata = load_metadata_from_db(table=table.name)\n\n    keywords = [tag.name_normalized for tag in table.tags.all()]\n    metadata[\"resources\"][0][\"keywords\"] = keywords\n\n    set_table_metadata(table=table.name, metadata=metadata)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#metadata-functions","title":"Metadata Functions","text":"<p>Provide functionality that is related to retrieving and updating the oemetadata resource from the database. The oemetadata is the object of a review.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#save-metadata-to-database","title":"Save Metadata to Database","text":"<p>Save updated metadata for a specific table in the OEP database.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table in the OEP.</p> required <code>updated_metadata</code> <code>dict</code> <p>The updated metadata dictionary.</p> required Note <p>This function loads the table object from the database, updates its metadata field, and then saves the updated table object back to the database.</p> Source code in <code>dataedit/metadata/__init__.py</code> <pre><code>def save_metadata_to_db(table: str, updated_metadata):\n    \"\"\"\n    Save updated metadata for a specific table in the OEP database.\n\n    Args:\n        table (str): The name of the table in the OEP.\n        updated_metadata (dict): The updated metadata dictionary.\n\n    Note:\n        This function loads the table object from the database,\n        updates its metadata field, and then saves the updated\n        table object back to the database.\n    \"\"\"\n\n    # Load the table object\n    table_obj = Table.load(name=table)\n\n    # Update the oemetadata field\n    table_obj.oemetadata = updated_metadata\n\n    # Save the updated table object\n    table_obj.save()\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#load-metadata-from-database","title":"Load Metadata from Database","text":"<p>Load metadata for a specific table from the OEP database.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table in the OEP.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The loaded metadata dictionary.</p> Note <p>The function currently loads metadata from the Table.oemetadata field. There is a consideration to change this function to use a different approach or keep the old functionality (TODO).</p> Source code in <code>dataedit/metadata/__init__.py</code> <pre><code>def load_metadata_from_db(table: str) -&gt; dict:\n    \"\"\"\n    Load metadata for a specific table from the OEP database.\n\n    Args:\n        table (str): The name of the table in the OEP.\n\n    Returns:\n        dict: The loaded metadata dictionary.\n\n    Note:\n        The function currently loads metadata from the Table.oemetadata field.\n        There is a consideration to change this function to use a different approach\n        or keep the old functionality (TODO).\n    \"\"\"\n\n    table_obj = Table.load(name=table)\n    metadata = table_obj.oemetadata\n    if not metadata:\n        # empty / new metadata\n\n        # TODO: the template is full of empty strings, which are not valid metadata\n        # so we use only parts of it\n\n        metaMetadata = OEMETADATA_V20_TEMPLATE[\"metaMetadata\"]\n        name = table_obj.name\n\n        metadata = {\n            \"name\": name,\n            \"resources\": [{\"name\": name}],\n            \"metaMetadata\": metaMetadata,\n        }\n        validate_metadata(metadata, check_license=False)\n\n    return metadata\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#models","title":"Models","text":"<p>Django models.</p>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#peerreview","title":"PeerReview","text":"<p>The model of the Open Peer Review defines what data is stored in the django database about each existing review. Next to the review itself it stores additional data about the the reviewer and contributor user and more. It is used in the PeerReviewManger.</p> <p>Note</p> <p>This model also provides functionality that is directly related to the model. It is up to discussion if we want to keep the functionality inside the model.</p> <p>               Bases: <code>Model</code></p> <p>Represents a peer review in the database.</p> <p>Attributes:</p> Name Type Description <code>table</code> <code>CharField</code> <p>Name of the table being reviewed.</p> <code>reviewer</code> <code>ForeignKey</code> <p>The user who reviews.</p> <code>contributor</code> <code>ForeignKey</code> <p>The user who contributes.</p> <code>is_finished</code> <code>BooleanField</code> <p>Whether the review is finished.</p> <code>date_started</code> <code>DateTimeField</code> <p>When the review started.</p> <code>date_submitted</code> <code>DateTimeField</code> <p>When the review was submitted.</p> <code>date_finished</code> <code>DateTimeField</code> <p>When the review finished.</p> <code>review</code> <code>JSONField</code> <p>The review data in JSON format.</p> Source code in <code>dataedit/models.py</code> <pre><code>class PeerReview(models.Model):\n    \"\"\"\n    Represents a peer review in the database.\n\n    Attributes:\n        table (CharField): Name of the table being reviewed.\n        reviewer (ForeignKey): The user who reviews.\n        contributor (ForeignKey): The user who contributes.\n        is_finished (BooleanField): Whether the review is finished.\n        date_started (DateTimeField): When the review started.\n        date_submitted (DateTimeField): When the review was submitted.\n        date_finished (DateTimeField): When the review finished.\n        review (JSONField): The review data in JSON format.\n    \"\"\"\n\n    table = CharField(max_length=1000, null=False)\n    reviewer = ForeignKey(\n        \"login.myuser\", on_delete=models.CASCADE, related_name=\"reviewed_by\", null=True\n    )\n    contributor = ForeignKey(\n        \"login.myuser\",\n        on_delete=models.CASCADE,\n        related_name=\"review_received\",\n        null=True,\n    )\n    is_finished = BooleanField(null=False, default=False)\n    date_started = DateTimeField(max_length=1000, null=False, default=timezone.now)\n    date_submitted = DateTimeField(max_length=1000, null=True, default=None)\n    date_finished = DateTimeField(max_length=1000, null=True, default=None)\n    review = JSONField(null=True)\n    # TODO: Maybe oemetadata should be stored in a separate table and imported\n    # via FK here / change also for Tables model\n    oemetadata = JSONField(null=False, default=dict)\n\n    review_id: QuerySet[\"PeerReviewManager\"]  # related_name, for static type checking\n    prev_review: QuerySet[\"PeerReviewManager\"]  # related_name, for static type checking\n    next_review: QuerySet[\"PeerReviewManager\"]  # related_name, for static type checking\n\n    # laden\n    @classmethod\n    def load(cls, table: str) -&gt; Union[\"PeerReview\", None]:\n        \"\"\"\n        Load the current reviewer user.\n        The current review is review is determened by the latest date started.\n\n        Args:\n            table (string): Table name\n\n        Returns:\n            opr (PeerReview): PeerReview object related to the latest\n            date started.\n        \"\"\"\n        opr = PeerReview.objects.filter(table=table).order_by(\"-date_started\").first()\n        return opr\n\n    # TODO: CAUTION unfinished work ... fix: includes all id\u00b4s and not just the\n    # related ones (reviews on same table) .. procedures false results\n    def get_prev_and_next_reviews(self, table: str):\n        \"\"\"\n        Sets the prev_review and next_review fields based on the date_started\n        field of the PeerReview objects associated with the same table.\n        \"\"\"\n        # Get all the PeerReview objects associated with the same table name\n        peer_reviews = PeerReview.objects.filter(table=table).order_by(\"date_started\")\n\n        current_index = None\n        for index, review in enumerate(peer_reviews):\n            if review.pk == self.pk:\n                current_index = index\n                break\n\n        prev_review = None\n        next_review = None\n\n        if current_index is not None:\n            if current_index &gt; 0:\n                prev_review = peer_reviews[current_index - 1]\n\n            if current_index &lt; len(peer_reviews) - 1:\n                next_review = peer_reviews[current_index + 1]\n\n        return prev_review, next_review\n\n    def save(self, *args, **kwargs):\n        review_type = kwargs.pop(\"review_type\", None)\n        pm_new = None\n\n        if not self.contributor == self.reviewer:\n            super().save(*args, **kwargs)\n            # TODO: This causes errors if review list ist empty\n\n            if review_type == \"save\":\n                pm_new = PeerReviewManager(\n                    opr=self, status=ReviewDataStatus.SAVED.value\n                )\n\n            elif review_type == \"submit\":\n                result = self.set_version_of_metadata_for_review(table=self.table)\n                if result[0]:\n                    logger.info(result[1])\n                elif result[0] is False:\n                    logger.info(result[1])\n\n                pm_new = PeerReviewManager(\n                    opr=self, status=ReviewDataStatus.SUBMITTED.value\n                )\n                pm_new.set_next_reviewer()\n\n            elif review_type == \"finished\":\n                result = self.set_version_of_metadata_for_review(table=self.table)\n                if result[0]:\n                    logger.info(result[1])\n                elif result[0] is False:\n                    logger.info(result[1])\n\n                pm_new = PeerReviewManager(\n                    opr=self, status=ReviewDataStatus.FINISHED.value\n                )\n                self.is_finished = True\n                self.date_finished = timezone.now()\n                super().save(*args, **kwargs)\n\n            if pm_new:\n                pm_new.save()\n\n        else:\n            raise ValidationError(\"Contributor and reviewer cannot be the same.\")\n\n    def delete(self, *args, **kwargs):\n        \"\"\"\n        Custom delete method to remove related PeerReviewManager entries.\n        \"\"\"\n        # Remove related records in PeerReviewManager\n        PeerReviewManager.objects.filter(opr=self).delete()\n\n        super().delete(*args, **kwargs)\n\n    def update(self, *args, **kwargs):\n        \"\"\"\n        Update the peer review if the latest peer review is not finished yet\n        but either saved or submitted.\n\n        \"\"\"\n\n        review_type = kwargs.pop(\"review_type\", None)\n        if not self.contributor == self.reviewer:\n            current_pm = PeerReviewManager.load(opr=self)\n            if review_type == \"save\":\n                current_pm.status = ReviewDataStatus.SAVED.value\n            elif review_type == \"submit\":\n                current_pm.status = ReviewDataStatus.SUBMITTED.value\n                current_pm.set_next_reviewer()\n            elif review_type == \"finished\":\n                self.is_finished = True\n                self.date_finished = timezone.now()\n                current_pm.status = ReviewDataStatus.FINISHED.value\n\n            # update peere review manager related to this peer review entry\n            current_pm.save()\n            super().save(*args, **kwargs)\n        else:\n            raise ValidationError(\"Contributor and reviewer cannot be the same.\")\n\n    def set_version_of_metadata_for_review(self, table: str, *args, **kwargs):\n        \"\"\"\n        Once the peer review is started, we save the current version of the\n        oemetadata that is present on the table to the peer review instance\n        to be able to do the review to a fixed state of the metadata.\n\n        A started review means a reviewer saves / submits or finishes (in case\n        the review is completed in one go) a review.\n\n        Args:\n            table (str): Table name\n\n        Returns:\n            State (tuple): Bool value that indicates weather there is already\n            a version of oemetadata available for this review &amp; readable\n            status message.\n        \"\"\"\n        table_oemetdata = Table.load(name=table).oemetadata\n\n        if self.oemetadata is None:\n            self.oemetadata = table_oemetdata\n            super().save(*args, **kwargs)\n\n            return (\n                True,\n                f\"Set current version of table's: '{table}' \" \"oemetadata for review.\",\n            )\n\n        return (\n            False,\n            f\"This tables (name: {table}) review \"\n            \"already got a version of oemetadata.\",\n        )\n\n    def update_all_table_peer_reviews_after_table_moved(self, *args, topic, **kwargs):\n        if isinstance(self.review, str):\n            review_data = json.loads(self.review)\n        else:\n            review_data = self.review or {}\n\n        review_data[\"topic\"] = topic\n\n        self.review = review_data\n\n        super().save(*args, **kwargs)\n\n    @property\n    def days_open(self):\n        if self.date_started is None:\n            return None  # Review has not started yet\n        elif self.date_finished:\n            return (self.date_finished - self.date_started).days  # Review has finished\n        else:\n            return (timezone.now() - self.date_started).days  # Review is still open\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReview.delete","title":"<code>delete(*args, **kwargs)</code>","text":"<p>Custom delete method to remove related PeerReviewManager entries.</p> Source code in <code>dataedit/models.py</code> <pre><code>def delete(self, *args, **kwargs):\n    \"\"\"\n    Custom delete method to remove related PeerReviewManager entries.\n    \"\"\"\n    # Remove related records in PeerReviewManager\n    PeerReviewManager.objects.filter(opr=self).delete()\n\n    super().delete(*args, **kwargs)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReview.get_prev_and_next_reviews","title":"<code>get_prev_and_next_reviews(table)</code>","text":"<p>Sets the prev_review and next_review fields based on the date_started field of the PeerReview objects associated with the same table.</p> Source code in <code>dataedit/models.py</code> <pre><code>def get_prev_and_next_reviews(self, table: str):\n    \"\"\"\n    Sets the prev_review and next_review fields based on the date_started\n    field of the PeerReview objects associated with the same table.\n    \"\"\"\n    # Get all the PeerReview objects associated with the same table name\n    peer_reviews = PeerReview.objects.filter(table=table).order_by(\"date_started\")\n\n    current_index = None\n    for index, review in enumerate(peer_reviews):\n        if review.pk == self.pk:\n            current_index = index\n            break\n\n    prev_review = None\n    next_review = None\n\n    if current_index is not None:\n        if current_index &gt; 0:\n            prev_review = peer_reviews[current_index - 1]\n\n        if current_index &lt; len(peer_reviews) - 1:\n            next_review = peer_reviews[current_index + 1]\n\n    return prev_review, next_review\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReview.load","title":"<code>load(table)</code>  <code>classmethod</code>","text":"<p>Load the current reviewer user. The current review is review is determened by the latest date started.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>string</code> <p>Table name</p> required <p>Returns:</p> Name Type Description <code>opr</code> <code>PeerReview</code> <p>PeerReview object related to the latest</p> <code>Union[PeerReview, None]</code> <p>date started.</p> Source code in <code>dataedit/models.py</code> <pre><code>@classmethod\ndef load(cls, table: str) -&gt; Union[\"PeerReview\", None]:\n    \"\"\"\n    Load the current reviewer user.\n    The current review is review is determened by the latest date started.\n\n    Args:\n        table (string): Table name\n\n    Returns:\n        opr (PeerReview): PeerReview object related to the latest\n        date started.\n    \"\"\"\n    opr = PeerReview.objects.filter(table=table).order_by(\"-date_started\").first()\n    return opr\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReview.set_version_of_metadata_for_review","title":"<code>set_version_of_metadata_for_review(table, *args, **kwargs)</code>","text":"<p>Once the peer review is started, we save the current version of the oemetadata that is present on the table to the peer review instance to be able to do the review to a fixed state of the metadata.</p> <p>A started review means a reviewer saves / submits or finishes (in case the review is completed in one go) a review.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name</p> required <p>Returns:</p> Name Type Description <code>State</code> <code>tuple</code> <p>Bool value that indicates weather there is already</p> <p>a version of oemetadata available for this review &amp; readable</p> <p>status message.</p> Source code in <code>dataedit/models.py</code> <pre><code>def set_version_of_metadata_for_review(self, table: str, *args, **kwargs):\n    \"\"\"\n    Once the peer review is started, we save the current version of the\n    oemetadata that is present on the table to the peer review instance\n    to be able to do the review to a fixed state of the metadata.\n\n    A started review means a reviewer saves / submits or finishes (in case\n    the review is completed in one go) a review.\n\n    Args:\n        table (str): Table name\n\n    Returns:\n        State (tuple): Bool value that indicates weather there is already\n        a version of oemetadata available for this review &amp; readable\n        status message.\n    \"\"\"\n    table_oemetdata = Table.load(name=table).oemetadata\n\n    if self.oemetadata is None:\n        self.oemetadata = table_oemetdata\n        super().save(*args, **kwargs)\n\n        return (\n            True,\n            f\"Set current version of table's: '{table}' \" \"oemetadata for review.\",\n        )\n\n    return (\n        False,\n        f\"This tables (name: {table}) review \"\n        \"already got a version of oemetadata.\",\n    )\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReview.update","title":"<code>update(*args, **kwargs)</code>","text":"<p>Update the peer review if the latest peer review is not finished yet but either saved or submitted.</p> Source code in <code>dataedit/models.py</code> <pre><code>def update(self, *args, **kwargs):\n    \"\"\"\n    Update the peer review if the latest peer review is not finished yet\n    but either saved or submitted.\n\n    \"\"\"\n\n    review_type = kwargs.pop(\"review_type\", None)\n    if not self.contributor == self.reviewer:\n        current_pm = PeerReviewManager.load(opr=self)\n        if review_type == \"save\":\n            current_pm.status = ReviewDataStatus.SAVED.value\n        elif review_type == \"submit\":\n            current_pm.status = ReviewDataStatus.SUBMITTED.value\n            current_pm.set_next_reviewer()\n        elif review_type == \"finished\":\n            self.is_finished = True\n            self.date_finished = timezone.now()\n            current_pm.status = ReviewDataStatus.FINISHED.value\n\n        # update peere review manager related to this peer review entry\n        current_pm.save()\n        super().save(*args, **kwargs)\n    else:\n        raise ValidationError(\"Contributor and reviewer cannot be the same.\")\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#peerreviewmanager","title":"PeerReviewManager","text":"<p>The Manager is introduced to be able to store additional information about the peer review process and separate it from the PeerReview model. The process is started by submitting a review and the manager maintains the order of which user has to take the next action to be able to hold and activate the process.</p> <p>Note</p> <p>This model also provides functionality that is directly related to the model. It is up to discussion if we want to keep the functionality inside the model.</p> <p>               Bases: <code>Model</code></p> <p>Manages peer review processes.</p> <p>This model handles the 1:n relation between table and open peer reviews. It tracks the days open for the peer review and its state. It determines who is next in the process between reviewer and contributor. It provides information about the previous and next review. It offers several methods that provide generic filters for the peer reviews.</p> <p>Attributes:</p> Name Type Description <code>opr</code> <code>ForeignKey</code> <p>The associated peer review.</p> <code>current_reviewer</code> <code>CharField</code> <p>The current reviewer.</p> <code>status</code> <code>CharField</code> <p>The current status of the review.</p> <code>is_open_since</code> <code>CharField</code> <p>How long the review has been open.</p> <code>prev_review</code> <code>ForeignKey</code> <p>The previous review in the process.</p> <code>next_review</code> <code>ForeignKey</code> <p>The next review in the process.</p> Source code in <code>dataedit/models.py</code> <pre><code>class PeerReviewManager(models.Model):\n    \"\"\"\n    Manages peer review processes.\n\n    This model handles the 1:n relation between table and open peer reviews.\n    It tracks the days open for the peer review and its state.\n    It determines who is next in the process between reviewer and contributor.\n    It provides information about the previous and next review.\n    It offers several methods that provide generic filters for the peer reviews.\n\n    Attributes:\n        opr (ForeignKey): The associated peer review.\n        current_reviewer (CharField): The current reviewer.\n        status (CharField): The current status of the review.\n        is_open_since (CharField): How long the review has been open.\n        prev_review (ForeignKey): The previous review in the process.\n        next_review (ForeignKey): The next review in the process.\n    \"\"\"\n\n    REVIEW_STATUS = [(status.value, status.name) for status in ReviewDataStatus]\n    REVIEWER_CHOICES = [(choice.value, choice.name) for choice in Reviewer]\n\n    opr = ForeignKey(\n        PeerReview, on_delete=models.CASCADE, related_name=\"review_id\", null=False\n    )\n    current_reviewer = models.CharField(\n        choices=REVIEWER_CHOICES, max_length=20, default=Reviewer.REVIEWER.value\n    )\n    status = models.CharField(\n        choices=REVIEW_STATUS, max_length=10, default=ReviewDataStatus.SAVED.value\n    )\n    is_open_since = models.CharField(null=True, max_length=10)\n    prev_review = ForeignKey(\n        PeerReview,\n        on_delete=models.CASCADE,\n        related_name=\"prev_review\",\n        null=True,\n        default=None,\n    )  # TODO: add logic\n    next_review = ForeignKey(\n        PeerReview,\n        on_delete=models.CASCADE,\n        related_name=\"next_review\",\n        null=True,\n        default=None,\n    )  # TODO: add logic\n\n    @classmethod\n    def load(cls, opr):\n        \"\"\"\n        Load the peer review manager associated with the given peer review.\n\n        Args:\n            opr (PeerReview): The peer review.\n\n        Returns:\n            PeerReviewManager: The peer review manager.\n        \"\"\"\n        peer_review_manager = PeerReviewManager.objects.get(opr=opr)\n        return peer_review_manager\n\n    def save(self, *args, **kwargs):\n        \"\"\"\n        Override the save method to perform additional logic\n        before saving the peer review manager.\n        \"\"\"\n        # Set is_open_since field if it is None\n        if self.is_open_since is None:\n            # Get the associated PeerReview instance\n            peer_review = self.opr\n\n            # Set is_open_since based on the days_open property of the\n            # PeerReview instance\n            days_open = peer_review.days_open\n            if days_open is not None:\n                self.is_open_since = str(days_open)\n        # Call the parent class's save method to save the PeerReviewManager instance\n        super().save(*args, **kwargs)\n\n    @classmethod\n    def update_open_since(cls, opr: PeerReview | None = None, *args, **kwargs):\n        \"\"\"\n        Update the \"is_open_since\" field of the peer review manager.\n\n        Args:\n            opr (PeerReview): The peer review.\n            If None, use the peer review associated with the manager.\n\n        \"\"\"\n        if opr is not None:\n            peer_review_manager = PeerReviewManager.objects.get(opr=opr)\n        else:\n            peer_review_manager = cls()\n\n        days_open = peer_review_manager.opr.days_open\n        peer_review_manager.is_open_since = str(days_open)\n\n        # Call the parent class's save method to save the PeerReviewManager instance\n        peer_review_manager.save(*args, **kwargs)\n\n    def set_next_reviewer(self):\n        \"\"\"\n        Set the order on which peer will be required to perform a action to\n        continue with the process.\n        \"\"\"\n        # TODO:check for user identifies as ...\n        if self.current_reviewer == Reviewer.REVIEWER.value:\n            self.current_reviewer = Reviewer.CONTRIBUTOR.value\n        else:\n            self.current_reviewer = Reviewer.REVIEWER.value\n        self.save()\n\n    def whos_turn(self):\n        \"\"\"\n        Get the user and role (contributor or reviewer) whose turn it is.\n\n        Returns:\n            Tuple[str, User]: The role and user.\n        \"\"\"\n        role, result = None, None\n        peer_review = self.opr\n        if self.current_reviewer == Reviewer.REVIEWER.value:\n            role = Reviewer.REVIEWER.value\n            result = peer_review.reviewer\n        else:\n            role = Reviewer.CONTRIBUTOR.value\n            result = peer_review.contributor\n\n        return role, result\n\n    @staticmethod\n    def load_contributor(table: str):\n        \"\"\"\n        Get the contributor for the table a review is started.\n\n        Args:\n            table (str): Table name.\n\n        Returns:\n            User: The contributor user.\n        \"\"\"\n        current_table = Table.load(name=table)\n        userpermission = current_table.userpermission_set.filter(\n            table=current_table.pk\n        ).first()\n        table_holder = userpermission.holder if userpermission else None\n        return table_holder\n\n    @staticmethod\n    def load_reviewer(table: str):\n        \"\"\"\n        Get the reviewer for the table a review is started.\n\n        Args:\n            table (str): Table name.\n\n        Returns:\n            User: The reviewer user.\n        \"\"\"\n        current_review = PeerReview.load(table=table)\n        if current_review and hasattr(current_review, \"reviewer\"):\n            return current_review.reviewer\n        else:\n            return None\n\n    @staticmethod\n    def filter_opr_by_reviewer(reviewer_user):\n        \"\"\"\n        Filter peer reviews by reviewer, excluding those with current peer\n        is contributor and the data status \"SAVED\" in the peer review manager.\n\n        Args:\n            reviewer_user (User): The reviewer user.\n\n        Returns:\n            QuerySet: Filtered peer reviews.\n        \"\"\"\n        return PeerReview.objects.filter(reviewer=reviewer_user).exclude(\n            review_id__current_reviewer=Reviewer.CONTRIBUTOR.value,\n            review_id__status=ReviewDataStatus.SAVED.value,\n        )\n\n    @staticmethod\n    def filter_latest_open_opr_by_reviewer(reviewer_user):\n        \"\"\"\n        Get the last open peer review for the given contributor.\n\n        Args:\n            contributor_user (User): The contributor user.\n\n        Returns:\n            PeerReview: Last open peer review or None if not found.\n        \"\"\"\n        try:\n            return (\n                PeerReview.objects.filter(reviewer=reviewer_user, is_finished=False)\n                .exclude(\n                    review_id__current_reviewer=Reviewer.CONTRIBUTOR.value,\n                    review_id__status=ReviewDataStatus.SAVED.value,\n                )\n                .latest(\"date_started\")\n            )\n        except PeerReview.DoesNotExist:\n            return None\n\n    @staticmethod\n    def filter_opr_by_contributor(contributor_user):\n        \"\"\"\n        Filter peer reviews by contributor, excluding those with current peer\n        is reviewer and the data status \"SAVED\" in the peer review manager.\n\n        Args:\n            contributor_user (User): The contributor user.\n\n        Returns:\n            QuerySet: Filtered peer reviews.\n        \"\"\"\n\n        return PeerReview.objects.filter(contributor=contributor_user).exclude(\n            review_id__current_reviewer=Reviewer.REVIEWER.value,\n            review_id__status=ReviewDataStatus.SAVED.value,\n        )\n\n    @staticmethod\n    def filter_latest_open_opr_by_contributor(contributor_user):\n        \"\"\"\n        Get the last open peer review for the given contributor.\n\n        Args:\n            contributor_user (User): The contributor user.\n\n        Returns:\n            PeerReview: Last open peer review or None if not found.\n        \"\"\"\n        try:\n            return (\n                PeerReview.objects.filter(\n                    contributor=contributor_user, is_finished=False\n                )\n                .exclude(\n                    review_id__current_reviewer=Reviewer.REVIEWER.value,\n                    review_id__status=ReviewDataStatus.SAVED.value,\n                )\n                .latest(\"date_started\")\n            )\n        except PeerReview.DoesNotExist:\n            return None\n\n    @staticmethod\n    def filter_opr_by_table(table: str) -&gt; QuerySet[PeerReview]:\n        \"\"\"\n        Filter peer reviews by table.\n\n        Args:\n            table (str): Table name.\n\n        Returns:\n            QuerySet: Filtered peer reviews.\n        \"\"\"\n        return PeerReview.objects.filter(table=table)\n\n    @staticmethod\n    def get_opr_by_id(opr_id) -&gt; PeerReview:\n        return PeerReview.objects.get(id=opr_id)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.filter_latest_open_opr_by_contributor","title":"<code>filter_latest_open_opr_by_contributor(contributor_user)</code>  <code>staticmethod</code>","text":"<p>Get the last open peer review for the given contributor.</p> <p>Parameters:</p> Name Type Description Default <code>contributor_user</code> <code>User</code> <p>The contributor user.</p> required <p>Returns:</p> Name Type Description <code>PeerReview</code> <p>Last open peer review or None if not found.</p> Source code in <code>dataedit/models.py</code> <pre><code>@staticmethod\ndef filter_latest_open_opr_by_contributor(contributor_user):\n    \"\"\"\n    Get the last open peer review for the given contributor.\n\n    Args:\n        contributor_user (User): The contributor user.\n\n    Returns:\n        PeerReview: Last open peer review or None if not found.\n    \"\"\"\n    try:\n        return (\n            PeerReview.objects.filter(\n                contributor=contributor_user, is_finished=False\n            )\n            .exclude(\n                review_id__current_reviewer=Reviewer.REVIEWER.value,\n                review_id__status=ReviewDataStatus.SAVED.value,\n            )\n            .latest(\"date_started\")\n        )\n    except PeerReview.DoesNotExist:\n        return None\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.filter_latest_open_opr_by_reviewer","title":"<code>filter_latest_open_opr_by_reviewer(reviewer_user)</code>  <code>staticmethod</code>","text":"<p>Get the last open peer review for the given contributor.</p> <p>Parameters:</p> Name Type Description Default <code>contributor_user</code> <code>User</code> <p>The contributor user.</p> required <p>Returns:</p> Name Type Description <code>PeerReview</code> <p>Last open peer review or None if not found.</p> Source code in <code>dataedit/models.py</code> <pre><code>@staticmethod\ndef filter_latest_open_opr_by_reviewer(reviewer_user):\n    \"\"\"\n    Get the last open peer review for the given contributor.\n\n    Args:\n        contributor_user (User): The contributor user.\n\n    Returns:\n        PeerReview: Last open peer review or None if not found.\n    \"\"\"\n    try:\n        return (\n            PeerReview.objects.filter(reviewer=reviewer_user, is_finished=False)\n            .exclude(\n                review_id__current_reviewer=Reviewer.CONTRIBUTOR.value,\n                review_id__status=ReviewDataStatus.SAVED.value,\n            )\n            .latest(\"date_started\")\n        )\n    except PeerReview.DoesNotExist:\n        return None\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.filter_opr_by_contributor","title":"<code>filter_opr_by_contributor(contributor_user)</code>  <code>staticmethod</code>","text":"<p>Filter peer reviews by contributor, excluding those with current peer is reviewer and the data status \"SAVED\" in the peer review manager.</p> <p>Parameters:</p> Name Type Description Default <code>contributor_user</code> <code>User</code> <p>The contributor user.</p> required <p>Returns:</p> Name Type Description <code>QuerySet</code> <p>Filtered peer reviews.</p> Source code in <code>dataedit/models.py</code> <pre><code>@staticmethod\ndef filter_opr_by_contributor(contributor_user):\n    \"\"\"\n    Filter peer reviews by contributor, excluding those with current peer\n    is reviewer and the data status \"SAVED\" in the peer review manager.\n\n    Args:\n        contributor_user (User): The contributor user.\n\n    Returns:\n        QuerySet: Filtered peer reviews.\n    \"\"\"\n\n    return PeerReview.objects.filter(contributor=contributor_user).exclude(\n        review_id__current_reviewer=Reviewer.REVIEWER.value,\n        review_id__status=ReviewDataStatus.SAVED.value,\n    )\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.filter_opr_by_reviewer","title":"<code>filter_opr_by_reviewer(reviewer_user)</code>  <code>staticmethod</code>","text":"<p>Filter peer reviews by reviewer, excluding those with current peer is contributor and the data status \"SAVED\" in the peer review manager.</p> <p>Parameters:</p> Name Type Description Default <code>reviewer_user</code> <code>User</code> <p>The reviewer user.</p> required <p>Returns:</p> Name Type Description <code>QuerySet</code> <p>Filtered peer reviews.</p> Source code in <code>dataedit/models.py</code> <pre><code>@staticmethod\ndef filter_opr_by_reviewer(reviewer_user):\n    \"\"\"\n    Filter peer reviews by reviewer, excluding those with current peer\n    is contributor and the data status \"SAVED\" in the peer review manager.\n\n    Args:\n        reviewer_user (User): The reviewer user.\n\n    Returns:\n        QuerySet: Filtered peer reviews.\n    \"\"\"\n    return PeerReview.objects.filter(reviewer=reviewer_user).exclude(\n        review_id__current_reviewer=Reviewer.CONTRIBUTOR.value,\n        review_id__status=ReviewDataStatus.SAVED.value,\n    )\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.filter_opr_by_table","title":"<code>filter_opr_by_table(table)</code>  <code>staticmethod</code>","text":"<p>Filter peer reviews by table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name.</p> required <p>Returns:</p> Name Type Description <code>QuerySet</code> <code>QuerySet[PeerReview]</code> <p>Filtered peer reviews.</p> Source code in <code>dataedit/models.py</code> <pre><code>@staticmethod\ndef filter_opr_by_table(table: str) -&gt; QuerySet[PeerReview]:\n    \"\"\"\n    Filter peer reviews by table.\n\n    Args:\n        table (str): Table name.\n\n    Returns:\n        QuerySet: Filtered peer reviews.\n    \"\"\"\n    return PeerReview.objects.filter(table=table)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.load","title":"<code>load(opr)</code>  <code>classmethod</code>","text":"<p>Load the peer review manager associated with the given peer review.</p> <p>Parameters:</p> Name Type Description Default <code>opr</code> <code>PeerReview</code> <p>The peer review.</p> required <p>Returns:</p> Name Type Description <code>PeerReviewManager</code> <p>The peer review manager.</p> Source code in <code>dataedit/models.py</code> <pre><code>@classmethod\ndef load(cls, opr):\n    \"\"\"\n    Load the peer review manager associated with the given peer review.\n\n    Args:\n        opr (PeerReview): The peer review.\n\n    Returns:\n        PeerReviewManager: The peer review manager.\n    \"\"\"\n    peer_review_manager = PeerReviewManager.objects.get(opr=opr)\n    return peer_review_manager\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.load_contributor","title":"<code>load_contributor(table)</code>  <code>staticmethod</code>","text":"<p>Get the contributor for the table a review is started.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name.</p> required <p>Returns:</p> Name Type Description <code>User</code> <p>The contributor user.</p> Source code in <code>dataedit/models.py</code> <pre><code>@staticmethod\ndef load_contributor(table: str):\n    \"\"\"\n    Get the contributor for the table a review is started.\n\n    Args:\n        table (str): Table name.\n\n    Returns:\n        User: The contributor user.\n    \"\"\"\n    current_table = Table.load(name=table)\n    userpermission = current_table.userpermission_set.filter(\n        table=current_table.pk\n    ).first()\n    table_holder = userpermission.holder if userpermission else None\n    return table_holder\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.load_reviewer","title":"<code>load_reviewer(table)</code>  <code>staticmethod</code>","text":"<p>Get the reviewer for the table a review is started.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name.</p> required <p>Returns:</p> Name Type Description <code>User</code> <p>The reviewer user.</p> Source code in <code>dataedit/models.py</code> <pre><code>@staticmethod\ndef load_reviewer(table: str):\n    \"\"\"\n    Get the reviewer for the table a review is started.\n\n    Args:\n        table (str): Table name.\n\n    Returns:\n        User: The reviewer user.\n    \"\"\"\n    current_review = PeerReview.load(table=table)\n    if current_review and hasattr(current_review, \"reviewer\"):\n        return current_review.reviewer\n    else:\n        return None\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.save","title":"<code>save(*args, **kwargs)</code>","text":"<p>Override the save method to perform additional logic before saving the peer review manager.</p> Source code in <code>dataedit/models.py</code> <pre><code>def save(self, *args, **kwargs):\n    \"\"\"\n    Override the save method to perform additional logic\n    before saving the peer review manager.\n    \"\"\"\n    # Set is_open_since field if it is None\n    if self.is_open_since is None:\n        # Get the associated PeerReview instance\n        peer_review = self.opr\n\n        # Set is_open_since based on the days_open property of the\n        # PeerReview instance\n        days_open = peer_review.days_open\n        if days_open is not None:\n            self.is_open_since = str(days_open)\n    # Call the parent class's save method to save the PeerReviewManager instance\n    super().save(*args, **kwargs)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.set_next_reviewer","title":"<code>set_next_reviewer()</code>","text":"<p>Set the order on which peer will be required to perform a action to continue with the process.</p> Source code in <code>dataedit/models.py</code> <pre><code>def set_next_reviewer(self):\n    \"\"\"\n    Set the order on which peer will be required to perform a action to\n    continue with the process.\n    \"\"\"\n    # TODO:check for user identifies as ...\n    if self.current_reviewer == Reviewer.REVIEWER.value:\n        self.current_reviewer = Reviewer.CONTRIBUTOR.value\n    else:\n        self.current_reviewer = Reviewer.REVIEWER.value\n    self.save()\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.update_open_since","title":"<code>update_open_since(opr=None, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Update the \"is_open_since\" field of the peer review manager.</p> <p>Parameters:</p> Name Type Description Default <code>opr</code> <code>PeerReview</code> <p>The peer review.</p> <code>None</code> Source code in <code>dataedit/models.py</code> <pre><code>@classmethod\ndef update_open_since(cls, opr: PeerReview | None = None, *args, **kwargs):\n    \"\"\"\n    Update the \"is_open_since\" field of the peer review manager.\n\n    Args:\n        opr (PeerReview): The peer review.\n        If None, use the peer review associated with the manager.\n\n    \"\"\"\n    if opr is not None:\n        peer_review_manager = PeerReviewManager.objects.get(opr=opr)\n    else:\n        peer_review_manager = cls()\n\n    days_open = peer_review_manager.opr.days_open\n    peer_review_manager.is_open_since = str(days_open)\n\n    # Call the parent class's save method to save the PeerReviewManager instance\n    peer_review_manager.save(*args, **kwargs)\n</code></pre>"},{"location":"oeplatform-code/features/open-peer-review-process/technical-docs/#dataedit.models.PeerReviewManager.whos_turn","title":"<code>whos_turn()</code>","text":"<p>Get the user and role (contributor or reviewer) whose turn it is.</p> <p>Returns:</p> Type Description <p>Tuple[str, User]: The role and user.</p> Source code in <code>dataedit/models.py</code> <pre><code>def whos_turn(self):\n    \"\"\"\n    Get the user and role (contributor or reviewer) whose turn it is.\n\n    Returns:\n        Tuple[str, User]: The role and user.\n    \"\"\"\n    role, result = None, None\n    peer_review = self.opr\n    if self.current_reviewer == Reviewer.REVIEWER.value:\n        role = Reviewer.REVIEWER.value\n        result = peer_review.reviewer\n    else:\n        role = Reviewer.CONTRIBUTOR.value\n        result = peer_review.contributor\n\n    return role, result\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/","title":"Index","text":""},{"location":"oeplatform-code/features/scenario-bundles/#scenario-bundles-feature","title":"Scenario Bundles feature","text":"<p>The scenario bundles feature is a response to the complex requirements for the transparent publication of scenarios in a complete and comprehensible manner. Various technologies are used to enable researchers to publish scenarios and any additional information. In addition, existing resources from the open energy platform are used and bundled together. This is intended to increase the visibility of available research work and enable comparability of the scenarios.</p>"},{"location":"oeplatform-code/features/scenario-bundles/#what-are-scenario-bundles-in-detail","title":"What are Scenario Bundles in detail?","text":"<p>Please continue reading here.</p>"},{"location":"oeplatform-code/features/scenario-bundles/#technologies","title":"Technologies","text":"<p>User Interface</p> <ul> <li>We offer a modern user interface developed with the REACT library.</li> </ul> <p>Backend &amp; Web-API</p> <ul> <li>We build on the backend of the Open Energy Platform and use Django to   implement functionalities such as saving and deleting scenario bundles and   thus enable communication with the database. In addition, Django provides the   WEB-API endpoints that are used to create a scenario bundle or query the   database using JSON requests, for example.</li> <li>A Python integration of the SPARQL query language is used to interact with the   Grpah database.</li> </ul> <p>Database</p> <ul> <li>A graph database is used to store the complex data structure of the scenario   bundles in the long term. We use Appache Jenna-Fuseki as a reliable   technology.</li> </ul>"},{"location":"oeplatform-code/features/scenario-bundles/#code-documentation","title":"Code Documentation","text":""},{"location":"oeplatform-code/features/scenario-bundles/#django-view-for-the-scenario-bundles","title":"Django view for the scenario bundles","text":"<p>Note</p> <p>Some of the information on this page may be changed in the future. To review the most recent information, please revisit.</p> <p>SPDX-FileCopyrightText: 2025 Adel Memariani https://github.com/adelmemariani \u00a9 Otto-von-Guericke-Universit\u00e4t Magdeburg SPDX-FileCopyrightText: 2025 Adel Memariani https://github.com/adelmemariani \u00a9 Otto-von-Guericke-Universit\u00e4t Magdeburg SPDX-FileCopyrightText: 2025 Adel Memariani https://github.com/adelmemariani \u00a9 Otto-von-Guericke-Universit\u00e4t Magdeburg SPDX-FileCopyrightText: 2025 Adel Memariani https://github.com/adelmemariani \u00a9 Otto-von-Guericke-Universit\u00e4t Magdeburg SPDX-FileCopyrightText: 2025 Adel Memariani https://github.com/adelmemariani \u00a9 Otto-von-Guericke-Universit\u00e4t Magdeburg SPDX-FileCopyrightText: 2025 Bryan Lancien https://github.com/bmlancien \u00a9 Reiner Lemoine Institut SPDX-FileCopyrightText: 2025 Christian Winger https://github.com/wingechr \u00a9 \u00d6ko-Institut e.V. SPDX-FileCopyrightText: 2025 Jonas Huber https://github.com/jh-RLI \u00a9 Reiner Lemoine Institut SPDX-FileCopyrightText: 2025 Jonas Huber https://github.com/jh-RLI \u00a9 Reiner Lemoine Institut SPDX-FileCopyrightText: 2025 Jonas Huber https://github.com/jh-RLI \u00a9 Reiner Lemoine Institut</p> <p>SPDX-License-Identifier: AGPL-3.0-or-later</p>"},{"location":"oeplatform-code/features/scenario-bundles/#factsheet.views.add_entities_view","title":"<code>add_entities_view(request, *args, **kwargs)</code>","text":"<p>Add entities to OEKG. The minimum requirements for adding an entity are the type and label.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP GET request.</p> required <code>entity_type</code> <code>str</code> <p>The type(OEO class) of the entity.</p> required <code>entity_label</code> <code>str</code> <p>The label of the entity.</p> required <code>entity_iri</code> <code>str</code> <p>The IRI of the entity.</p> required Source code in <code>factsheet/views.py</code> <pre><code>@login_required\ndef add_entities_view(request, *args, **kwargs):\n    \"\"\"\n    Add entities to OEKG. The minimum requirements for\n    adding an entity are the type and label.\n\n    Args:\n        request (HttpRequest): The incoming HTTP GET request.\n        entity_type (str): The type(OEO class) of the entity.\n        entity_label (str): The label of the entity.\n        entity_iri (str): The IRI of the entity.\n    \"\"\"\n    request_body = json.loads(request.body)\n    entity_type = request_body[\"entity_type\"]\n    entity_label = request_body[\"entity_label\"]\n    entity_iri = request_body[\"entity_iri\"]\n\n    vocab = entity_type.split(\".\")[0]\n    classId = entity_type.split(\".\")[1]\n    prefix = \"\"\n    if vocab == \"OEO\":\n        prefix = \"https://openenergyplatform.org/ontology/oeo/\"\n    if vocab == \"OBO\":\n        prefix = \"http://purl.obolibrary.org/obo/\"\n\n    entity_type_URI = URIRef(prefix + classId)\n\n    entity_URI = URIRef(\"https://openenergyplatform.org/ontology/oekg/\" + entity_iri)\n\n    oekg.add((entity_URI, RDF.type, entity_type_URI))\n    oekg.add((entity_URI, RDFS.label, Literal(entity_label)))\n\n    response = JsonResponse(\n        \"A new entity added!\", safe=False, content_type=\"application/json\"\n    )\n    patch_response_headers(response, cache_timeout=1)\n    return response\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#factsheet.views.create_factsheet_view","title":"<code>create_factsheet_view(request, *args, **kwargs)</code>","text":"<p>Creates a scenario bundle based on user's data. Currently, the minimum requirement to create a bundle is the \"acronym\". The \"acronym\" must be unique. If the provided acronym already exists in the OEKG, then the function returns a \"Duplicate error\".</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP GET request.</p> required <code>uid</code> <code>str</code> <p>The unique ID for the bundle.</p> required <code>acronym</code> <code>str</code> <p>The acronym for the bundle.</p> required <code>abstract</code> <code>str</code> <p>The abstract for the bundle.</p> required <code>institution</code> <code>list of objects</code> <p>The institutions for the bundle.</p> required <code>funding_source</code> <code>list of objects</code> <p>The funding sources for the bundle.</p> required <code>contact_person</code> <code>list of objects</code> <p>The contact persons for the bundle.</p> required <code>sector_divisions</code> <code>list of objects</code> <p>The sector divisions for the bundle.</p> required <code>sectors</code> <code>list of objects</code> <p>The sectors for the bundle.</p> required <code>technologies</code> <code>list of objects</code> <p>The technologies for the bundle.</p> required <code>study_keywords</code> <code>list of strings</code> <p>The study keywords for the bundle.</p> required <code>scenarios</code> <code>list of objects</code> <p>The scenarios for the bundle.</p> required <code>models</code> <code>list of strings</code> <p>The models for the bundle.</p> required <code>frameworks</code> <code>list of strings</code> <p>The frameworks for the bundle.</p> required <code>publications</code> <code>list[object]</code> <p>A list of n publications related to the bundle study_name (str): The study name for the bundle. date_of_publication (str): The date of publication for the bundle. report_title (str): The report title for the bundle. report_doi (str): The report_doi for the bundle. place_of_publication (str): The place of publication for the bundle. link_to_study_report (str): The link to study for the bundle. authors (list of objects): The authors for the bundle.</p> required <p>Returns:</p> Type Description <p>\"Factsheet saved\" if successful, \"Duplicate error\" if the bundle's</p> <p>acronym exists.</p> Source code in <code>factsheet/views.py</code> <pre><code>@require_POST\ndef create_factsheet_view(request, *args, **kwargs):\n    \"\"\"\n    Creates a scenario bundle based on user's data. Currently, the minimum requirement\n    to create a bundle is the \"acronym\". The \"acronym\" must be unique. If the provided\n    acronym already exists in the OEKG, then the function returns a \"Duplicate error\".\n\n    Args:\n        request (HttpRequest): The incoming HTTP GET request.\n        uid (str): The unique ID for the bundle.\n        acronym (str): The acronym for the bundle.\n        abstract (str): The abstract for the bundle.\n        institution (list of objects): The institutions for the bundle.\n        funding_source (list of objects): The funding sources for the bundle.\n        contact_person (list of objects): The contact persons for the bundle.\n        sector_divisions (list of objects): The sector divisions for the bundle.\n        sectors (list of objects): The sectors for the bundle.\n        technologies (list of objects): The technologies for the bundle.\n        study_keywords (list of strings): The study keywords for the bundle.\n        scenarios (list of objects): The scenarios for the bundle.\n        models (list of strings): The models for the bundle.\n        frameworks (list of strings): The frameworks for the bundle.\n        publications (list[object]): A list of n publications related to the bundle\n            study_name (str): The study name for the bundle.\n            date_of_publication (str): The date of publication for the bundle.\n            report_title (str): The report title for the bundle.\n            report_doi (str): The report_doi for the bundle.\n            place_of_publication (str): The place of publication for the bundle.\n            link_to_study_report (str): The link to study for the bundle.\n            authors (list of objects): The authors for the bundle.\n\n    Returns:\n        \"Factsheet saved\" if successful, \"Duplicate error\" if the bundle's\n        acronym exists.\n\n    \"\"\"\n\n    if not request.user.is_authenticated:\n        return HttpResponseForbidden(\"User not authenticated\")\n\n    request_body = json.loads(request.body)\n    name = request_body[\"name\"]  # noqa\n    uid = request_body[\"uid\"]\n    acronym = request_body[\"acronym\"]\n    study_name = request_body[\"study_name\"]\n    abstract = request_body[\"abstract\"]\n    institution = request_body[\"institution\"]\n    funding_source = request_body[\"funding_source\"]\n    contact_person = request_body[\"contact_person\"]\n    sector_divisions = request_body[\"sector_divisions\"]\n    sectors = request_body[\"sectors\"]\n    # expanded_sectors = request_body[\"expanded_sectors\"]  # noqa\n    # energy_carriers = request_body['energy_carriers']\n    # expanded_energy_carriers = request_body['expanded_energy_carriers']\n    # energy_transformation_processes = request_body['energy_transformation_processes']\n    # expanded_energy_transformation_processes = request_body['expanded_energy_transformation_processes'] # noqa\n    technologies = request_body[\"technologies\"]\n    study_keywords = request_body[\"study_keywords\"]\n    scenarios = request_body[\"scenarios\"]\n    publications = request_body[\"publications\"]\n    models = request_body[\"models\"]\n    frameworks = request_body[\"frameworks\"]\n\n    Duplicate_study_factsheet = False\n\n    for s, p, o in oekg.triples((None, RDF.type, OEO.OEO_00020227)):\n        study_acronym = oekg.value(s, DC.acronym)\n        if str(clean_name(acronym)) == str(study_acronym):\n            Duplicate_study_factsheet = True\n\n    if Duplicate_study_factsheet == True:  # noqa\n        response = JsonResponse(\n            \"Factsheet exists\", safe=False, content_type=\"application/json\"\n        )\n        patch_response_headers(response, cache_timeout=1)\n        return response\n    else:\n        bundle = Graph()\n\n        study_URI = URIRef(\"https://openenergyplatform.org/ontology/oekg/\" + uid)\n        bundle.add((study_URI, RDF.type, OEO.OEO_00020227))\n\n        if acronym != \"\":\n            bundle.add((study_URI, DC.acronym, Literal(remove_non_printable(acronym))))\n        if study_name != \"\":\n            bundle.add(\n                (\n                    study_URI,\n                    RDFS.label,\n                    Literal(remove_non_printable(study_name)),\n                )\n            )\n        if abstract != \"\":\n            bundle.add(\n                (study_URI, DC.abstract, Literal(remove_non_printable(abstract)))\n            )\n\n        _publications = json.loads(publications) if publications is not None else []\n        for item in _publications:\n            publications_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/publication/\" + item[\"id\"]\n            )\n            # OEO_00020012\n            bundle.add((publications_URI, OEO.OEO_00390095, Literal(item[\"id\"])))\n            bundle.add((publications_URI, RDF.type, OEO.OEO_00020012))\n            bundle.add((study_URI, OBO.BFO_0000051, publications_URI))\n            if item[\"report_title\"] != \"\":\n                bundle.add(\n                    (\n                        publications_URI,\n                        RDFS.label,\n                        Literal(remove_non_printable(item[\"report_title\"])),\n                    )\n                )\n\n            _authors = item[\"authors\"]\n            for author in _authors:\n                author_URI = URIRef(\n                    \"https://openenergyplatform.org/ontology/oekg/\" + author[\"iri\"]\n                )\n                bundle.add((author_URI, RDF.type, OEO.OEO_00000064))\n                bundle.add((publications_URI, OEO.OEO_00000506, author_URI))\n\n            if item[\"doi\"] != \"\":\n                bundle.add((publications_URI, OEO.OEO_00390098, Literal(item[\"doi\"])))\n\n            if (\n                item[\"date_of_publication\"] != \"01-01-1900\"\n                and item[\"date_of_publication\"] != \"\"\n            ):\n                bundle.add(\n                    (\n                        publications_URI,\n                        OEO.OEO_00390096,\n                        Literal(item[\"date_of_publication\"], datatype=XSD.dateTime),\n                    )\n                )\n\n            if item[\"link_to_study_report\"] != \"\":\n                bundle.add(\n                    (URIRef(item[\"link_to_study_report\"]), RDF.type, OEO.OEO_00000353)\n                )\n                bundle.add(\n                    (\n                        publications_URI,\n                        OEO.OEO_00390078,\n                        URIRef(item[\"link_to_study_report\"]),\n                    )\n                )\n\n            bundle.add((study_URI, OBO.BFO_0000051, publications_URI))\n\n        _scenarios = json.loads(scenarios) if scenarios is not None else []\n        for item in _scenarios:\n            if item[\"acronym\"] != \"\":\n                scenario_URI = URIRef(\n                    \"https://openenergyplatform.org/ontology/oekg/scenario/\"\n                    + item[\"id\"]\n                )\n                bundle.add((study_URI, OBO.BFO_0000051, scenario_URI))\n                bundle.add(\n                    (\n                        scenario_URI,\n                        DC.acronym,\n                        Literal(remove_non_printable(item[\"acronym\"])),\n                    )\n                )\n                if item[\"name\"] != \"\":\n                    bundle.add(\n                        (\n                            scenario_URI,\n                            RDFS.label,\n                            Literal(remove_non_printable(item[\"name\"])),\n                        )\n                    )\n                    bundle.add((scenario_URI, RDF.type, OEO.OEO_00000365))\n                if item[\"abstract\"] != \"\":\n                    bundle.add(\n                        (\n                            scenario_URI,\n                            DC.abstract,\n                            Literal(remove_non_printable(item[\"abstract\"])),\n                        )\n                    )\n\n                bundle.add((scenario_URI, OEO.OEO_00390095, Literal(item[\"id\"])))\n\n                if \"regions\" in item:\n                    for region in item[\"regions\"]:\n                        region_URI = URIRef(region[\"iri\"])\n                        scenario_region = URIRef(\n                            \"https://openenergyplatform.org/ontology/oekg/region/\"\n                            + region[\"iri\"].rsplit(\"/\", 1)[1]\n                        )\n                        bundle.add((scenario_region, RDF.type, OEO.OEO_00020032))\n                        bundle.add(\n                            (scenario_region, RDFS.label, Literal(region[\"name\"]))\n                        )\n                        bundle.add((scenario_region, OEO.OEO_00390078, region_URI))\n                        bundle.add((scenario_URI, OEO.OEO_00020220, scenario_region))\n\n                if \"interacting_regions\" in item:\n                    for interacting_region in item[\"interacting_regions\"]:\n                        interacting_region_URI = URIRef(interacting_region[\"iri\"])\n                        scenario_interacting_region = URIRef(\n                            \"https://openenergyplatform.org/ontology/oekg/\"\n                            + interacting_region[\"iri\"]\n                        )\n\n                        bundle.add(\n                            (scenario_interacting_region, RDF.type, OEO.OEO_00020036)\n                        )\n                        bundle.add(\n                            (\n                                scenario_interacting_region,\n                                RDFS.label,\n                                Literal(interacting_region[\"name\"]),\n                            )\n                        )\n                        bundle.add(\n                            (\n                                scenario_interacting_region,\n                                OEO.OEO_00390078,\n                                interacting_region_URI,\n                            )\n                        )\n                        bundle.add(\n                            (\n                                scenario_URI,\n                                OEO.OEO_00020222,\n                                scenario_interacting_region,\n                            )\n                        )\n\n                if \"scenario_years\" in item:\n                    for scenario_year in item[\"scenario_years\"]:\n                        bundle.add(\n                            (\n                                scenario_URI,\n                                OEO.OEO_00020440,\n                                Literal(scenario_year[\"name\"], datatype=XSD.dateTime),\n                            )\n                        )\n\n                if \"descriptors\" in item:\n                    for descriptor in item[\"descriptors\"]:\n                        descriptor = URIRef(descriptor[\"class\"])\n                        bundle.add((scenario_URI, OEO.OEO_00390073, descriptor))\n\n                # TODO: Jonas Huber: Update to avoid duplicated table name entries\n                if \"input_datasets\" in item:\n                    for input_dataset in item[\"input_datasets\"]:\n                        # TODO- set in settings\n                        input_dataset_URI = URIRef(\n                            \"https://openenergyplatform.org/ontology/oekg/input_datasets/\"  # noqa\n                            + input_dataset[\"key\"]\n                        )\n                        bundle.add((input_dataset_URI, RDF.type, OEO.OEO_00030029))\n                        bundle.add(\n                            (\n                                input_dataset_URI,\n                                RDFS.label,\n                                Literal(\n                                    remove_non_printable(\n                                        input_dataset[\"value\"][\"label\"]\n                                    )\n                                ),\n                            )\n                        )\n                        bundle.add(\n                            (\n                                input_dataset_URI,\n                                OEO.OEO_00390094,\n                                Literal(input_dataset[\"value\"][\"url\"]),\n                            )\n                        )\n                        bundle.add(\n                            (\n                                input_dataset_URI,\n                                OEKG[\"has_id\"],\n                                Literal(input_dataset[\"idx\"]),\n                            )\n                        )\n                        bundle.add(\n                            (\n                                input_dataset_URI,\n                                OEO.OEO_00390095,\n                                Literal(input_dataset[\"key\"]),\n                            )\n                        )\n                        bundle.add((scenario_URI, OEO.OEO_00020437, input_dataset_URI))\n\n                # TODO: Jonas Huber: Update to avoid duplicated table name entries\n                if \"output_datasets\" in item:\n                    for output_dataset in item[\"output_datasets\"]:\n                        output_dataset_URI = URIRef(\n                            \"https://openenergyplatform.org/ontology/oekg/output_datasets/\"  # noqa\n                            + output_dataset[\"key\"]\n                        )\n                        bundle.add((output_dataset_URI, RDF.type, OEO.OEO_00030030))\n                        bundle.add(\n                            (\n                                output_dataset_URI,\n                                RDFS.label,\n                                Literal(\n                                    remove_non_printable(\n                                        output_dataset[\"value\"][\"label\"]\n                                    )\n                                ),\n                            )\n                        )\n                        bundle.add(\n                            (\n                                output_dataset_URI,\n                                OEO.OEO_00390094,\n                                Literal(output_dataset[\"value\"][\"url\"]),\n                            )\n                        )\n                        bundle.add(\n                            (\n                                output_dataset_URI,\n                                OEKG[\"has_id\"],\n                                Literal(output_dataset[\"idx\"]),\n                            )\n                        )\n                        bundle.add(\n                            (\n                                output_dataset_URI,\n                                OEO.OEO_00390095,\n                                Literal(output_dataset[\"key\"]),\n                            )\n                        )\n                        bundle.add((scenario_URI, OEO.OEO_00020436, output_dataset_URI))\n\n        institutions = json.loads(institution) if institution is not None else []\n        for item in institutions:\n            institution_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/\" + item[\"iri\"]\n            )\n            bundle.add((study_URI, OEO.OEO_00000510, institution_URI))\n\n        funding_sources = (\n            json.loads(funding_source) if funding_source is not None else []\n        )\n        for item in funding_sources:\n            funding_source_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/\" + item[\"iri\"]\n            )\n            bundle.add((study_URI, OEO.OEO_00000509, funding_source_URI))\n        contact_persons = (\n            json.loads(contact_person) if contact_person is not None else []\n        )\n        for item in contact_persons:\n            contact_person_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/\" + item[\"iri\"]\n            )\n            bundle.add((study_URI, OEO.OEO_00000508, contact_person_URI))\n\n        _sector_divisions = (\n            json.loads(sector_divisions) if sector_divisions is not None else []\n        )\n        for item in _sector_divisions:\n            sector_divisions_URI = URIRef(item[\"class\"])\n            bundle.add((study_URI, OEO.OEO_00390079, sector_divisions_URI))\n\n        _sectors = json.loads(sectors) if sectors is not None else []\n        for item in _sectors:\n            sector_URI = URIRef(item[\"class\"])\n            bundle.add((study_URI, OEO.OEO_00020439, sector_URI))\n\n        _technologies = json.loads(technologies) if technologies is not None else []\n        for item in _technologies:\n            technology_URI = URIRef(item[\"class\"])\n            bundle.add((study_URI, OEO.OEO_00020438, technology_URI))\n\n        _models = json.loads(models) if models is not None else []\n        for item in _models:\n            model_id = item.get(\"id\")\n            if item.get(\"acronym\"):\n                model_acronym = item.get(\"acronym\")\n            else:\n                model_acronym = item.get(\"name\")\n            model_url = item.get(\"url\")\n\n            if not model_id or not model_acronym or not model_url:\n                continue  # Skip this item if any critical field is empty\n\n            model_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/models/\" + str(model_id)\n            )\n            bundle.add((model_URI, RDF.type, OEO.OEO_00000277))\n            bundle.add(\n                (\n                    model_URI,\n                    RDFS.label,\n                    Literal(remove_non_printable(model_acronym)),\n                )\n            )\n            bundle.add(\n                (\n                    model_URI,\n                    OEO.OEO_00390094,\n                    Literal(model_url),\n                )\n            )\n            bundle.add((study_URI, OBO.BFO_0000051, model_URI))\n\n        _frameworks = json.loads(frameworks) if frameworks is not None else []\n        for item in _frameworks:\n            framework_id = item.get(\"id\")\n            if item.get(\"acronym\"):\n                framework_acronym = item.get(\"acronym\")\n            else:\n                framework_acronym = item.get(\"name\")\n            framework_url = item.get(\"url\")\n\n            if not framework_id or not framework_acronym or not framework_url:\n                continue  # Skip this item if any critical field is empty\n\n            framework_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/frameworks/\"\n                + str(framework_id)\n            )\n\n            bundle.add((framework_URI, RDF.type, OEO.OEO_00000172))\n\n            if framework_acronym:\n                bundle.add(\n                    (\n                        framework_URI,\n                        RDFS.label,\n                        Literal(remove_non_printable(framework_acronym)),\n                    )\n                )\n\n            if framework_url:\n                bundle.add(\n                    (\n                        framework_URI,\n                        OEO.OEO_00390094,\n                        Literal(framework_url),\n                    )\n                )\n\n            bundle.add((study_URI, OBO.BFO_0000051, framework_URI))\n\n        _study_keywords = (\n            json.loads(study_keywords) if study_keywords is not None else []\n        )\n        # TODO:  Literal(keyword) should be URiRef\n        if _study_keywords != []:\n            for keyword in _study_keywords:\n                bundle.add((study_URI, OEO.OEO_00390071, Literal(keyword)))\n\n        for s, p, o in bundle.triples((None, None, None)):\n            oekg.add((s, p, o))\n\n        response = JsonResponse(\n            \"Factsheet saved\", safe=False, content_type=\"application/json\"\n        )\n        result = set_ownership(bundle_uid=uid, user=request.user)\n        logger.info(result)\n        patch_response_headers(response, cache_timeout=1)\n\n        return response\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#factsheet.views.delete_factsheet_by_id_view","title":"<code>delete_factsheet_by_id_view(request, *args, **kwargs)</code>","text":"<p>Removes a scenario bundle based on the provided ID.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP GET request.</p> required <code>id</code> <code>str</code> <p>The unique ID for the bundle.</p> required Source code in <code>factsheet/views.py</code> <pre><code>@only_if_user_is_owner_of_scenario_bundle\n@login_required\ndef delete_factsheet_by_id_view(request, *args, **kwargs):\n    \"\"\"\n    Removes a scenario bundle based on the provided ID.\n\n    Args:\n        request (HttpRequest): The incoming HTTP GET request.\n        id (str): The unique ID for the bundle.\n\n    \"\"\"\n    id = request.GET.get(\"id\")\n    study_URI = URIRef(\"https://openenergyplatform.org/ontology/oekg/\" + id)\n\n    for s, p, o in oekg.triples((study_URI, OBO.BFO_0000051, None)):\n        oekg.remove((o, None, None))\n    oekg.remove((study_URI, None, None))\n\n    response = JsonResponse(\n        \"factsheet removed!\", safe=False, content_type=\"application/json\"\n    )\n    patch_response_headers(response, cache_timeout=1)\n    return response\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#factsheet.views.get_entities_by_type_view","title":"<code>get_entities_by_type_view(request, *args, **kwargs)</code>","text":"<p>Returns all entities (from OEKG) with a certain type. The type should be supplied by the user.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP GET request.</p> required <code>entity_type</code> <code>str</code> <p>The type(OEO class) of the entity.</p> required Source code in <code>factsheet/views.py</code> <pre><code>def get_entities_by_type_view(request, *args, **kwargs):\n    \"\"\"\n    Returns all entities (from OEKG) with a certain type.\n    The type should be supplied by the user.\n\n    Args:\n        request (HttpRequest): The incoming HTTP GET request.\n        entity_type (str): The type(OEO class) of the entity.\n    \"\"\"\n    entity_type = request.GET.get(\"entity_type\")\n    vocab = entity_type.split(\".\")[0]\n    classId = entity_type.split(\".\")[1]\n    prefix = \"\"\n    if vocab == \"OEO\":\n        prefix = \"https://openenergyplatform.org/ontology/oeo/\"\n    if vocab == \"OBO\":\n        prefix = \"http://purl.obolibrary.org/obo/\"\n\n    entity_URI = URIRef(prefix + classId)\n\n    entities = []\n    for s, p, o in oekg.triples((None, RDF.type, entity_URI)):\n        sl = oekg.value(s, RDFS.label)\n        entities.append({\"name\": sl, \"id\": sl, \"iri\": str(s).split(\"/\")[-1]})\n\n    response = JsonResponse(entities, safe=False, content_type=\"application/json\")\n    patch_response_headers(response, cache_timeout=1)\n    return response\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#factsheet.views.populate_factsheets_elements_view","title":"<code>populate_factsheets_elements_view(request, *args, **kwargs)</code>","text":"<p>This function populates the elements required for creating or updating a factsheet. For example: Elements returned form this function populate dropdown elements which help the user to select sectors, technologies, scenario descriptors etc.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP GET request.</p> required <p>Returns:</p> Name Type Description <code>JsonResponse</code> <p>A JSON response containing the elements for factsheet creation or         update.</p> Source code in <code>factsheet/views.py</code> <pre><code>def populate_factsheets_elements_view(request, *args, **kwargs):\n    \"\"\"\n    This function populates the elements required for creating or updating a factsheet.\n    For example: Elements returned form this function populate dropdown elements which\n    help the user to select sectors, technologies, scenario descriptors etc.\n\n    Args:\n        request (HttpRequest): The incoming HTTP GET request.\n\n    Returns:\n        JsonResponse: A JSON response containing the elements for factsheet creation or\n                    update.\n    \"\"\"\n    scenario_class = oeo_owl.search_one(iri=OEO.OEO_00000364)\n    scenario_subclasses = get_all_sub_classes(scenario_class)\n\n    technology_class = oeo_owl.search_one(iri=OEO.OEO_00000407)\n    technology_subclasses = get_all_sub_classes(technology_class)\n\n    # energy_carrier_class = oeo_owl.search_one(iri=\"http://openenergy-platform.org/ontology/oeo/OEO_00020039\") # noqa\n    # energy_carriers = get_all_sub_classes(energy_carrier_class)\n\n    # energy_transformation_process_class = oeo_owl.search_one(iri=\"http://openenergy-platform.org/ontology/oeo/OEO_00020003\") # noqa\n    # energy_transformation_processes = get_all_sub_classes(energy_transformation_process_class) # noqa\n\n    sector_divisions_list, sectors_list = build_sector_dropdowns_from_oeo(oeo)\n    elements = {}\n    # elements['energy_carriers'] = [energy_carriers]\n    # elements['energy_transformation_processes'] = [energy_transformation_processes]\n    elements[\"sector_divisions\"] = sector_divisions_list\n    elements[\"sectors\"] = sectors_list\n    elements[\"scenario_descriptors\"] = scenario_subclasses\n    elements[\"technologies\"] = technology_subclasses\n\n    # for s, p, o in oeo.triples(( None, RDFS.subClassOf, OEO.OEO_00020003 )):\n    #     sl = oeo.value(s, RDFS.label)\n    #     parent = {\n    #         'value': str(sl),\n    #         'label': sl,\n    #         'class': s\n    #     }\n    #     children = []\n    #     for s1, p, o in oeo.triples(( None, RDFS.subClassOf, s )):\n    #         sl1 = oeo.value(s1, RDFS.label)\n    #         children2 = []\n    #         for s2, p, o in oeo.triples(( None, RDFS.subClassOf, s1 )):\n    #             sl2 = oeo.value(s2, RDFS.label)\n    #             children3 = []\n    #             for s3, p, o in oeo.triples(( None, RDFS.subClassOf, s2 )):\n    #                 sl3 = oeo.value(s3, RDFS.label)\n    #                 children3.append({\n    #                     'value': str(sl) + str(sl1) + str(sl2) + str(sl3),\n    #                     'label': sl3,\n    #                     'class': s3\n    #                 })\n\n    #             if children3 != []:\n    #                 children2.append({\n    #                     'value': str(sl) + str(sl1) + str(sl2),\n    #                     'label': sl2,\n    #                     'class': s2,\n    #                     'children': children3\n    #                 })\n    #             else:\n    #                 children2.append({\n    #                     'value': str(sl) + str(sl1) + str(sl2),\n    #                     'class': s2,\n    #                     'label': sl2,\n    #                 })\n\n    #         if children2 != []:\n    #             children.append({\n    #             'value': str(sl) + str(sl1),\n    #             'label': sl1,\n    #             'class': s1,\n    #             'children': children2\n    #             })\n    #         else:\n    #             children.append({\n    #             'value': str(sl) + str(sl1),\n    #             'class': s1,\n    #             'label': sl1\n    #             })\n\n    #     if children != []:\n    #         parent['children'] = children\n\n    #     energy_transformation_processes.append(parent)\n\n    # energy_carriers = []\n    # for s, p, o in oeo.triples(( None, RDFS.subClassOf, OEO.OEO_00020039 )):\n    #     sl = oeo.value(s, RDFS.label)\n    #     parent = {\n    #         'value': str(sl),\n    #         'label': sl,\n    #         'class': s\n    #     }\n    #     children = []\n    #     for s1, p, o in oeo.triples(( None, RDFS.subClassOf, s )):\n    #         sl1 = oeo.value(s1, RDFS.label)\n    #         children2 = []\n    #         for s2, p, o in oeo.triples(( None, RDFS.subClassOf, s1 )):\n    #             sl2 = oeo.value(s2, RDFS.label)\n    #             children3 = []\n    #             for s3, p, o in oeo.triples(( None, RDFS.subClassOf, s2 )):\n    #                 sl3 = oeo.value(s3, RDFS.label)\n    #                 children3.append({\n    #                     'value': str(sl) + \"^^\" + str(sl1) + \"^^\" + str(sl2) + \"^^\" + str(sl3), # noqa\n    #                     'label': sl3,\n    #                     'class': s3\n    #                 })\n\n    #             if children3 != []:\n    #                 children2.append({\n    #                     'value': str(sl) + \"^^\" + str(sl1) + \"^^\" + str(sl2),\n    #                     'label': sl2,\n    #                     'class': s2,\n    #                     'children': children3\n    #                 })\n    #             else:\n    #                 children2.append({\n    #                     'value': str(sl) + \"^^\" + str(sl1) + \"^^\" + str(sl2),\n    #                     'label': sl2,\n    #                 })\n\n    #         if children2 != []:\n    #             children.append({\n    #             'value': str(sl) + \"^^\" + str(sl1),\n    #             'label': sl1,\n    #             'class': s1,\n    #             'children': children2\n    #             })\n    #         else:\n    #             children.append({\n    #             'value': str(sl) + \"^^\" + str(sl1),\n    #             'class': s1,\n    #             'label': sl1\n    #             })\n\n    #     if children != []:\n    #         parent['children'] = children\n\n    #     energy_carriers.append(parent)\n\n    response = JsonResponse(elements, safe=False, content_type=\"application/json\")\n    patch_response_headers(response, cache_timeout=1)\n\n    return response\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#factsheet.views.update_an_entity_view","title":"<code>update_an_entity_view(request, *args, **kwargs)</code>","text":"<p>Updates an entity in OEKG. The minimum requirements for updating an entity are the type, the old label, and the new label.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP GET request.</p> required <code>entity_type</code> <code>str</code> <p>The type(OEO class) of the entity.</p> required <code>entity_label</code> <code>str</code> <p>The label of the entity.</p> required <code>new_entity_label</code> <code>str</code> <p>The new label of the entity.</p> required <code>entity_id</code> <code>str</code> <p>The IRI of the entity.</p> required Source code in <code>factsheet/views.py</code> <pre><code>@login_required\ndef update_an_entity_view(request, *args, **kwargs):\n    \"\"\"\n    Updates an entity in OEKG. The minimum requirements for\n    updating an entity are the type, the old label, and the\n    new label.\n\n    Args:\n        request (HttpRequest): The incoming HTTP GET request.\n        entity_type (str): The type(OEO class) of the entity.\n        entity_label (str): The label of the entity.\n        new_entity_label (str): The new label of the entity.\n        entity_id (str): The IRI of the entity.\n    \"\"\"\n    request_body = json.loads(request.body)\n    entity_type = request_body[\"entity_type\"]\n    entity_label = request_body[\"entity_label\"]\n    new_entity_label = request_body[\"new_entity_label\"]\n    entity_id = request_body[\"entity_iri\"]\n\n    vocab = entity_type.split(\".\")[0]\n    classId = entity_type.split(\".\")[1]\n    prefix = \"\"\n    if vocab == \"OEO\":\n        prefix = \"https://openenergyplatform.org/ontology/oeo/\"\n    if vocab == \"OBO\":\n        prefix = \"http://purl.obolibrary.org/obo/\"\n\n    entity_type_URI = URIRef(prefix + classId)  # noqa\n    entity_IRI = URIRef(\"https://openenergyplatform.org/ontology/oekg/\" + (entity_id))\n\n    oekg.add((entity_IRI, RDFS.label, Literal(new_entity_label)))\n    oekg.remove((entity_IRI, RDFS.label, Literal(entity_label)))\n\n    response = JsonResponse(\n        \"entity updated!\", safe=False, content_type=\"application/json\"\n    )\n    patch_response_headers(response, cache_timeout=1)\n    return response\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#factsheet.views.update_factsheet_view","title":"<code>update_factsheet_view(request, *args, **kwargs)</code>","text":"<p>Updates a scenario bundle based on user's data.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HttpRequest</code> <p>The incoming HTTP GET request.</p> required <code>uid</code> <code>str</code> <p>The unique ID for the bundle.</p> required <code>acronym</code> <code>str</code> <p>The acronym for the bundle.</p> required <code>abstract</code> <code>str</code> <p>The abstract for the bundle.</p> required <code>institution</code> <code>list of objects</code> <p>The institutions for the bundle.</p> required <code>funding_source</code> <code>list of objects</code> <p>The funding sources for the bundle.</p> required <code>contact_person</code> <code>list of objects</code> <p>The contact persons for the bundle.</p> required <code>sector_divisions</code> <code>list of objects</code> <p>The sector divisions for the bundle.</p> required <code>sectors</code> <code>list of objects</code> <p>The sectors for the bundle.</p> required <code>technologies</code> <code>list of objects</code> <p>The technologies for the bundle.</p> required <code>study_keywords</code> <code>list of strings</code> <p>The study keywords for the bundle.</p> required <code>scenarios</code> <code>list of objects</code> <p>The scenarios for the bundle.</p> required <code>models</code> <code>list of strings</code> <p>The models for the bundle.</p> required <code>frameworks</code> <code>list of strings</code> <p>The frameworks for the bundle.</p> required <code>publications</code> <code>list[object]</code> <p>A list of n publications related to the bundle study_name (str): The study name for the bundle. date_of_publication (str): The date of publication for the bundle. report_title (str): The report title for the bundle. report_doi (str): The report_doi for the bundle. place_of_publication (str): The place of publication for the bundle. link_to_study_report (str): The link to study for the bundle. authors (list of objects): The authors for the bundle.</p> required Source code in <code>factsheet/views.py</code> <pre><code>@login_required\n@only_if_user_is_owner_of_scenario_bundle\ndef update_factsheet_view(request, *args, **kwargs):\n    \"\"\"\n    Updates a scenario bundle based on user's data.\n\n    Args:\n        request (HttpRequest): The incoming HTTP GET request.\n        uid (str): The unique ID for the bundle.\n        acronym (str): The acronym for the bundle.\n        abstract (str): The abstract for the bundle.\n        institution (list of objects): The institutions for the bundle.\n        funding_source (list of objects): The funding sources for the bundle.\n        contact_person (list of objects): The contact persons for the bundle.\n        sector_divisions (list of objects): The sector divisions for the bundle.\n        sectors (list of objects): The sectors for the bundle.\n        technologies (list of objects): The technologies for the bundle.\n        study_keywords (list of strings): The study keywords for the bundle.\n        scenarios (list of objects): The scenarios for the bundle.\n        models (list of strings): The models for the bundle.\n        frameworks (list of strings): The frameworks for the bundle.\n        publications (list[object]): A list of n publications related to the bundle\n            study_name (str): The study name for the bundle.\n            date_of_publication (str): The date of publication for the bundle.\n            report_title (str): The report title for the bundle.\n            report_doi (str): The report_doi for the bundle.\n            place_of_publication (str): The place of publication for the bundle.\n            link_to_study_report (str): The link to study for the bundle.\n            authors (list of objects): The authors for the bundle.\n    \"\"\"\n    request_body = json.loads(request.body)\n    fsData = request_body[\"fsData\"]\n    # id = request_body[\"id\"]  # noqa\n    uid = request_body[\"uid\"]\n    # name = request_body[\"name\"]  # noqa\n    studyName = request_body[\"study_name\"]\n    acronym = request_body[\"acronym\"]\n    abstract = request_body[\"abstract\"]\n    institution = request_body[\"institution\"]\n    funding_source = request_body[\"funding_source\"]\n    contact_person = request_body[\"contact_person\"]\n    sector_divisions = request_body[\"sector_divisions\"]\n    sectors = request_body[\"sectors\"]\n    # expanded_sectors = request_body[\"expanded_sectors\"]  # noqa\n    # energy_carriers = request_body['energy_carriers']\n    # expanded_energy_carriers = request_body['expanded_energy_carriers']\n    # energy_transformation_processes = request_body['energy_transformation_processes']\n    # expanded_energy_transformation_processes = request_body['expanded_energy_transformation_processes'] # noqa\n    technologies = request_body[\"technologies\"]\n    study_keywords = request_body[\"study_keywords\"]\n    scenarios = request_body[\"scenarios\"]\n    models = request_body[\"models\"]\n    frameworks = request_body[\"frameworks\"]\n    publications = request_body[\"publications\"]\n\n    Duplicate_study_factsheet = False\n\n    for s, p, o in oekg.triples((None, RDF.type, OEO.OEO_00020227)):\n        study_acronym = oekg.value(s, DC.acronym)\n        if str(clean_name(acronym)) == str(study_acronym) and str(\n            clean_name(acronym)\n        ) != str(fsData[\"acronym\"]):\n            Duplicate_study_factsheet = True\n\n    if Duplicate_study_factsheet == True:  # noqa\n        response = JsonResponse(\n            \"Factsheet exists\", safe=False, content_type=\"application/json\"\n        )\n        patch_response_headers(response, cache_timeout=1)\n        return response\n\n    if Duplicate_study_factsheet == False:  # noqa\n        study_URI = URIRef(\"https://openenergyplatform.org/ontology/oekg/\" + uid)\n\n        old_bundle = Graph()\n        for s, p, o in oekg.triples((study_URI, None, None)):\n            old_bundle.add((s, p, o))\n        for s, p, o in oekg.triples((study_URI, OBO.BFO_0000051, None)):\n            for s1, p1, o1 in oekg.triples((o, None, None)):\n                old_bundle.add((s1, p1, o1))\n\n        new_bundle = Graph()\n        new_bundle.add((study_URI, RDF.type, OEO.OEO_00020227))\n\n        _publications = json.loads(publications) if publications is not None else []\n        for item in _publications:\n            publications_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/publication/\" + item[\"id\"]\n            )\n\n            new_bundle.add((publications_URI, OEO.OEO_00390095, Literal(item[\"id\"])))\n            new_bundle.add((publications_URI, RDF.type, OEO.OEO_00020012))\n            new_bundle.add((study_URI, OBO.BFO_0000051, publications_URI))\n            if item[\"report_title\"] != \"\":\n                new_bundle.add(\n                    (publications_URI, RDFS.label, Literal(item[\"report_title\"]))\n                )\n\n            _authors = item[\"authors\"]\n\n            if _authors:\n                for author in _authors:\n                    if author[\"name\"]:\n                        author_URI = URIRef(\n                            \"https://openenergyplatform.org/ontology/oekg/\"\n                            + author[\"iri\"]\n                        )\n                        new_bundle.add((author_URI, RDF.type, OEO.OEO_00000064))\n                        new_bundle.add((publications_URI, OEO.OEO_00000506, author_URI))\n\n            if item[\"doi\"] != \"\":\n                new_bundle.add(\n                    (publications_URI, OEO.OEO_00390098, Literal(item[\"doi\"]))\n                )\n\n            if (\n                item[\"date_of_publication\"] != \"1900\"\n                and item[\"date_of_publication\"] != \"\"\n            ):\n                new_bundle.add(\n                    (\n                        publications_URI,\n                        OEO.OEO_00390096,\n                        Literal(item[\"date_of_publication\"], datatype=XSD.dateTime),\n                    )\n                )\n\n            if item[\"link_to_study_report\"] != \"\":\n                new_bundle.add(\n                    (URIRef(item[\"link_to_study_report\"]), RDF.type, OEO.OEO_00000353)\n                )\n                new_bundle.add(\n                    (\n                        publications_URI,\n                        OEO.OEO_00390078,\n                        URIRef(item[\"link_to_study_report\"]),\n                    )\n                )\n\n            new_bundle.add((study_URI, OBO.BFO_0000051, publications_URI))\n\n            # remove old date in publication\n            # iterate to make sure it can only have unique publication date\n            for _s, _p, _o in oekg.triples((publications_URI, OEO.OEO_00390096, None)):\n                oekg.remove((_s, _p, _o))\n\n        _scenarios = json.loads(scenarios) if scenarios is not None else []\n        for item in _scenarios:\n            if item[\"acronym\"] != \"\":\n                scenario_URI = URIRef(\n                    \"https://openenergyplatform.org/ontology/oekg/scenario/\"\n                    + item[\"id\"]\n                )\n\n                for s, p, o in oekg.triples((scenario_URI, None, None)):\n                    oekg.remove((o, p, o))\n\n                new_bundle.add((scenario_URI, OEO.OEO_00390095, Literal(item[\"id\"])))\n                new_bundle.add((scenario_URI, RDF.type, OEO.OEO_00000365))\n                # TODO Acronmy wird lavbel\n                new_bundle.add(\n                    (\n                        scenario_URI,\n                        DC.acronym,\n                        Literal(remove_non_printable(item[\"acronym\"])),\n                    )\n                )\n                if item[\"name\"] != \"\":\n                    new_bundle.add(\n                        (\n                            scenario_URI,\n                            RDFS.label,\n                            Literal(remove_non_printable(item[\"name\"])),\n                        )\n                    )\n                if item[\"abstract\"] != \"\" and item[\"abstract\"] != None:  # noqa\n                    new_bundle.add(\n                        (\n                            scenario_URI,\n                            DC.abstract,\n                            Literal(remove_non_printable(item[\"abstract\"])),\n                        )\n                    )\n\n                if \"regions\" in item:\n                    for region in item[\"regions\"]:\n                        region_URI = URIRef(region[\"iri\"])\n                        scenario_region = URIRef(\n                            \"https://openenergyplatform.org/ontology/oekg/region/\"\n                            + region[\"iri\"].rsplit(\"/\", 1)[1]\n                        )\n                        new_bundle.add((scenario_region, RDF.type, OEO.OEO_00020032))\n                        new_bundle.add(\n                            (\n                                scenario_region,\n                                RDFS.label,\n                                Literal(region[\"name\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (\n                                scenario_region,\n                                OEO.OEO_00390078,\n                                region_URI,\n                            )\n                        )\n                        new_bundle.add(\n                            (scenario_URI, OEO.OEO_00020220, scenario_region)\n                        )\n                        new_bundle.add(\n                            (scenario_URI, OEO.OEO_00390078, scenario_region)\n                        )\n\n                if \"interacting_regions\" in item:\n                    for interacting_region in item[\"interacting_regions\"]:\n                        interacting_region_URI = URIRef(interacting_region[\"iri\"])\n                        scenario_interacting_region = URIRef(\n                            \"https://openenergyplatform.org/ontology/oekg/\"\n                            + interacting_region[\"iri\"]\n                        )\n\n                        new_bundle.add(\n                            (scenario_interacting_region, RDF.type, OEO.OEO_00020036)\n                        )\n                        new_bundle.add(\n                            (\n                                scenario_interacting_region,\n                                RDFS.label,\n                                Literal(interacting_region[\"name\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (\n                                scenario_interacting_region,\n                                OEO.OEO_00390078,\n                                interacting_region_URI,\n                            )\n                        )\n\n                        new_bundle.add(\n                            (\n                                scenario_URI,\n                                OEO.OEO_00020222,\n                                scenario_interacting_region,\n                            )\n                        )\n                # TODO Value does not have datatype xsd:dateTime\n                if \"scenario_years\" in item:\n                    for scenario_year in item[\"scenario_years\"]:\n                        new_bundle.add(\n                            (\n                                scenario_URI,\n                                OEO.OEO_00020440,\n                                Literal(scenario_year[\"name\"], datatype=XSD.dateTime),\n                            )\n                        )\n\n                if \"descriptors\" in item:\n                    for descriptor in item[\"descriptors\"]:\n                        descriptor = URIRef(descriptor[\"class\"])\n                        new_bundle.add((scenario_URI, OEO.OEO_00390073, descriptor))\n\n                # TODO: Jonas Huber: Update to avoid duplicated table name entries\n                # TODO: Predicate is not allowed (closed shape)\n                if \"input_datasets\" in item:\n                    for input_dataset in item[\"input_datasets\"]:\n                        input_dataset_URI = URIRef(\n                            \"https://openenergyplatform.org/ontology/oekg/input_datasets/\"  # noqa\n                            + input_dataset[\"key\"]\n                        )\n\n                        for s, p, o in oekg.triples((input_dataset_URI, None, None)):\n                            oekg.remove((o, p, o))\n\n                        new_bundle.add((input_dataset_URI, RDF.type, OEO.OEO_00030029))\n                        new_bundle.add(\n                            (\n                                input_dataset_URI,\n                                RDFS.label,\n                                Literal(input_dataset[\"value\"][\"label\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (\n                                input_dataset_URI,\n                                OEO.OEO_00390094,\n                                Literal(input_dataset[\"value\"][\"url\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (\n                                input_dataset_URI,\n                                OEKG[\"has_id\"],\n                                Literal(input_dataset[\"idx\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (\n                                input_dataset_URI,\n                                OEO.OEO_00390095,\n                                Literal(input_dataset[\"key\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (scenario_URI, OEO.OEO_00020437, input_dataset_URI)\n                        )\n\n                # TODO: Jonas Huber: Update to avoid duplicated table name entries\n                if \"output_datasets\" in item:\n                    for output_dataset in item[\"output_datasets\"]:\n                        output_dataset_URI = URIRef(\n                            \"https://openenergyplatform.org/ontology/oekg/output_datasets/\"  # noqa: E501\n                            + output_dataset[\"key\"]\n                        )\n                        new_bundle.add((output_dataset_URI, RDF.type, OEO.OEO_00030030))\n                        new_bundle.add(\n                            (\n                                output_dataset_URI,\n                                RDFS.label,\n                                Literal(output_dataset[\"value\"][\"label\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (\n                                output_dataset_URI,\n                                OEO.OEO_00390094,\n                                Literal(output_dataset[\"value\"][\"url\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (\n                                output_dataset_URI,\n                                OEKG[\"has_id\"],\n                                Literal(output_dataset[\"idx\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (\n                                output_dataset_URI,\n                                OEO.OEO_00390095,\n                                Literal(output_dataset[\"key\"]),\n                            )\n                        )\n                        new_bundle.add(\n                            (scenario_URI, OEO.OEO_00020436, output_dataset_URI)\n                        )\n\n                new_bundle.add((study_URI, OBO.BFO_0000051, scenario_URI))\n\n        if acronym != \"\":\n            new_bundle.add(\n                (study_URI, DC.acronym, Literal(remove_non_printable(acronym)))\n            )\n\n        new_bundle.add(\n            (study_URI, RDFS.label, Literal(remove_non_printable(studyName)))\n        )\n\n        institutions = json.loads(institution) if institution is not None else []\n        for item in institutions:\n            institution_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/\" + item[\"iri\"]\n            )\n            new_bundle.add((study_URI, OEO.OEO_00000510, institution_URI))\n\n        funding_sources = (\n            json.loads(funding_source) if funding_source is not None else []\n        )\n        for item in funding_sources:\n            funding_source_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/\" + item[\"iri\"]\n            )\n            new_bundle.add((study_URI, OEO.OEO_00000509, funding_source_URI))\n\n        if abstract != \"\":\n            new_bundle.add(\n                (study_URI, DC.abstract, Literal(remove_non_printable(abstract)))\n            )\n\n        contact_persons = (\n            json.loads(contact_person) if contact_person is not None else []\n        )\n        for item in contact_persons:\n            contact_person_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/\" + item[\"iri\"]\n            )\n            new_bundle.add((study_URI, OEO.OEO_00000508, contact_person_URI))\n\n        _sector_divisions = (\n            json.loads(sector_divisions) if sector_divisions is not None else []\n        )\n        for item in _sector_divisions:\n            sector_divisions_URI = URIRef(item[\"class\"])\n            new_bundle.add((study_URI, OEO.OEO_00390079, sector_divisions_URI))\n\n        _sectors = json.loads(sectors) if sectors is not None else []\n        for item in _sectors:\n            sector_URI = URIRef(item[\"class\"])\n            new_bundle.add((study_URI, OEO.OEO_00020439, sector_URI))\n\n        _technologies = json.loads(technologies) if technologies is not None else []\n        for item in _technologies:\n            technology_URI = URIRef(item[\"class\"])\n            new_bundle.add((study_URI, OEO.OEO_00020438, technology_URI))\n\n        _models = json.loads(models) if models is not None else []\n        for item in _models:\n            model_id = item.get(\"id\")\n\n            if item.get(\"acronym\"):\n                model_acronym = item.get(\"acronym\")\n            else:\n                model_acronym = item.get(\"name\")\n            model_url = item.get(\"url\")\n\n            if not model_id or not model_acronym or not model_url:\n                continue  # Skip this item if any critical field is empty\n\n            model_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/models/\" + str(model_id)\n            )\n            new_bundle.add((model_URI, RDF.type, OEO.OEO_00000277))\n\n            new_bundle.add(\n                (\n                    model_URI,\n                    RDFS.label,\n                    Literal(remove_non_printable(model_acronym)),\n                )\n            )\n\n            new_bundle.add(\n                (\n                    model_URI,\n                    OEO.OEO_00390094,\n                    Literal(model_url),\n                )\n            )\n\n            new_bundle.add((study_URI, OBO.BFO_0000051, model_URI))\n\n            # remove old labels\n            # iterate to make sure only current selection is available\n            for _s, _p, _o in oekg.triples((model_URI, RDFS.label, None)):\n                oekg.remove((_s, _p, _o))\n\n            # remove old iri\u00b4s\n            # iterate to make sure only current selection is available\n            for _s, _p, _o in oekg.triples((model_URI, OEO.OEO_00390094, None)):\n                oekg.remove((_s, _p, _o))\n\n        _frameworks = json.loads(frameworks) if frameworks is not None else []\n        for item in _frameworks:\n            framework_id = item.get(\"id\")\n            if item.get(\"acronym\"):\n                framework_acronym = item.get(\"acronym\")\n            else:\n                framework_acronym = item.get(\"name\")\n            framework_url = item.get(\"url\")\n\n            if not framework_id or not framework_url:\n                continue  # Skip this item if any critical field is empty\n\n            framework_URI = URIRef(\n                \"https://openenergyplatform.org/ontology/oekg/frameworks/\"\n                + str(framework_id)\n            )\n\n            new_bundle.add((framework_URI, RDF.type, OEO.OEO_00000172))\n            if framework_acronym:\n                new_bundle.add(\n                    (\n                        framework_URI,\n                        RDFS.label,\n                        Literal(remove_non_printable(framework_acronym)),\n                    )\n                )\n            if framework_url:\n                new_bundle.add(\n                    (\n                        framework_URI,\n                        OEO.OEO_00390094,\n                        Literal(framework_url),\n                    )\n                )\n\n            new_bundle.add((study_URI, OBO.BFO_0000051, framework_URI))\n\n            # remove old labels\n            # iterate to make sure only current selection is available\n            for _s, _p, _o in oekg.triples((framework_URI, RDFS.label, None)):\n                oekg.remove((_s, _p, _o))\n\n            # remove old iri\u00b4s\n            # iterate to make sure only current selection is available\n            for _s, _p, _o in oekg.triples((framework_URI, OEO.OEO_00390094, None)):\n                oekg.remove((_s, _p, _o))\n\n        _study_keywords = (\n            json.loads(study_keywords) if study_keywords is not None else []\n        )\n        for keyword in _study_keywords:\n            new_bundle.add((study_URI, OEO.OEO_00390071, URIRef(keyword)))\n\n        iso_old_bundle = to_isomorphic(old_bundle)\n        iso_new_bundle = to_isomorphic(new_bundle)\n\n        in_both, in_first, in_second = graph_diff(iso_old_bundle, iso_new_bundle)\n\n        in_first_json = str(in_first.serialize(format=\"json-ld\"))  # noqa\n        in_second_json = str(in_second.serialize(format=\"json-ld\"))  # noqa\n\n        # remove old bundle from oekg\n        for s, p, o in oekg.triples((study_URI, OBO.BFO_0000051, None)):\n            oekg.remove((o, None, None))\n        oekg.remove((study_URI, None, None))\n\n        for s, p, o in oekg.triples((study_URI, OBO.BFO_0000051, None)):\n            oekg.remove((o, None, None))\n        oekg.remove((study_URI, None, None))\n\n        # add updated bundle to oekg\n        for s, p, o in new_bundle.triples((None, None, None)):\n            oekg.add((s, p, o))\n\n        OEKG_Modifications_instance = OEKG_Modifications(  # noqa\n            bundle_id=uid,\n            user=login_models.myuser.objects.filter(name=request.user).first(),\n            old_state=in_first.serialize(format=\"json-ld\"),\n            new_state=in_second.serialize(format=\"json-ld\"),\n        )\n        OEKG_Modifications_instance.save()\n\n        response = JsonResponse(\n            \"factsheet updated!\", safe=False, content_type=\"application/json\"\n        )\n        patch_response_headers(response, cache_timeout=1)\n        return response\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#the-scenario-bundle-object-construction-and-api-in-django","title":"The scenario bundle object construction and API in django","text":"<p>Below we describe how we construct the Scenario bundles in the scenario bundles django app. Using JSON as an input format the complex scenario bundle object becomes more manageable when working with WEB-technologies. Users will create a scenario bundle using a user interface with input text and selection fields this information is send and processed as JSON before it is stored in the OEKG using RDF\u00b4s triple notation.</p> <p>You can read the following sections as: This is how django processes the data, and this is where the data is send once the user submits or changes a scenario bundles. The URL pointing out what django view will handle the JSON object below. This is very similar to what general web api\u00b4s do like REST-API\u00b4s. The exception here is that there is an CSRF Token involved which is required by the django backend to make sure requests are save and do not originate form an unsafe source allowing the scenario bundle frontend to send data to the backend.</p> <p>The technology that drives this implementation is HTTP. The JSON objects and key:value information is send in packaged as a payload that is send along with each requests. A requests can be triggered by multiple actions for example a button that is pressed by the user. Based on the URL and the payload the backend can determine what functionality must be triggered. This can be for example creating a scenario bundle or retrieving a specific bundle by its ID.</p> <p>Note</p> <p>Some of the information on this page may be changed in the future. To review the most recent information, please revisit.</p>"},{"location":"oeplatform-code/features/scenario-bundles/#create-a-new-bundle-in-oekg","title":"Create a new bundle in OEKG","text":"<p><code>https://openenergy-platform.org/scenario-bundles/add/</code></p> <p>An example of input parameters</p> <pre><code>{\n  \"id\": \"new\",\n  \"uid\": \"6157d6d6-7a7b-a61e-21d3-a8f936b19056\",\n  \"study_name\": \"Example study name\",\n  \"acronym\": \"Example acronym\",\n  \"abstract\": \"Example abstract ...\",\n  \"institution\": [\n    {\n      \"iri\": \"708ad5dc-7f8b-6c65-6a5f-0fc54fe8221b\",\n      \"name\": \"\u00d6ko-Institut e.V.\"\n    },\n    {\n      \"iri\": \"8e1515b9-9b1f-fa06-a3a2-d552b0ea7dcd\",\n      \"name\": \"Otto-von-Guericke-Universit\u00e4t Magdeburg\"\n    }\n  ],\n  \"funding_source\": [\n    {\n      \"iri\": \"82dd628d-f748-560b-b0cd-06466cf90f1a\",\n      \"name\": \"Bundesministerium f\u00fcr Umwelt, Naturschutz und nukleare Sicherheit\"\n    }\n  ],\n  \"contact_person\": [],\n  \"sector_divisions\": [],\n  \"sectors\": [\n    {\n      \"label\": \"KSG sector buildings\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010067\"\n    },\n    {\n      \"label\": \"KSG sector industry\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010066\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): wetlands\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010192\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): other product manufacture and use\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010172\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): manure management\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010180\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): multilateral operations\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010203\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): chemical industry - other\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010353\"\n    }\n  ],\n  \"technologies\": [\n    {\n      \"label\": \"power generation technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010423\"\n    },\n    {\n      \"label\": \"wind power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010424\"\n    },\n    {\n      \"label\": \"offshore wind power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010426\"\n    },\n    {\n      \"label\": \"solar thermal power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010429\"\n    },\n    {\n      \"label\": \"hydro power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010431\"\n    },\n    {\n      \"label\": \"run of river power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010432\"\n    }\n  ],\n  \"study_descriptors\": [\n    \"life cycle analysis\",\n    \"(changes in) demand\",\n    \"degree of electrifiaction\",\n    \"Reallabor\",\n    \"regionalisation\",\n    \"peak electricity generation\"\n  ],\n  \"report_title\": \"Example report title\",\n  \"date_of_publication\": \" 2021\",\n  \"report_doi\": \"5345-43-5634-6-346-46-43\",\n  \"place_of_publication\": \"\",\n  \"link_to_study\": \" https://openenergy-platform.org/\",\n  \"authors\": [],\n  \"scenarios\": [\n    {\n      \"id\": \"4974db65-542d-31cd-6f08-11ef9a58680a\",\n      \"name\": \"Example scenario name 1 \",\n      \"acronym\": \"Example scenario acronym 1 \",\n      \"abstract\": \"Example scenario abstract 1 ... \",\n      \"regions\": [\n        {\n          \"name \": \"Germany  \",\n          \"iri \": \"https://www.omg.org/spec/LCC/Countries/ISO3166-1-CountryCodes/Germany \"\n        }\n      ],\n      \"interacting_regions\": [\n        {\n          \"name \": \"Spain  \",\n          \"iri \": \"https://www.omg.org/spec/LCC/Countries/ISO3166-1-CountryCodes/Spain \"\n        }\n      ],\n      \"scenario_years\": [\n        {\n          \"iri \": \"33131404-e58e-12bc-170e-32aba1c83d99 \",\n          \"name \": \"2021 \"\n        }\n      ],\n      \"descriptors \": [\n        {\n          \"label\": \"explorative scenario \",\n          \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00020248 \"\n        },\n        {\n          \"label\": \"policy scenario \",\n          \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00020309 \"\n        },\n        {\n          \"label\": \"climate scenario \",\n          \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00030007\"\n        }\n      ],\n      \"input_datasets\": [\n        {\n          \"key\": \"f2d32e9c-1fa0-4d66-9ffd-c297d4bb5c9a \",\n          \"idx\": 0,\n          \"value \": {\n            \"label \": \"abbb_transmission_capacity \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/abbb_transmission_capacity \"\n          }\n        },\n        {\n          \"key \": \"ca9c82f3-9ba0-7d71-6601-dd520680bedb \",\n          \"idx \": 1,\n          \"value \": {\n            \"label \": \"abbb_demand \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/abbb_demand \"\n          }\n        }\n      ],\n      \"output_datasets \": [\n        {\n          \"key \": \"0db015dd-1543-f0e9-9579-3602fb16a680 \",\n          \"idx \": 0,\n          \"value \": {\n            \"label \": \"abbb_transformer \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/abbb_transformer \"\n          }\n        }\n      ]\n    },\n    {\n      \"id \": \"1f4bb594-4b1c-dca4-2465-e04a54eec10b \",\n      \"name \": \"Example scenario name 2 \",\n      \"acronym \": \"Example scenario acronym 2 \",\n      \"abstract \": \"Example scenario abstract 2 ... \",\n      \"regions \": [\n        {\n          \"name \": \"France  \",\n          \"iri \": \"https://www.omg.org/spec/LCC/Countries/ISO3166-1-CountryCodes/France \"\n        }\n      ],\n      \"interacting_regions \": [\n        {\n          \"name \": \"Germany  \",\n          \"iri \": \"https://www.omg.org/spec/LCC/Countries/ISO3166-1-CountryCodes/Germany \"\n        }\n      ],\n      \"scenario_years \": [],\n      \"descriptors \": [\n        {\n          \"label \": \"explorative scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00020248 \"\n        },\n        {\n          \"label \": \"with additional measures scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00020312 \"\n        },\n        {\n          \"label \": \"greenhouse gas emission scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00020317 \"\n        },\n        {\n          \"label \": \"climate scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00030007 \"\n        },\n        {\n          \"label \": \"economic scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00030008 \"\n        }\n      ],\n      \"input_datasets \": [\n        {\n          \"key \": \"bfc811ee-11f5-6a5a-247d-6f66bb676dd9 \",\n          \"idx \": 0,\n          \"value \": {\n            \"label \": \"abbb_transformer \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/abbb_transformer \"\n          }\n        }\n      ],\n      \"output_datasets \": [\n        {\n          \"key \": \"fbc30f51-7f32-9c21-dfb2-7534aeac538d \",\n          \"idx \": 0,\n          \"value \": {\n            \"label \": \"ego_slp_parameters \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/ego_slp_parameters \"\n          }\n        }\n      ]\n    }\n  ],\n  \"models\": [\n    {\n      \"id \": \"SciGrid: Open Source Reference Model of European Transmission Networks for Scientific Analysis \",\n      \"name \": \"SciGrid: Open Source Reference Model of European Transmission Networks for Scientific Analysis \"\n    },\n    {\n      \"id \": \"Balmorel \",\n      \"name \": \"Balmorel \"\n    },\n    {\n      \"id \": \"National Electricity Market Optimiser \",\n      \"name \": \"National Electricity Market Optimiser \"\n    },\n    {\n      \"id \": \"urbs Bavaria \",\n      \"name \": \"urbs Bavaria \"\n    }\n  ],\n  \"frameworks\": [\n    {\n      \"id \": \"Python for Power System Analysis toolbox (PyPSA) \",\n      \"name \": \"Python for Power System Analysis toolbox (PyPSA) \"\n    },\n    {\n      \"id \": \"Framework for Integrated Energy System Assessment \",\n      \"name \": \"Framework for Integrated Energy System Assessment \"\n    },\n    {\n      \"id \": \"Model Order Reduction for Gas and Energy Networks \",\n      \"name \": \"Model Order Reduction for Gas and Energy Networks \"\n    },\n    {\n      \"id \": \"OMEGAlpes \",\n      \"name \": \"OMEGAlpes \"\n    },\n    {\n      \"id \": \"Potsdam Integrated Assessment Modeling Framework (PIAM) \",\n      \"name \": \"Potsdam Integrated Assessment Modeling Framework (PIAM) \"\n    }\n  ]\n}\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#get-a-bundle-in-oekg","title":"Get a bundle in OEKG","text":"<p>Retrieve a bundle by its <code>uid</code></p> <p><code>https://openenergy-platform.org/scenario-bundles/get/</code></p> <p>An example of input parameters</p> <pre><code>{ \"uid\": \"6157d6d6-7a7b-a61e-21d3-a8f936b19056\" }\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#remove-a-bundle-from-oekg","title":"Remove a bundle from OEKG","text":"<p><code>https://openenergy-platform.org/scenario-bundles/delete/</code></p> <p>To delete a bundle, the <code>uid</code> of the bundle should be provided.</p> <p>An example of input parameters</p> <pre><code>{ \"uid\": \"6157d6d6-7a7b-a61e-21d3-a8f936b19056\" }\n</code></pre>"},{"location":"oeplatform-code/features/scenario-bundles/#update-a-bundle-in-oekg","title":"Update a bundle in OEKG","text":"<p><code>https://openenergy-platform.org/scenario-bundles/update/</code></p> <p>An example of input parameters</p> <p>The <code>uid</code> should belong to an existing bundle in OEKG. The remaining fields are identical to those in the create bundle API.</p> <pre><code>{\n  \"uid\": \"6157d6d6-7a7b-a61e-21d3-a8f936b19056\",\n  \"study_name\": \"Example study name\",\n  \"acronym\": \"Example acronym\",\n  \"abstract\": \"Example abstract ...\",\n  \"institution\": [\n    {\n      \"iri\": \"708ad5dc-7f8b-6c65-6a5f-0fc54fe8221b\",\n      \"name\": \"\u00d6ko-Institut e.V.\"\n    },\n    {\n      \"iri\": \"8e1515b9-9b1f-fa06-a3a2-d552b0ea7dcd\",\n      \"name\": \"Otto-von-Guericke-Universit\u00e4t Magdeburg\"\n    }\n  ],\n  \"funding_source\": [\n    {\n      \"iri\": \"82dd628d-f748-560b-b0cd-06466cf90f1a\",\n      \"name\": \"Bundesministerium f\u00fcr Umwelt, Naturschutz und nukleare Sicherheit\"\n    }\n  ],\n  \"contact_person\": [],\n  \"sector_divisions\": [],\n  \"sectors\": [\n    {\n      \"label\": \"KSG sector buildings\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010067\"\n    },\n    {\n      \"label\": \"KSG sector industry\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010066\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): wetlands\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010192\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): other product manufacture and use\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010172\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): manure management\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010180\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): multilateral operations\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010203\"\n    },\n    {\n      \"label\": \"CRF sector (IPCC 2006): chemical industry - other\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010353\"\n    }\n  ],\n  \"technologies\": [\n    {\n      \"label\": \"power generation technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010423\"\n    },\n    {\n      \"label\": \"wind power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010424\"\n    },\n    {\n      \"label\": \"offshore wind power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010426\"\n    },\n    {\n      \"label\": \"solar thermal power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010429\"\n    },\n    {\n      \"label\": \"hydro power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010431\"\n    },\n    {\n      \"label\": \"run of river power technology\",\n      \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00010432\"\n    }\n  ],\n  \"study_descriptors\": [\n    \"life cycle analysis\",\n    \"(changes in) demand\",\n    \"degree of electrifiaction\",\n    \"Reallabor\",\n    \"regionalisation\",\n    \"peak electricity generation\"\n  ],\n  \"report_title\": \"Example report title\",\n  \"date_of_publication\": \" 2021\",\n  \"report_doi\": \"5345-43-5634-6-346-46-43\",\n  \"place_of_publication\": \"\",\n  \"link_to_study\": \" https://openenergy-platform.org/\",\n  \"authors\": [],\n  \"scenarios\": [\n    {\n      \"id\": \"4974db65-542d-31cd-6f08-11ef9a58680a\",\n      \"name\": \"Example scenario name 1 \",\n      \"acronym\": \"Example scenario acronym 1 \",\n      \"abstract\": \"Example scenario abstract 1 ... \",\n      \"regions\": [\n        {\n          \"name \": \"Germany  \",\n          \"iri \": \"https://www.omg.org/spec/LCC/Countries/ISO3166-1-CountryCodes/Germany \"\n        }\n      ],\n      \"interacting_regions\": [\n        {\n          \"name \": \"Spain  \",\n          \"iri \": \"https://www.omg.org/spec/LCC/Countries/ISO3166-1-CountryCodes/Spain \"\n        }\n      ],\n      \"scenario_years\": [\n        {\n          \"iri \": \"33131404-e58e-12bc-170e-32aba1c83d99 \",\n          \"name \": \"2021 \"\n        }\n      ],\n      \"descriptors \": [\n        {\n          \"label\": \"explorative scenario \",\n          \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00020248 \"\n        },\n        {\n          \"label\": \"policy scenario \",\n          \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00020309 \"\n        },\n        {\n          \"label\": \"climate scenario \",\n          \"class\": \"http://openenergy-platform.org/ontology/oeo/OEO_00030007\"\n        }\n      ],\n      \"input_datasets\": [\n        {\n          \"key\": \"f2d32e9c-1fa0-4d66-9ffd-c297d4bb5c9a \",\n          \"idx\": 0,\n          \"value \": {\n            \"label \": \"abbb_transmission_capacity \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/abbb_transmission_capacity \"\n          }\n        },\n        {\n          \"key \": \"ca9c82f3-9ba0-7d71-6601-dd520680bedb \",\n          \"idx \": 1,\n          \"value \": {\n            \"label \": \"abbb_demand \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/abbb_demand \"\n          }\n        }\n      ],\n      \"output_datasets \": [\n        {\n          \"key \": \"0db015dd-1543-f0e9-9579-3602fb16a680 \",\n          \"idx \": 0,\n          \"value \": {\n            \"label \": \"abbb_transformer \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/abbb_transformer \"\n          }\n        }\n      ]\n    },\n    {\n      \"id \": \"1f4bb594-4b1c-dca4-2465-e04a54eec10b \",\n      \"name \": \"Example scenario name 2 \",\n      \"acronym \": \"Example scenario acronym 2 \",\n      \"abstract \": \"Example scenario abstract 2 ... \",\n      \"regions \": [\n        {\n          \"name \": \"France  \",\n          \"iri \": \"https://www.omg.org/spec/LCC/Countries/ISO3166-1-CountryCodes/France \"\n        }\n      ],\n      \"interacting_regions \": [\n        {\n          \"name \": \"Germany  \",\n          \"iri \": \"https://www.omg.org/spec/LCC/Countries/ISO3166-1-CountryCodes/Germany \"\n        }\n      ],\n      \"scenario_years \": [],\n      \"descriptors \": [\n        {\n          \"label \": \"explorative scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00020248 \"\n        },\n        {\n          \"label \": \"with additional measures scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00020312 \"\n        },\n        {\n          \"label \": \"greenhouse gas emission scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00020317 \"\n        },\n        {\n          \"label \": \"climate scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00030007 \"\n        },\n        {\n          \"label \": \"economic scenario \",\n          \"class \": \"http://openenergy-platform.org/ontology/oeo/OEO_00030008 \"\n        }\n      ],\n      \"input_datasets \": [\n        {\n          \"key \": \"bfc811ee-11f5-6a5a-247d-6f66bb676dd9 \",\n          \"idx \": 0,\n          \"value \": {\n            \"label \": \"abbb_transformer \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/abbb_transformer \"\n          }\n        }\n      ],\n      \"output_datasets \": [\n        {\n          \"key \": \"fbc30f51-7f32-9c21-dfb2-7534aeac538d \",\n          \"idx \": 0,\n          \"value \": {\n            \"label \": \"ego_slp_parameters \",\n            \"iri \": \"https://openenergy-platform.org/database/tables/scenario/ego_slp_parameters \"\n          }\n        }\n      ]\n    }\n  ],\n  \"models\": [\n    {\n      \"id \": \"SciGrid: Open Source Reference Model of European Transmission Networks for Scientific Analysis \",\n      \"name \": \"SciGrid: Open Source Reference Model of European Transmission Networks for Scientific Analysis \"\n    },\n    {\n      \"id \": \"Balmorel \",\n      \"name \": \"Balmorel \"\n    },\n    {\n      \"id \": \"National Electricity Market Optimiser \",\n      \"name \": \"National Electricity Market Optimiser \"\n    },\n    {\n      \"id \": \"urbs Bavaria \",\n      \"name \": \"urbs Bavaria \"\n    }\n  ],\n  \"frameworks\": [\n    {\n      \"id \": \"Python for Power System Analysis toolbox (PyPSA) \",\n      \"name \": \"Python for Power System Analysis toolbox (PyPSA) \"\n    },\n    {\n      \"id \": \"Framework for Integrated Energy System Assessment \",\n      \"name \": \"Framework for Integrated Energy System Assessment \"\n    },\n    {\n      \"id \": \"Model Order Reduction for Gas and Energy Networks \",\n      \"name \": \"Model Order Reduction for Gas and Energy Networks \"\n    },\n    {\n      \"id \": \"OMEGAlpes \",\n      \"name \": \"OMEGAlpes \"\n    },\n    {\n      \"id \": \"Potsdam Integrated Assessment Modeling Framework (PIAM) \",\n      \"name \": \"Potsdam Integrated Assessment Modeling Framework (PIAM) \"\n    }\n  ]\n}\n</code></pre>"},{"location":"oeplatform-code/features/upload-wizard/tabular-data-upload/","title":"Tabular data upload","text":""},{"location":"oeplatform-code/features/upload-wizard/tabular-data-upload/#upload","title":"Upload","text":"<p>The process op uploading data to the oep is implemented in the OEP-WEB api and can be used via rest entirely. Recently some required enhancements have been identified and the API will be updated, old endpoints are redirected to prevent breaking 3rd party code.</p> <p>More extensive testing will be introduced and some datasets related new endpoints are added. The core functionality which can be used to create tabular data resources in the postgresql database must be optimized but will be one of the main parts of the feature described in this section.</p> <p>Building on the existing functionality and the collective feedback from its users we will rework the upload UI. In the end the OEP website implements a UI which uses all available api endpoints making the process of creating data less technical. This also adds a visualization for the data management as datasets which consist of multiple data resources can be edited and managed in general. We currently work out the details but it becomes clear that some parts of the ui will be relevant during creating and then later to come back and edit or extend the information which might require being able to reuse some ui elements in other pages of the oeplatform.</p> <p>The interface can offer a central dashboard to create and maintain datasets to gain a very good data quality. Adding extensive metadata lining the resource to external objects or attaching them to scenario bundles helps to build a linked information object which in the end offers all information required to be transparent in use, reusable regarding license information and in general understandable.</p>"},{"location":"oeplatform-code/features/upload-wizard/tabular-data-upload/#method","title":"Method","text":"<p>We use an http api request/response cycle which requires batching requests for larger uploads.</p> <p>There is an UI which enables uploading CSV datasets to the OEDB and registering the data resource in the OEP data-management system. Especially the creation of OEMetadata and Datasets is important on a low level. To extend this we will have to wait until we implement organizations and projects who wrap datasets and single table resources to establish a storage structure which reflects the linage and data grouping information. Data can then be identified by contributor, project and an extensive collection of metadata keys from the oemetadata available for a resource.</p> <p>Reflecting on the point in time when a dataset or data resource is published it would be best to let the user actively decide at what point they want to submit it to bew reviewed. This would then also help the review process which would require a actively submitted request for review. This is similar to GitHubs pull requests. We dont need Review requests with draft states as all data will be in a draft state first. It should also be possible to review data which was not submitted for review but only as an option not in a highlighted way as when a review is requested.</p> <p>Overall this leads to a coherent process of creating data providing descriptive metadata and then considering the data resource complete. For validation and general data and metadata quality checks then the community or specific reviewers can participate in reviews. Which should lead to good quality data repositories.</p> <p>Some special functionality which was introduced during the SIROP project can also be placed prominently to enhance visibility and usability of such functionality. Especially for data annotation, subject (topic) annotations and linkage to the databus this rework should be a huge benefit. Adding the option to fill such information assets during the creation step of the data resource but only requiring a small amount of metadata. By also adding a quick action option we also enable user to just create a table resource and do all the other stuff later on. This is full flexibility which is only possible once the OEDB - OEP schema coupling is solved moving all further data structuring into the OEP application logic making all layers between database/table resource virtual keeping is simple to enable very less restrictive database usage. This still requires minimal validation to confirm the submitted data meets the technical requirements.</p>"},{"location":"oeplatform-code/features/upload-wizard/tabular-data-upload/#ui","title":"UI","text":"<p>The main subject to restructure is the UI it will have to provide a clear, structured workspace to manage creating a dataset including multiple data resources and describing the data as tabular data structure enabling creating SQL and oemetadata compliant resource description which can be created on the OEDB (Postgresql table).</p> <p>UI Elements</p> <ul> <li>Guide the User: Steps &amp; Progress</li> <li>Detailed Interfaces dor each step:<ul> <li>Dataset information</li> <li>Metadata Template (apply for all resources, add specifics later)</li> <li>Add resource (setup table, upload form datapackage or csv, Setup data   annotations)</li> <li>User Review (show recommendations and errors in metadata) and submit for   peer-review or keep in draft</li> </ul> </li> </ul> <ul> <li>Offer Quick action to create a table resource without dataset information just   by name and table structure (as it is currently)</li> <li>Link to external information like academy, specifications &amp; show api endpoints   for every section element?</li> </ul>"},{"location":"oeplatform-code/web-api/","title":"Index","text":""},{"location":"oeplatform-code/web-api/#web-api-s","title":"Web API\u00b4s","text":"<p>This section describes the web APIs provided by the oeplatform. In the context of the oeplatform, the web APIs include http request interfaces that require an expected request body with a JSON data structure to formulate the specific request. As a result, a JSON response is sent back.</p> <p>Currently, a REST API is used that provides basic data management functions for interacting with the OEDB, with a focus on interacting with the data uploaded by users. The other WEB API provides functions for interacting with the scenario bundles. With this API, users can perform complex semantic queries.</p>"},{"location":"oeplatform-code/web-api/oedb-rest-api/","title":"Index","text":""},{"location":"oeplatform-code/web-api/oedb-rest-api/#rest-http-api","title":"Rest (http) API","text":"<p>We are still in the process of migrating this document!</p> <p>If you are looking for our former ReadTheDocs based documentation: We do not support it anymore and added a redirect to this page here. Migrating the outdated documentation and updating the content will take some time. Please revisit this page later again.</p> <p>In the meantime we suggest you to have a look at our Courses &amp; Tutorials available in the Academy.</p>"},{"location":"oeplatform-code/web-api/oedb-rest-api/#what-the-rest-api-offers","title":"What the Rest-API offers","text":"<p>When working with data, it is very helpful to be able to implement programmatic solutions for managing data resources. The Rest API provides such functionality by opening the underlying database of the OEP website via HTTP. Users can access data tables under specific IRI's and retrieve various information artefacts. Following the REST specification, the common JSON format is used to transfer the data. External applications can easily process such JSON data and also upload new data to the database. This document provides information on the so called API Endpoint specification. This Information is relevant to use the CRUD functionality of the REST-API.</p>"},{"location":"oeplatform-code/web-api/oedb-rest-api/#open-api","title":"Open API","text":"<p>Below you see a draft version of the OpenAPI-based. It is the documentation for all HTTP-API endpoints and in the future it can be used to test out the API.</p> API Documentation"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/","title":"Resource data size","text":""},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#database-table-sizes","title":"Database Table Sizes","text":"<p>Short guide for the Table Sizes API endpoint. This endpoint returns the storage size of individual tables (including indexes) or all tables across all schemas.</p> <p>Base URL: <code>https://openenergyplatform.org</code></p>"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#authentication","title":"Authentication","text":"<p>This endpoint requires token authentication.</p> <pre><code>Authorization: Token &lt;YOUR_API_TOKEN&gt;\n</code></pre> <p>Security</p> <p>Never use real tokens in documentation. Always use placeholders like <code>&lt;YOUR_API_TOKEN&gt;</code>.</p>"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#endpoint","title":"Endpoint","text":"<pre><code>GET /api/v0/db/table-sizes/\n</code></pre>"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#query-parameters","title":"Query Parameters","text":"Parameter Type Description <code>schema</code> str optional; filter by schema <code>table</code> str optional; filter by a specific table (only useful in combination with <code>schema</code>)"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#examples","title":"Examples","text":""},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#all-tables-all-schemas","title":"All Tables (all Schemas)","text":"<pre><code>curl -s \\\n  -H \"Authorization: Token &lt;YOUR_API_TOKEN&gt;\" \\\n  \"https://openenergyplatform.org/api/v0/db/table-sizes/\"\n</code></pre>"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#single-table","title":"Single Table","text":"<pre><code>curl -s \\\n  -H \"Authorization: Token &lt;YOUR_API_TOKEN&gt;\" \\\n  \"https://openenergyplatform.org/api/v0/db/table-sizes/?table=oeko_testtable\"\n</code></pre>"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#raw-http-example","title":"Raw HTTP Example","text":"<pre><code>GET /api/v0/db/table-sizes/?table=oeko_testtable HTTP/1.1\nHost: openenergyplatform.org\nAuthorization: Token &lt;YOUR_API_TOKEN&gt;\n</code></pre>"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#example-response","title":"Example Response","text":"<pre><code>{\n  \"table_name\": \"oeko_testtable\",\n  \"table_bytes\": 0,\n  \"index_bytes\": 0,\n  \"total_bytes\": 8192,\n  \"table_pretty\": \"0 bytes\",\n  \"index_pretty\": \"0 bytes\",\n  \"total_pretty\": \"8192 bytes\"\n}\n</code></pre> <p>Note on empty tables</p> <p><code>8192</code> bytes is typically the default overhead for an empty table (one memory page). Therefore, <code>total_bytes</code> can be &gt; 0 even if <code>table_bytes</code> and <code>index_bytes</code> are zero.</p>"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#response-fields","title":"Response Fields","text":"Field Type Description <code>table_schema</code> str Name of the schema <code>table_name</code> str Table name <code>table_bytes</code> int Size of the table data in bytes <code>index_bytes</code> int Size of the associated indexes in bytes <code>total_bytes</code> int Sum of <code>table_bytes</code> + <code>index_bytes</code> + possible overhead <code>table_pretty</code> str Human-readable representation of <code>table_bytes</code> <code>index_pretty</code> str Human-readable representation of <code>index_bytes</code> <code>total_pretty</code> str Human-readable representation of <code>total_bytes</code>"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#error-cases","title":"Error Cases","text":"<ul> <li><code>401 Unauthorized</code>: Token missing or invalid.</li> <li><code>400 Bad Request</code>: Invalid parameter combination (e.g., <code>table</code> without   <code>schema</code>).</li> </ul>"},{"location":"oeplatform-code/web-api/oedb-rest-api/resource-data-size/#quickstart-in-python-requests","title":"Quickstart in Python (requests)","text":"<pre><code>import requests\n\nBASE_URL = \"https://openenergyplatform.org/api/v0/db/table-sizes/\"\nHEADERS = {\"Authorization\": \"Token &lt;YOUR_API_TOKEN&gt;\"}\n\n# All tables\nr = requests.get(BASE_URL, headers=HEADERS)\nr.raise_for_status()\nprint(r.json())\n\n# Single table\nparams = {\"table\": \"testtable\"}\nr = requests.get(BASE_URL, headers=HEADERS, params=params)\nr.raise_for_status()\nprint(r.json())\n</code></pre> <p>Last updated: 17.08.2025</p>"},{"location":"oeplatform-code/web-api/oekg-api/","title":"Index","text":""},{"location":"oeplatform-code/web-api/oekg-api/#oekg-web-based-access","title":"OEKG web based access","text":"<p>In this document we describe how you can access the contents of the OEKG via Web based Requests using HTTP</p>"},{"location":"oeplatform-code/web-api/oekg-api/#the-sparql-endpoint-for-oekg","title":"The SPARQL endpoint for OEKG","text":"<p><code>https://openenergyplatform.org/api/v0/oekg/sparql/</code></p> <p>Here is an example of how to query the Open Energy Knowledge Graph (OEKG) using SPARQL using python and the requests library for http requests.</p> <p>OEP-API Token</p> <p>For authentication with the OEP-REST-API you have to register on https://openenergyplatform.org/accounts/signup/ or sign in with you institution. Once you are registered you can find your API Token in you Profile page under the \"Settings\" Tab. Clicks \"Show Token\" and copy the hash value.</p> <p>See our more detailed guide on how to get started with the OpenEnergyPlatform.</p> <pre><code>import requests\n\nOEP_API_TOKEN = \"&lt;Add-Your-Token&gt;\"\nHEADER = {\"Authorization\": f\"Token {OEP_API_TOKEN}\"}\nsparql_endpoint = \"https://openenergyplatform.org/api/v0/oekg/sparql/\"\npayload = {\n    \"query\": \"\"\"SELECT ?s ?p ?o\n                WHERE {\n                  ?s ?p ?o\n                }\"\"\",\n    \"format\": \"json\"\n}\n\nr = requests.post(url=sparql_endpoint, json=payload, headers=HEADER)\nprint(r.json())\n</code></pre>"},{"location":"oeplatform-code/web-api/oekg-api/#open-api","title":"Open API","text":"<p>Below you see a draft version of the OpenAPI-based. It is the documentation for all HTTP-API endpoints and in the future it can be used to test out the API.</p> API Documentation"},{"location":"oeplatform-code/web-api/oekg-api/scenario-dataset/","title":"Edit scenario datasets","text":""},{"location":"oeplatform-code/web-api/oekg-api/scenario-dataset/#api-to-manipulate-dataset-for-in-a-scenario","title":"API to manipulate dataset for in a scenario","text":""},{"location":"oeplatform-code/web-api/oekg-api/scenario-dataset/#basics","title":"Basics","text":"<p>This functionality is part of the oeplatform web api and can be accessed sending POST requests to this endpoint:</p> <ul> <li><code>https://openenergyplatform.org/api/v0/scenario-bundle/scenario/manage-datasets/</code></li> </ul> <p>You need a client to send http requests.</p> <ul> <li>Python: requests</li> <li>linux: curl</li> <li>Client software: HTTPie</li> <li>and more</li> </ul> <p>For authorization you must use you API Token which can be optioned form the profile page on the OEP. In case you leaked it you can also reset the token. See section Access restrictions and future consideration.</p> <p>The post request must contain a body with payload:</p> <pre><code>{\n  \"scenario_bundle\": \"1970ba29-155b-6e70-7c22-c12a33244a24\",\n  \"scenario\": \"5d95247d-df75-a95b-7286-dd4b3bc1c92a\",\n  \"datasets\": [\n    {\n      \"name\": \"eu_leg_data_2017_eio_ir_article23_t3\",\n      \"type\": \"input\"\n    },\n    {\n      \"name\": \"testetstetst\",\n      \"type\": \"output\"\n    },\n    {\n      \"name\": \"WS_23_24_B665_2025_01_23\",\n      \"external_url\": \"https://databus.openenergyplatform.org/koubaa/LLEC_Dataset/WS_23_24_B665_2025_01_23/WS_23_24_B665_2025_01_23\",\n      \"type\": \"output\"\n    }\n  ]\n}\n</code></pre> <ul> <li>scenario_bundle: can be obtained from the scenario bundle website (copy from   url)</li> <li>scenario: can also be obtained from the website; In the scenario tab there is   a button to copy each scenario UID</li> <li>datasets: Is a list of all datasets you want to add</li> <li>name: you can lookup a table name that is available on the OEP and published   in the scenario topic. The technical name is required here.</li> <li>type: Chose either \"input\" or \"output\" here, the dataset will be added to the   related section in the scenario</li> <li>external_url: This parameter is OPTIONAL to be precise you dont have to use it   if you are adding a dataset that is available on the OEP. You can use it to   link external datasets but it requires you to first register them on the   databus to get a persistent id. The databus offers a Publishing page. After   the dataset is registered you can copy the file or version URL and add it to   the external_url field.</li> </ul> <ul> <li>https://databus.openenergyplatform.org/app/publish-wizard</li> <li>The databus also offers a API in case you want to register in bulk</li> </ul>"},{"location":"oeplatform-code/web-api/oekg-api/scenario-dataset/#example-using-curl","title":"Example using curl","text":"<pre><code>curl --request POST \\\n  --url https://openenergyplatform.org/api/v0/scenario-bundle/scenario/manage-datasets/ \\\n  --header 'Authorization: Token &lt;YOUR TOKEN&gt;' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n  \"scenario_bundle\": \"1970ba29-155b-6e70-7c22-c12a33244a24\",\n  \"scenario\": \"5d95247d-df75-a95b-7286-dd4b3bc1c92a\",\n  \"datasets\": [\n    {\n      \"name\": \"eu_leg_data_2017_eio_ir_article23_t3\",\n      \"type\": \"input\"\n    },\n    {\n      \"name\": \"testetstetst\",\n      \"type\": \"output\"\n    },\n    {\n      \"name\": \"WS_23_24_B665_2025_01_23\",\n      \"external_url\": \"https://databus.openenergyplatform.org/koubaa/LLEC_Dataset/WS_23_24_B665_2025_01_23/WS_23_24_B665_2025_01_23\",\n      \"type\": \"output\"\n    },\n    {\n      \"name\": \"first_test_table\",\n      \"type\": \"output\"\n    }\n  ]\n}'\n</code></pre>"},{"location":"oeplatform-code/web-api/oekg-api/scenario-dataset/#access-restrictions-and-future-consideration","title":"Access restrictions and future consideration","text":"<p>Currently only the person who created a scenario bundle is able to edit its content. Soon this will change and users will be able to assign a group to a bundle. Groups are also used to manage access to dataset resources on the OEP here we will use the same groups. Once this is implemented you will have to create/assign a group to you bundle and then you can collaborate on the editing.</p>"}]}